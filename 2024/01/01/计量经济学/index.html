<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>计量经济学 | Harlon Yan</title><meta name="author" content="Harlon Yan"><meta name="copyright" content="Harlon Yan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="计量经济学导论 第1章 计量经济学的性质与经济数据 【教材精讲-《计量经济学导论.现代观点》】第一章 导论_哔哩哔哩_bilibili 什么是计量经济学？ 计量经济学在做什么？找数、建模、分析 经济分析的数据结构长什么样？强调数据之间的关系（截面、混合截面、时间序列、面板数据） 计量经济学家最关心什么？因果关系！ 计量经济学在做什么？ 在做什么问题？ 估计经济关系：评价一些经">
<meta property="og:type" content="article">
<meta property="og:title" content="计量经济学">
<meta property="og:url" content="http://example.com/2024/01/01/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6/index.html">
<meta property="og:site_name" content="Harlon Yan">
<meta property="og:description" content="计量经济学导论 第1章 计量经济学的性质与经济数据 【教材精讲-《计量经济学导论.现代观点》】第一章 导论_哔哩哔哩_bilibili 什么是计量经济学？ 计量经济学在做什么？找数、建模、分析 经济分析的数据结构长什么样？强调数据之间的关系（截面、混合截面、时间序列、面板数据） 计量经济学家最关心什么？因果关系！ 计量经济学在做什么？ 在做什么问题？ 估计经济关系：评价一些经">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2logo%20%EF%BC%88%E5%B0%8F).png">
<meta property="article:published_time" content="2023-12-31T16:00:00.000Z">
<meta property="article:modified_time" content="2025-01-28T14:05:09.759Z">
<meta property="article:author" content="Harlon Yan">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2logo%20%EF%BC%88%E5%B0%8F).png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "计量经济学",
  "url": "http://example.com/2024/01/01/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6/",
  "image": "http://example.com/img/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2logo%20%EF%BC%88%E5%B0%8F).png",
  "datePublished": "2023-12-31T16:00:00.000Z",
  "dateModified": "2025-01-28T14:05:09.759Z",
  "author": [
    {
      "@type": "Person",
      "name": "Harlon Yan",
      "url": "http://example.com/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2024/01/01/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '计量经济学',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI0OCIgaGVpZ2h0PSI0OCIgdmlld0JveD0iMCAwIDI0IDI0Ij48Y2lyY2xlIGN4PSI0IiBjeT0iMTIiIHI9IjMiIGZpbGw9ImN1cnJlbnRDb2xvciI+PGFuaW1hdGUgaWQ9InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAiIGF0dHJpYnV0ZU5hbWU9InIiIGJlZ2luPSIwO3N2Z1NwaW5uZXJzM0RvdHNTY2FsZTEuZW5kLTAuMjVzIiBkdXI9IjAuNzVzIiB2YWx1ZXM9IjM7LjI7MyIvPjwvY2lyY2xlPjxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjMiIGZpbGw9ImN1cnJlbnRDb2xvciI+PGFuaW1hdGUgYXR0cmlidXRlTmFtZT0iciIgYmVnaW49InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAuZW5kLTAuNnMiIGR1cj0iMC43NXMiIHZhbHVlcz0iMzsuMjszIi8+PC9jaXJjbGU+PGNpcmNsZSBjeD0iMjAiIGN5PSIxMiIgcj0iMyIgZmlsbD0iY3VycmVudENvbG9yIj48YW5pbWF0ZSBpZD0ic3ZnU3Bpbm5lcnMzRG90c1NjYWxlMSIgYXR0cmlidXRlTmFtZT0iciIgYmVnaW49InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAuZW5kLTAuNDVzIiBkdXI9IjAuNzVzIiB2YWx1ZXM9IjM7LjI7MyIvPjwvY2lyY2xlPjwvc3ZnPg==" data-original="/./img/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2logo%20%EF%BC%88%E5%B0%8F).png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">5</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-categories"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-about"></i><span> 关于</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background: linear-gradient(to left, #40e0d0, #ff8c00, #ff0080);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Harlon Yan</span></a><a class="nav-page-title" href="/"><span class="site-name">计量经济学</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-categories"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-about"></i><span> 关于</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">计量经济学</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-12-31T16:00:00.000Z" title="发表于 2024-01-01 00:00:00">2024-01-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-01-28T14:05:09.759Z" title="更新于 2025-01-28 22:05:09">2025-01-28</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>计量经济学导论</p>
<h1 id="第1章-计量经济学的性质与经济数据">第1章
计量经济学的性质与经济数据</h1>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1c94y1t7YZ/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第一章
导论_哔哩哔哩_bilibili</a></p>
<p>什么是计量经济学？</p>
<p>计量经济学在做什么？找数、建模、分析</p>
<p>经济分析的数据结构长什么样？强调数据之间的关系（截面、混合截面、时间序列、面板数据）</p>
<p>计量经济学家最关心什么？因果关系！</p>
<h2 id="计量经济学在做什么">计量经济学在做什么？</h2>
<h3 id="在做什么问题">在做什么问题？</h3>
<p>估计经济关系：评价一些经济变量之间的关联，如最低工资和失业率、税收政策和经济增长......</p>
<p>检验经济理论：理论是抽象的，那么它是否能够经得住事实数据的检验？</p>
<p>评价政策效果：政策措施是否能够达到预期的目标？</p>
<h3 id="在用什么样的方法体系做">在用什么样的方法体系做？</h3>
<p><mark>找数：</mark>经验分析（empirical
analysis，用数据去进行研究，不是凭经验分析，国内常称为实证分析），经验分析就是利用数据来检验某个理论或估计某种关系。</p>
<p><mark>建模：</mark>构建模型，转化参数（将现实中的复杂关系抽象成函数，将我们关心的效果、成效等变量转换成函数中的<mark>参数</mark>，这个参数是最需要关心的量）。其基本流程是：<mark>经济理论→经济模型→经济计量模型</mark>。其中<mark>经济模型（economic
model）</mark>总是由<u>描述</u>各种关系的数理方程构成。这些模型背后的基本假设前提就是效用最大化，即个人在资源约束条件下最大化其福利。经济计量模型（econometric
model）是对上述经济模型的函数的形式进行明确表示，以犯罪的经济模型为例：</p>
<p><span class="math display">\[y =
f(x_{1},x_{2},x_{3},x_{4},x_{5},x_{6}{,x}_{7})\]</span></p>
<p>其中<span
class="math inline">\(y\)</span>是花在犯罪活动上的小时数，<span
class="math inline">\(x_{1}\)</span>是从事犯罪活动每小时的"工资"，<span
class="math inline">\(x_{2}\)</span>是合法就业的小时工作，<span
class="math inline">\(x_{3}\ldots\ldots
x_{7}\)</span>依次是根据经济理论得出的与犯罪时长有关的变量。但是这个经济模型中，有许多的量是无法观测到的，比如<span
class="math inline">\(x_{1}\)</span>是从事犯罪活动每小时的"工资"，其变量之间的关系也是不确定的，因此我们设定一个计量经济模型，去消除模型中的不确定性，如下：</p>
<p><span class="math display">\[crime = \beta_{0} + \beta_{1}{wage}_{m}
+ \beta_{2}othinc + \beta_{3}freqarr +\]</span></p>
<p><span class="math display">\[\beta_{4}freqconv + \beta_{5}avgsen +
\beta_{6}age + u\]</span></p>
<p>这些变量的选择即是以经济理论为依据，又有数据方面的考虑。其中，<span
class="math inline">\(u\)</span>包含了其余不可观测的因素，如上文提到的<span
class="math inline">\(x_{1}\)</span>是从事犯罪活动每小时的"工资"。<span
class="math inline">\(u\)</span>是一个误差项（error
term）或干扰项（disturbance
term），对其的处理是任何计量分析中最重要的内容。</p>
<p>但在实际分析过程中，一般就是直接构造经济计量模型，因为如果对犯罪这种经历模型进行仔细推敲，不仅消耗的时间长，而且会把我们带到经济理论的某个特定而又通常极为困难的领域。</p>
<p><mark>分析：</mark>参数估计，参数检验。如对上述计量模型中的<span
class="math inline">\(\beta\)</span>和<span
class="math inline">\(u\)</span>进行研究。</p>
<h3 id="经济数据的数据结构">经济数据的数据结构</h3>
<table style="width:94%;">
<colgroup>
<col style="width: 19%" />
<col style="width: 18%" />
<col style="width: 19%" />
<col style="width: 20%" />
<col style="width: 16%" />
</colgroup>
<thead>
<tr>
<th></th>
<th>截面数据</th>
<th>时间序列</th>
<th>混合截面</th>
<th>面板数据</th>
</tr>
</thead>
<tbody>
<tr>
<td>形式</td>
<td><p>给 定时间点，</p>
<p>不同对象</p></td>
<td><p>不 同时间点，</p>
<p>同一个对象</p></td>
<td><p>不同时间点，</p>
<p>不同对象</p></td>
<td><p>不同 时间点，</p>
<p>同 一批对象</p></td>
</tr>
<tr>
<td>内涵</td>
<td>随机抽样</td>
<td>历史 依赖性（趋 势、周期）</td>
<td>存 在时间维，单 位之间不相关</td>
<td>不同对 象的纵向 演变过程</td>
</tr>
</tbody>
</table>
<h4 id="截面数据集cross-sectional-data-set">截面数据集（cross-sectional
data set）</h4>
<p>横截面数据集一般是针对不同对象在同一时间点进行数据收集。但在一个纯粹的横截面分析中，我们应该忽略数据搜集中细小的时间差别。如果一系列家庭都是在同一年度的不同星期被调查的，我们仍视之为横截面数据集。</p>
<p>横截面数据的一个重要特征的就是，我们通常可以假定，它们是从样本背后的总体中通过<mark>随机抽样（random
sampling）</mark>而得到的。但是，讲随机抽样作为横截面数据的一个假定也是不妥的，可能存在一些现实情况和技术操作上的问题导致偏离随机抽样。</p>
<p>由于一般是随机抽样得到的，所以各行（观测）之间没有明显联系。如下图两个例子。第一个表格每一行代表一个观测的工人，观测和观测之间没有任何的关系，数据收集也都是在同一时间点，因此是一个典型的截面数据。</p>
<p><img src="https://s2.loli.net/2025/01/28/2QTRNOhtLF96giV.png"
style="width:5.7023in;height:2.26073in" /></p>
<p>但对于第二张图，变量gpcrgdp表示1960-1985年间实际人均GDP的平均增长率，govcons60表示1960年政府消费占GDP的百分比，second60表示1960年成人中受过中级教育的百分比。虽然不是所有的变量都在同一时间点收集，但其不同行/观测之间仍然是不存在相关关系的，因此也同样能够将这些信息看成横截面数据集。</p>
<p><img src="https://s2.loli.net/2025/01/28/o84PSkNscrZ6IpH.png"
style="width:5.76806in;height:1.725in" /></p>
<h4 id="时间序列数据time-series-data">时间序列数据（time series
data）</h4>
<p>各个行/观测之间有相关关系，存在历史依赖性。</p>
<p>时间序列数据有两个重要的特征：</p>
<p>第一个特征基于以下事实：很少假设经济数据的观测能够独立于时间，也就是多数经济及其他时间序列都与其近期历史相关（通常是高度相关）。这也导致对时间序列数据的分析要比对横截面数据的分析更为困难。</p>
<p>第二个特征是数据搜集时的数据频率（data
frequency），最常见的频率是每天、每周、每月、每个季度和每年。需要注意的是，许多按周、月、季度报告的经济时间序列都表现出很强的季节类型。</p>
<h4 id="混合截面数据pooled-cross-sectional-data">混合截面数据（pooled
cross-sectional data）</h4>
<p>混合截面相当于在截面数据上增加了时间变量，它抽取了不同对象在不同时间点的数据，或者说将几个不同时间点的截面数据组合在一起。与时间序列最明显的区别在于，虽然它抽取了不同时间点的数据，但不同时间点对应了不同的观测对象，而不是对同一个观测对象纪录不同时间点的数据。如下图所示：</p>
<p><img src="https://s2.loli.net/2025/01/28/rvymJFPsEwNtM7G.png"
style="width:4.89908in;height:2.18412in" /></p>
<p>我们虽然抽取了1993和1995年的数据，但1993年的观测（1、2、3......250）与1995年的观测（251、252、253......520）是完全不同的，不构成历史依赖性，因此不是时间序列数据。</p>
<h4 id="面板数据panel-data又称纵列数据">面板数据（panel
data，又称纵列数据）</h4>
<p>面板数据相当于将一些时间序列数据组合起来，不仅有不同的观测的数据，也有统一观测在不同时间点的数据，如下图：</p>
<p><img src="https://s2.loli.net/2025/01/28/O196M2sUmnRwHgz.png"
style="width:5.76806in;height:2.33681in" /></p>
<p>我们研究的对象是城市（city），图表中有1、2、3......150个城市的观测对象，并且对于每一个城市都收集了其1986年和1990年不同时间点的数据。因此这是一个面板数据。通过面板数据能够研究横向上（不同观测）的区别和纵向上（不同时间）的演变，是计量经济学家最喜欢、最常用的数据结构。</p>
<h2 id="计量经济学最关心什么">计量经济学最关心什么</h2>
<p>探讨因果关系！也可以说是因果效应（causal effect）</p>
<p>在探讨因果关系时最麻烦也是最重要的是众多的<u>混淆因素</u>。</p>
<p><strong>例子1：肥料对作物收成的影响？</strong></p>
<p>除了肥料以外，收成还会受土壤、阳光、降水等因素（混淆因素）。</p>
<p>因此，解决这个问题的方法是，每一块地在选择肥料量的时候，这个选择要独立于影响收成的其他土地因素。也就是随机选，使用随机选最有可能平均掉其余的混淆因素，不让研究产生系统性差异。</p>
<p><strong>例子2：教育真的有用嘛？（劳动经济学的经典问题）</strong></p>
<p>生活中普通人发现更好的学历的人大多都获得了更好的工作，也就是眼见为实，这是观测数据还是实验数据呢？观测数据！<mark>观测数据让我们看到的是表象，也就是让我们更多看到相关关系</mark>！</p>
<p>通过一般观测，我们能在在高学历和高工资之间划上相关关系，但不能划上因果关系，因为有可能是第三方因素（家庭经济条件、社会资源、学习能力等）导致了高学历和高工资。</p>
<h1 id="第2章-简单回归模型">第2章 简单回归模型</h1>
<p>问题一：既然两个变量之间没有精确关系，那么如何考虑自变量<span
class="math inline">\(X\)</span>以外其他影响因变量<span
class="math inline">\(Y\)</span>的因素呢？引入误差项<span
class="math inline">\(u\)</span></p>
<p>问题二：如何选择函数来表征自变量<span
class="math inline">\(X\)</span>和因变量<span
class="math inline">\(Y\)</span>的关系呢？线性形式是一种基础且重要的形式。</p>
<p>问题三：通过什么确定"在其他条件不变"的情况下因变量<span
class="math inline">\(Y\)</span>和自变量<span
class="math inline">\(X\)</span>关系呢？通过合理的假设。</p>
<h2 id="线性回归模型概念">线性回归模型概念</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV13z4y1j7x3/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第二章（1）吃透线性回归模型_哔哩哔哩_bilibili</a></p>
<p>一幅图：条件均值</p>
<p>三大要点：线性回归的形式、内涵、假设</p>
<p>七个概念：自变量、因变量、截距参数、斜率参数、均值独立、零条件均值、总体回归函数</p>
<h3 id="形式和内涵">形式和内涵</h3>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x +
u\]</span></p>
<p>其中，<span
class="math inline">\(y\)</span>是因变量，也称作被解释变量、响应变量、被预测变量、回归子；<span
class="math inline">\(x\)</span>是自变量，也称作解释变量、控制变量、预测变量、回归元、协变量；<span
class="math inline">\(\beta_{0}\)</span>是截距参数；<span
class="math inline">\(\beta_{1}\)</span>是斜率参数，<span
class="math inline">\(\beta_{0}\)</span>和<span
class="math inline">\(\beta_{1}\)</span>是估计的重点；<span
class="math inline">\(u\)</span>是误差项，也称作干扰项、未观测项。</p>
<p><span
class="math inline">\(\beta_{0}\)</span>：当x取值为0时，y的平均取值（常数项）</p>
<p><span class="math inline">\(\beta_{1}\)</span>：斜率，保持<span
class="math inline">\(u\)</span>不变，<span
class="math inline">\(y\)</span>变化量与<span
class="math inline">\(x\)</span>变化量的比值。</p>
<p>线性：影响效应不变，即无论<span
class="math inline">\(x\)</span>初始值为多少，<span
class="math inline">\(x\)</span>每一单位的变化对<span
class="math inline">\(y\)</span>的影响都是相同的。</p>
<h3 id="假设">假设</h3>
<p>线性回归需要满足对误差项<span
class="math inline">\(u\)</span>的零条件均值假设，</p>
<p>在线性归回模型设计的过程中，我们既要忽略其他因素<span
class="math inline">\(u\)</span>，又要控制其他因素<span
class="math inline">\(u\)</span>（也就是<span
class="math inline">\(\mathrm{\Delta}u = 0\)</span>，当自变量<span
class="math inline">\(x\)</span>变化的时候，<span
class="math inline">\(u\)</span>不能变），这就需要我们对误差项<span
class="math inline">\(u\)</span>设定一些统计上的假设，即零条件均值假设：</p>
<p><span class="math display">\[E\left( u \middle| x \right) = 0\left\{
\begin{array}{r}
E\left. （u \right.） = 0 \\
E\left( u \middle| x \right) = E(u)
\end{array} \right.\ \]</span></p>
<p>其中，<span class="math inline">\(E\left. （u \right.） =
0\)</span>只是要求<span
class="math inline">\(u\)</span>的平均值为0，这是一个弱假设，因为即使<span
class="math inline">\(u\)</span>的平均值不是0（假使能观察到），也可以通过常数项<span
class="math inline">\(\beta_{0}\)</span>将其吸收过去弥补为0（书上有相关证明题）；而<span
class="math inline">\(E\left( u \middle| x \right) =
E(u)\)</span>则保证在<span class="math inline">\(x\)</span>变化时，<span
class="math inline">\(u\)</span>不随之而改变，具体来说：</p>
<p>当<span class="math inline">\(x\)</span>变化时，<span
class="math inline">\(u\)</span>不随之而改变，换言之<span
class="math inline">\(u\)</span>与<span
class="math inline">\(x\)</span>不相关。那么如何测度两个变量之间的相关性呢？一是考虑使用皮尔逊相关系数</p>
<p>皮尔逊相关系数<span
class="math inline">\(\rho_{xy}\)</span>由协方差<span
class="math inline">\(Cov(x，y)\)</span>（可以为负数）和标准差<span
class="math inline">\(\sigma_{x}{、\sigma}_{y}\)</span>计算得出，取值在-1到1之间，越接近0越不相关，计算公式如下。</p>
<p><span class="math display">\[\rho_{xy} =
\frac{Cov(x，y)}{\sigma_{x}\sigma_{y} }\]</span></p>
<p><span class="math display">\[Cov(x，y) = \frac{\sum_{i =
1}^{N}{(x_{i} - \mu_{x})(y_{i} - \mu_{y})} }{N}\]</span></p>
<p><span class="math display">\[\sigma^{2} = \frac{\sum_{i =
1}^{N}{(x_{i} - \mu)}^{2} }{N}\]</span></p>
<p>皮尔逊相关系数只能衡量<span class="math inline">\(x\)</span>和<span
class="math inline">\(y\)</span>的线性相关，不能衡量非线性关系（比如<span
class="math inline">\(x\)</span>和<span
class="math inline">\(x^{2}\)</span>，两者明显有相关关系，在<span
class="math inline">\(x &lt; 0\)</span>时两者时负相关，在<span
class="math inline">\(x &gt;
0\)</span>时两者是正相关，但如果计算它们两组数据的皮尔逊相关系数很可能为0）。因此，在这里我们不能使用皮尔逊相关系数来衡量线性回归模型中自变量<span
class="math inline">\(x\)</span>和误差项<span
class="math inline">\(u\)</span>之间的关联，所以学者们通过<mark>条件期望</mark><span
class="math inline">\(E(Y|X = x)\)</span>进行衡量。</p>
<p>在求期望时，对应于一个随机变量<span
class="math inline">\(X\)</span>会有一个分布（不同取值下的概率值），就能求出一个基本在中间位置的期望。条件分布是指对于二维随机变量(X，Y)，可以考虑在其中一个随机变量取得(可能的)固定值的条件下，另一随机变量的概率分布，对条件分布算期望就是条件期望。如下图，是教育年限和工作的关系，在<span
class="math inline">\(X =
4\)</span>时有一组数据，这组数据有一个分布，就是条件分布。</p>
<p><img src="https://s2.loli.net/2025/01/28/soLFXCu8rMijBGb.png"
style="width:4.5625in;height:3.04274in" /></p>
<p>因此回到零条件均值假设：</p>
<p><span class="math display">\[E\left( u \middle| x \right) = 0\left\{
\begin{array}{r}
E\left. （u \right.） = 0 \\
E\left( u \middle| x \right) = E(u)
\end{array} \right.\ \]</span></p>
<p>其中，<span class="math inline">\(E\left( u \middle| x \right) = E(u)
= 0\)</span>指的是<span class="math inline">\(u\)</span>的期望与<span
class="math inline">\(x\)</span>的取值无关，<span
class="math inline">\(u\)</span>与<span
class="math inline">\(x\)</span>不相关（<span
class="math inline">\(cov(u,x) = 0\)</span>）。证明过程如下：</p>
<p><span class="math display">\[E(ux) = E\left( E\left( ux \middle| x
\right) \right) = E\left( xE\left( u \middle| x \right) \right) =
0\]</span></p>
<p><span class="math display">\[E(u)E(x) = E\left( E\left( u \middle| x
\right) \right)E(x) = 0\]</span></p>
<p>因此：</p>
<p><span class="math display">\[cov(u,x) = E(ux) - E(u)E(x) =
0\]</span></p>
<p>以工资与教育程度为例：</p>
<p><span class="math display">\[wage = \beta_{0} + \beta_{1}educ +
u\]</span></p>
<p>其中，<span class="math inline">\(wage\)</span>是工资，<span
class="math inline">\(educ\)</span>是受教育程度，<span
class="math inline">\(u\)</span>是误差项（包含其余影响<span
class="math inline">\(wage\)</span>却又与<span
class="math inline">\(educ\)</span>无关的因素），在这里我们假设是"能力"。那么，<u>零条件均值假设</u>则需要保证无论是初中学历的那一批人，还是大学学历的那一批人，它们的平均能力都是相同的，即<span
class="math inline">\(E\left( wage \middle| educ = 初中 \right) =
E\left( wage \middle| educ = 大学
\right)\)</span>。如果不满足这个条件<span
class="math inline">\(u\)</span>和<span
class="math inline">\(educ\)</span>有关了，那么就是出现了"<mark>内生性</mark>"问题。</p>
<h3 id="总体回归函数">总体回归函数</h3>
<p>对原始线性回归函数进行推导（对于给定的x，就可以把x看成常数，常数的期望是他本身）：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x +
u\]</span></p>
<p><span class="math display">\[E\left( y \middle| x \right) = E\left(
\beta_{0} + \beta_{1}x + u \right) = \beta_{0} + \beta_{1}x + E\left( u
\middle| x \right) = \beta_{0} + \beta_{1}x\]</span></p>
<p>这个就是总体回归函数（PRF），从中可以得出：</p>
<p>①<span
class="math inline">\(X\)</span>每变动一个单位，Y的条件期望值变动<span
class="math inline">\(\beta_{1}\)</span>个单位</p>
<p>②<span class="math inline">\(\beta_{0} +
\beta_{1}x\)</span>可以称作模型的系统部分，<span
class="math inline">\(u\)</span>称作模型的非系统部分，系统部分决定了模型对<span
class="math inline">\(y\)</span>的解释程度。</p>
<p>如下图，对于给定的<span
class="math inline">\(X\)</span>会有一个关于<span
class="math inline">\(Y\)</span>的条件分布，对这个条件分布求期望，就是一个条件期望<span
class="math inline">\(E\left( y \middle| x_{i}
\right)\)</span>，将所有的条件期望连成线，就是总体回归函数<span
class="math inline">\(E\left( y \middle| x \right)\)</span>。</p>
<p><img src="https://s2.loli.net/2025/01/28/DQWba8k24m1fEd5.png"
style="width:2.87402in;height:2.33146in" /><img
src="https://s2.loli.net/2025/01/28/bgUQDjZzodhaXSq.png"
style="width:2.87402in;height:1.84272in" /></p>
<h2 id="参数估计">参数估计</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV13P411b7Dr/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第二章（2）:最小二乘估计_哔哩哔哩_bilibili</a></p>
<h3 id="最小二乘估计ols">最小二乘估计（OLS）</h3>
<p>重要概念：残差，拟合值，OLS回归线（样本回归函数）</p>
<p>一些常用的算式推导基础，对于离差<span class="math inline">\(d_{i} =
x_{i} - \overline{x}\)</span>，则有：</p>
<p><span class="math display">\[\sum_{i = 1}^{n}d_{i} = 0\]</span></p>
<p><span class="math display">\[\sum_{i = 1}^{n}{ {d_{i} }^{2} = \sum_{i
= 1}^{n}{(x_{i} - \overline{x})}^{2} = \sum_{i = 1}^{n}{ {x_{i} }^{2} -
n{\overline{x} }^{2} } }\]</span></p>
<p><span class="math display">\[\sum_{i = 1}^{n}{(x_{i} -
\overline{x})(y_{i} - \overline{y}) = \sum_{i = 1}^{n}{x_{i}y_{i} -
n\overline{x}\overline{y} } } = \sum_{i = 1}^{n}{(x_{i} -
\overline{x})y_{i} } = \sum_{i = 1}^{n}{(y_{i} - \overline{y})x_{i}
}\]</span></p>
<p>假设，最后估计出来的线性回归函数为<span
class="math inline">\(\widehat{y} = \widehat{\beta_{0} } +
\widehat{\beta_{1} }x\)</span>，如下图所示。当给定<span
class="math inline">\(x_{i}\)</span>时，估计值<span
class="math inline">\(\widehat{y_{i} }\)</span>与实际值<span
class="math inline">\(y_{i}\)</span>的差值为残差（residual）<span
class="math inline">\(\widehat{u_{i} }\)</span>，则：</p>
<p><span class="math display">\[\widehat{u_{i} } = y_{i} -
\widehat{y_{i} } = y_{i} - \widehat{\beta_{0} } - \widehat{\beta_{1}
}x_{i}\]</span></p>
<p><img src="https://s2.loli.net/2025/01/28/DO7icwrsyUjPnl4.png"
style="width:5.3475in;height:3.6311in" /></p>
<p>因此，我们使用残差平方和作为我们的优化目标，去找<span
class="math inline">\(\widehat{\beta_{0} }\)</span>和<span
class="math inline">\(\widehat{\beta_{1} }\)</span>使得<span
class="math inline">\(\sum_{i = 1}^{n}{\widehat{u_{i} }
}^{2}\)</span>最小。这就是最小二乘估计法的思想。具体来说：</p>
<p><span class="math display">\[Q = \sum_{i = 1}^{n}{\widehat{u_{i} }
}^{2} = \sum_{i = 1}^{n}{ {(y}_{i} - \widehat{y_{i} })}^{2} = \sum_{i =
1}^{n}{ {(y}_{i} - \widehat{\beta_{0} } - \widehat{\beta_{1}
}x_{i})}^{2}\]</span></p>
<p>将<span class="math inline">\(\widehat{\beta_{0} }\)</span>和<span
class="math inline">\(\widehat{\beta_{1}
}\)</span>看成未知数，求它们为多少时，<span
class="math inline">\(Q\)</span>最小。对<span
class="math inline">\(\widehat{\beta_{0} }\)</span>和<span
class="math inline">\(\widehat{\beta_{1}
}\)</span>分别求偏导并满足都为0，求出驻点。</p>
<p>【计算过程】</p>
<p>最终算出<span class="math inline">\(\widehat{\beta_{1}
}\)</span>是<span class="math inline">\(x\)</span>和<span
class="math inline">\(y\)</span>的协方差除以<span
class="math inline">\(x\)</span>的方差</p>
<p><span class="math display">\[\widehat{\beta_{1} } = \frac{Cov(x，y)}{
{\sigma_{x} }^{2} } = \frac{\sum_{i = 1}^{N}{(x_{i} -
\overline{x})(y_{i} - \overline{y})} }{\sum_{i = 1}^{N}{(x_{i} -
\overline{x})}^{2} } = \frac{\sum_{i = 1}^{N}{x_{i}y_{i} } -
n\overline{x}\overline{y} }{\sum_{i = 1}^{n}{ {x_{i} }^{2} -
n{\overline{x} }^{2} } }\]</span></p>
<p><span class="math display">\[\widehat{\beta_{0} } = \overline{y} -
\widehat{\beta_{1} }\overline{x}\]</span></p>
<p>我们发现回归系数<span class="math inline">\(\widehat{\beta_{1}
}\)</span>与相关系数<span
class="math inline">\(\rho_{xy}\)</span>存在<mark>正比关系</mark>！由：</p>
<p><span class="math display">\[\rho_{xy} =
\frac{Cov(x，y)}{\sigma_{x}\sigma_{y} }\]</span></p>
<p>可得：</p>
<p><span class="math display">\[\widehat{\beta_{1} } = \frac{\sigma_{y}
}{\sigma_{x} }\rho_{xy}\]</span></p>
<p>★因此我们能够发现<span class="math inline">\(\widehat{\beta_{1}
}\)</span>肯定是反映了<span class="math inline">\(x\)</span>和<span
class="math inline">\(y\)</span>之间的<mark>相关关系</mark>，但究竟有没有进一步反映<mark>因果关系</mark>呢？需要进一步确定有没有其余不是<span
class="math inline">\(x\)</span>的因素对<span
class="math inline">\(y\)</span>有影响，也就是零条件均值假设是否成立，即<span
class="math inline">\(E\left( u \middle| x \right) = E(u) =
0\)</span>。</p>
<p>例子：受教育年限与工资</p>
<p><span class="math display">\[wage = \beta_{0} + \beta_{1}educ +
u\]</span></p>
<p>根据观测到的一系列<span class="math inline">\(x\)</span>和<span
class="math inline">\(y\)</span>的值我们估计出<span
class="math inline">\(\beta_{0}\)</span>和<span
class="math inline">\(\beta_{1}\)</span>，得到：</p>
<p><span class="math display">\[wage = - 0.90 + 0.54educ\]</span></p>
<p>其中：</p>
<p>①截距估计为负数，也就是受教育年限为0时，工资为负的，这是不符合实际的。其原因可能是数据集中没有<span
class="math inline">\((0,0)\)</span>样本。</p>
<p>②<span class="math inline">\(\beta_{1} =
0.54\)</span>说明多增加一年教育，小时工资增长54美分。但究竟是否能够做因果推断，即由于多增加一年教育，导致小时工资增长54美分，还需要考虑<span
class="math inline">\(E\left( u \middle| x \right) =
E(u)\)</span>是否成立。</p>
<p>★这个式子叫做OLS回归函数，也就是样本回归函数<span
class="math inline">\(\widehat{y} = \widehat{\beta_{0} } +
\widehat{\beta_{1} }x\)</span>。但我们真实想要估计的是总体回归函数<span
class="math inline">\(E\left( y \middle| x \right) = \beta_{0} +
\beta_{1}x\)</span>。但由于我们的数据是抽样数据，因此<span
class="math inline">\(\widehat{\beta_{0} }\)</span>和<span
class="math inline">\(\beta_{0}\)</span>，<span
class="math inline">\(\widehat{\beta_{1} }\)</span>和<span
class="math inline">\(\beta_{1}\)</span>会存在偏差。<u>换言之，随着随机抽样的样本数据的不同，</u><span
class="math inline">\(\widehat{\beta_{0} }\)</span><u>和</u><span
class="math inline">\(\widehat{\beta_{1}
}\)</span><u>是可变的，它们是随机变量</u>。</p>
<h3 id="矩估计">矩估计</h3>
<p>在书中也通过矩法方法对<span class="math inline">\(\widehat{\beta_{0}
}\)</span>和<span class="math inline">\(\widehat{\beta_{1}
}\)</span>进行估计。</p>
<p>在上面求偏导的过程中，对<span
class="math inline">\(\widehat{\beta_{1} }\)</span>求偏导有：<span
class="math inline">\(\sum_{i = 1}^{n}{\left( y_{i} - \widehat{\beta_{0}
} - \widehat{\beta_{1} }x_{i} \right) = 0}\)</span>，对<span
class="math inline">\(\widehat{\beta_{0} }\)</span>求偏导有：<span
class="math inline">\(\sum_{i = 1}^{n}{\left( y_{i} - \widehat{\beta_{0}
} - \widehat{\beta_{1} }x_{i} \right)x_{i} =
0}\)</span>，将两式的左边都乘上<span
class="math inline">\(\frac{1}{n}\)</span>，能够推导出：</p>
<p><span class="math display">\[E\left( \widehat{u_{i} } \right) =
0\]</span></p>
<p><span class="math display">\[E\left( \widehat{u_{i} }x_{i} \right) =
0\]</span></p>
<p>而残差<span class="math inline">\(\widehat{u_{i}
}\)</span>是误差<span
class="math inline">\(u\)</span>在样本中的体现，因此有：</p>
<p><span class="math display">\[E(u) = 0\]</span></p>
<p><span class="math display">\[E(ux) = 0\]</span></p>
<p>所以<span class="math inline">\(E(ux) - E(u)E(x) =
0\)</span>，即<span class="math inline">\(Cov(u,x) =
0\)</span>（根据协方差的定义进行推导，其中<span
class="math inline">\(E(x)\)</span>和<span
class="math inline">\(E(u)\)</span>看成常数）。而在零条件均值假设中，有<span
class="math inline">\(E\left( u \middle| x \right) =
E(u)\)</span>，其内涵是<span class="math inline">\(x\)</span>和<span
class="math inline">\(u\)</span>是不相关的，它们的相关系数应该为0，所以也有<span
class="math inline">\(Cov(u,x) = 0\)</span>。</p>
<p>所以可以通过假设条件<span class="math inline">\(E\left( u \middle| x
\right) = E(u)\)</span>和<span class="math inline">\(E(u) =
0\)</span>推导出<span class="math inline">\(Cov(u,x) =
0\)</span>，进而去估计<span class="math inline">\(\widehat{\beta_{0}
}\)</span>和<span class="math inline">\(\widehat{\beta_{1}
}\)</span>。这种方法我们叫做矩估计。</p>
<p>[]或者，也可以根据期望迭代法则<span class="math inline">\(E\left(
E\left( Y \middle| X \right) \right) = E(Y)\)</span>，那么<span
class="math inline">\(E(u) = E\left( E\left( u \middle| x \right)
\right) = 0\)</span>,<span class="math inline">\(E(ux) = E\left( E\left(
ux \middle| x \right) \right) = E\left( xE\left( u \middle| x \right)
\right) = 0\)</span>，所以<span class="math inline">\(Cov(u,x) = E(ux) -
E(u)E(x) = 0\)</span>。因此零条件均值假设比<span
class="math inline">\(Cov(u,x)\)</span>更强。</p>
<h2
id="期望方差协方差的一些公式变换性质">期望、方差、协方差的一些公式变换性质</h2>
<p><span class="math display">\[E(c) = c\]</span></p>
<p><span class="math display">\[E(kX) = kE(X)\]</span></p>
<p><span class="math display">\[E(X + Y) = E(X) + E(Y)\]</span></p>
<p><span class="math display">\[E(aX + bY) = aE(X) + bE(Y)\]</span></p>
<p><span class="math display">\[若X,Y相互独立，E\left. （XY \right.） =
E(X)E(Y)\]</span></p>
<p><span class="math display">\[D(X) = E{(X - E(X))}^{2} = E\left( X^{2}
\right) - {E(X)}^{2}\]</span></p>
<p><span class="math display">\[D(kX) = k^{2}D(X)\]</span></p>
<p><span class="math display">\[若X,Y相互独立,\ D(ax + bY) = a^{2}D(X) +
b^{2}D(Y)\]</span></p>
<p><span class="math display">\[D(X + Y) = D(X) + D(Y) +
2Cov(X，Y)\]</span></p>
<p><span class="math display">\[D(X - Y) = D(X) + D(Y) -
2Cov(X，Y)\]</span></p>
<p><span class="math display">\[Cov(X,Y) = E\lbrack\left( X - E(X)
\right)\left( Y - E(Y) \right)\rbrack = E(XY) - E(X)E(Y)\]</span></p>
<p><span class="math display">\[Cov(X,Y) = Cov(Y,X)\]</span></p>
<p><span class="math display">\[Cov(aX，bY) = abCov(X，Y)\]</span></p>
<p><span class="math display">\[Cov\left( X_{1} + X_{2},Y \right) =
E\left( X_{1}Y \right) + E\left( X_{2}Y \right) - E\left( X_{1}
\right)E(Y) - E\left( X_{2} \right)E(Y) = Cov(X_{1},Y) +
Cov(X_{2},Y)\]</span></p>
<p><span class="math display">\[Cov\left( X_{1} - X_{2},Y \right) =
E\left( X_{1}Y \right) - E\left( X_{2}Y \right) - E\left( X_{1}
\right)E(Y) + E\left( X_{2} \right)E(Y) = Cov\left( X_{1},Y \right) -
Cov(X_{2},Y)\]</span></p>
<p><span class="math display">\[Cov(X + a,Y + b) =
Cov(X，Y)\]</span></p>
<p><span class="math display">\[Cov(X，X) = D(X)\]</span></p>
<h2 id="参数估计的数学性质">参数估计的数学性质</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Au4y1r7ME/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第二章（3）弹性与拟合优度：参数估计的数学性质_哔哩哔哩_bilibili</a></p>
<h3
id="最小二乘估计的数学性质某一具体样本的数学性质即widehatmathbfbeta_mathbf0-和widehatmathbfbeta_mathbf1-是固定的">最小二乘估计的数学性质（某一具体样本的数学性质，即<span
class="math inline">\(\widehat{\mathbf{\beta}_{\mathbf{0} }
}\)</span>和<span
class="math inline">\(\widehat{\mathbf{\beta}_{\mathbf{1} }
}\)</span>是固定的）</h3>
<p>由上节可知：</p>
<p><span class="math display">\[\widehat{\beta_{1} } = \frac{Cov(x，y)}{
{\sigma_{x} }^{2} } = \frac{\sum_{i = 1}^{N}{(x_{i} -
\overline{x})(y_{i} - \overline{y})} }{\sum_{i = 1}^{N}{(x_{i} -
\overline{x})}^{2} } = \frac{\sum_{i = 1}^{N}{x_{i}y_{i} } -
n\overline{x}\overline{y} }{\sum_{i = 1}^{n}{ {x_{i} }^{2} -
n{\overline{x} }^{2} } }\]</span></p>
<p><span class="math display">\[\widehat{\beta_{0} } = \overline{y} -
\widehat{\beta_{1} }\overline{x}\]</span></p>
<p><span class="math display">\[\widehat{u_{i} } = y_{i} -
\widehat{y_{i} } = y_{i} - \widehat{\beta_{0} } - \widehat{\beta_{1}
}x_{i}\]</span></p>
<p>那么有如下<strong><mark>性质一</mark></strong>（这是对<span
class="math inline">\(\widehat{\beta_{0} }\)</span>求一阶偏导，<span
class="math inline">\(x_{i}\)</span>不存在估计值<span
class="math inline">\(\widehat{x_{i} }\)</span>或者说<span
class="math inline">\(x_{i}\)</span>与<span
class="math inline">\(\widehat{x_{i} }\)</span>是相同的）：</p>
<p><span class="math display">\[\sum_{i = 1}^{n}\widehat{u_{i} } =
\sum_{i = 1}^{n}{ {(y}_{i} - \widehat{y_{i} } }) = \sum_{i = 1}^{n}{
{(y}_{i} - \widehat{\beta_{0} } - \widehat{\beta_{1} }x_{i})} =
0\]</span></p>
<p>进一步在等式两边乘以<span
class="math inline">\(\frac{1}{n}\)</span>则有:</p>
<p><span class="math display">\[\overline{y_{i} } -
\overline{\widehat{y_{i} } } = 0,即\overline{y_{i} } =
\overline{\widehat{y_{i} } }\]</span></p>
<p><strong><mark>性质二</mark></strong>（这是对<span
class="math inline">\(\widehat{\beta_{1} }\)</span>求一阶偏导）：</p>
<p><span class="math display">\[\sum_{i = 1}^{n}{x_{i}\widehat{u_{i} } }
= 0\]</span></p>
<p>进一步推导：</p>
<p><span class="math display">\[\sum_{i = 1}^{n}{\widehat{y_{i}
}\widehat{u_{i} } } = \sum_{i = 1}^{n}{\left( \widehat{\beta_{0} } +
\widehat{\beta_{1} }x_{i} \right)\widehat{u_{i} } } = 0\]</span></p>
<p><strong><mark>性质三</mark></strong>（<span
class="math inline">\((x,y)\)</span>也在样本回归线上）：</p>
<p>根据性质一，有<span class="math inline">\(\frac{1}{n}\sum_{i =
1}^{n}{ {(y}_{i} - \widehat{\beta_{0} } - \widehat{\beta_{1} }x_{i})} =
0\)</span>，则<span class="math inline">\(\frac{1}{n}\sum_{i =
1}^{n}y_{i} = \frac{1}{n}\sum_{i = 1}^{n}{(\widehat{\beta_{0} } +
\widehat{\beta_{1} }x_{i})}\)</span></p>
<p><span class="math display">\[\overline{y} = \widehat{\beta_{0} } +
\widehat{\beta_{1} }\overline{x}\]</span></p>
<h3 id="方差分解sstssessr">方差分解：SST/SSE/SSR</h3>
<p>SST（total sum of squares，总平方和）；SSE（explained sum of
squares，解释平方和）；SSR（residual sum of
squares，残差平方和/剩余平方和）</p>
<p><img src="https://s2.loli.net/2025/01/28/DO7icwrsyUjPnl4.png"
style="width:4.78306in;height:3.24783in" /></p>
<p>有：</p>
<p><span class="math display">\[SST = \sum_{i = 1}^{n}{(y_{i} -
\overline{y_{i} })}^{2}\]</span></p>
<p><span class="math display">\[SSR = \sum_{i = 1}^{n}{\widehat{u_{i} }
}^{2} = \sum_{i = 1}^{n}{(y_{i} - \widehat{y_{i} })}^{2}\]</span></p>
<p><span class="math display">\[SSE = \sum_{i = 1}^{n}{(\widehat{y_{i} }
- \overline{\widehat{y_{i} } })}^{2} = \sum_{i = 1}^{n}{(\widehat{y_{i}
} - \overline{y_{i} })}^{2}\]</span></p>
<p>经过进一步变换：</p>
<p><span class="math display">\[SST = \sum_{i = 1}^{n}{(y_{i} -
\overline{y_{i} })}^{2} = \sum_{i = 1}^{n}{\lbrack\left( y_{i} -
\widehat{y_{i} } \right) + \left( \widehat{y_{i} } - \overline{y_{i} }
\right)\rbrack}^{2} = \sum_{i = 1}^{n}{(y_{i} - \widehat{y_{i} })}^{2} +
\sum_{i = 1}^{n}{(\widehat{y_{i} } - \overline{y_{i} })}^{2} + 2\sum_{i
= 1}^{n}{\lbrack\left( y_{i} - \widehat{y_{i} } \right)\left(
\widehat{y_{i} } - \overline{y_{i} } \right)\rbrack} = SSR + SSE +
2\sum_{i = 1}^{n}{\lbrack\widehat{u_{i} }\left( \widehat{y_{i} } -
\overline{y_{i} } \right)\rbrack} = SSR + SSE + 2\sum_{i =
1}^{n}{\widehat{u_{i} }\widehat{y_{i} } } - 2\overline{y_{i} }\sum_{i =
1}^{n}\widehat{u_{i} } = SSR + SSE\]</span></p>
<p>拟合优度（<span
class="math inline">\(R^{2}\)</span>）度量自变量对因变量的解释力，是模型可以解释的波动（<span
class="math inline">\(SSE\)</span>）除以了总体的波动（<span
class="math inline">\(SST\)</span>）：</p>
<p><span class="math display">\[R^{2} = \frac{SSE}{SST} = \frac{SSE}{SSE
+ SSR} = 1 - \frac{SSR}{SST}\]</span></p>
<p>关于<span class="math inline">\(R^{2}\)</span>有：</p>
<p>①值域在[0,1]；②<span
class="math inline">\(R^{2}\)</span>很小，只能说明选择的自变量<span
class="math inline">\(x\)</span>对因变量<span
class="math inline">\(y\)</span>的波动解释能力不强，不代表前面的估计不准确❓。</p>
<p>例子：CEO的薪水和股本回报率</p>
<p><span class="math display">\[\widehat{salary} = 963.191 +
18.501roe\]</span></p>
<p><span class="math display">\[n = 209,R^{2} = 0.0132\]</span></p>
<p>其中<span
class="math inline">\(R^{2}\)</span>说明回归能够解释薪水1.3%的变动，这也与实际相符合，因为影响CEO薪水的因素太多了，股本回报率只是其中很小的一部分。</p>
<p>例子：竞选指出和投票结果</p>
<p><span class="math display">\[\widehat{voteA} = 26.81 +
0.464shareA\]</span></p>
<p><span class="math display">\[n = 173,R^{2} = 0.856\]</span></p>
<p>其中<span
class="math inline">\(R^{2}\)</span>说明回归能够解释投票结果85.6%的变动。</p>
<h3 id="量纲变换">量纲变换</h3>
<p>有原始模型和样本回归函数（OLS回归函数）如下：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x +
u\]</span></p>
<p><span class="math display">\[\widehat{y} = \widehat{\beta_{0} } +
\widehat{\beta_{1} }x\]</span></p>
<p>当因变量扩散100倍为<span
class="math inline">\(\widetilde{y}\)</span>时：</p>
<p><span class="math display">\[\widetilde{y} = 100y = {100\beta}_{0} +
{100\beta}_{1}x + 100u\]</span></p>
<p>所以此时：</p>
<p><span class="math display">\[\widetilde{\beta_{0} } =
100\widehat{\beta_{0} }\]</span></p>
<p><span class="math display">\[\widetilde{\beta_{1} } =
100\widehat{\beta_{1} }\]</span></p>
<p>当自变量扩大100倍为<span
class="math inline">\(\widetilde{x}\)</span>时：</p>
<p><span class="math display">\[y = \beta_{0} + \frac{\beta_{1}
}{100}\widetilde{x} + u\]</span></p>
<p>所以此时：</p>
<p><span class="math display">\[\widetilde{\beta_{0} } =
\widehat{\beta_{0} }\]</span></p>
<p><span class="math display">\[\widetilde{\beta_{1} } =
\frac{\widehat{\beta_{1} } }{100}\]</span></p>
<h3 id="非线性变换和弹性">非线性变换和弹性</h3>
<p><span class="math display">\[100\mathrm{\Delta}\log\left( x_{0}
\right) \approx \%\mathrm{\Delta}x\]</span></p>
<p>也就是，从<span class="math inline">\(x_{0}\)</span>变换到<span
class="math inline">\(x_{1}\)</span>（<span
class="math inline">\(\mathrm{\Delta}x = \mathrm{\Delta}x_{1} -
\mathrm{\Delta}x_{0}\)</span>，但<span
class="math inline">\(\%\mathrm{\Delta}x = 100*\frac{x_{1} - x_{0}
}{x_{0} } = 100*\frac{\mathrm{\Delta}x}{x_{0} } \neq
100*\mathrm{\Delta}x\)</span>）：</p>
<p><span class="math display">\[100\left( \log\left( x_{1} \right) -
\log\left( x_{0} \right) \right) \approx 100*\frac{x_{1} - x_{0} }{x_{0}
}\]</span></p>
<p>证明上述，需要使用泰勒公式：</p>
<p>设<span class="math inline">\(f(x)\)</span>在<span
class="math inline">\(x_{0}\)</span>处有<span
class="math inline">\(n\)</span>阶导数，则有公式：</p>
<p><span class="math display">\[f(x) = f\left( x_{0} \right) +
\frac{f^{&#39;}\left( x_{0} \right)}{1!}\left( x - x_{0} \right) +
\frac{f^{&#39;}&#39;\left( x_{0} \right)}{2!}\left( x - x_{0}
\right)^{2} + \ldots + \frac{f^{(n)}\left( x_{0} \right)}{n!}\left( x -
x_{0} \right)^{n} + o\lbrack(\left( x - x_{0}
\right)^{n})\rbrack\]</span></p>
<p>最后一项为误差，泰勒公式说明任意一个函数都能以幂函数的形式近似表示出来。因此我们取<span
class="math inline">\(f(x) = log(x)\)</span>（这里的<span
class="math inline">\(\log(x)\)</span>也就是<span
class="math inline">\(ln(x)\)</span>），则：</p>
<p><span class="math display">\[\log(x) \approx \log\left( x_{0} \right)
+ \frac{x - x_{0} }{x_{0} }\]</span></p>
<p>所以：</p>
<p><span class="math display">\[100\left( \log\left( x_{1} \right) -
\log\left( x_{0} \right) \right) \approx 100*\frac{x_{1} - x_{0} }{x_{0}
}，即100\mathrm{\Delta}\log\left( x_{0} \right) \approx
\%\mathrm{\Delta}x\]</span></p>
<h4 id="常弹性模型">常弹性模型</h4>
<p>对于<mark><u>常弹性模型</u></mark>：</p>
<p><span class="math display">\[\log(y) = \beta_{0} + \beta_{1}log(x) +
u\]</span></p>
<p>有：</p>
<p><span class="math display">\[\widehat{\beta_{1} } =
\frac{\mathrm{\Delta}\log(y)}{\mathrm{\Delta}log(x)} =
\frac{100\mathrm{\Delta}\log(y)}{100\mathrm{\Delta}log(x)} =
\frac{\%\mathrm{\Delta}y}{\%\mathrm{\Delta}x}\]</span></p>
<p>也就是，当<span class="math inline">\(x\)</span>变动原来的1%时，<span
class="math inline">\(y\)</span>变动原来的<span
class="math inline">\(\beta_{1}\%\)</span>。（"<span
class="math inline">\(x\)</span>变动为原来的多少"指的就是<span
class="math inline">\(\frac{x_{1} - x_{0} }{x_{0}
}\)</span>为多少，"<span
class="math inline">\(x\)</span>变动多少个单位"指的是<span
class="math inline">\(\mathrm{\Delta}x = \mathrm{\Delta}x_{1} -
\mathrm{\Delta}x_{0}\)</span>是多少）</p>
<h4 id="半弹性模型">半弹性模型</h4>
<p>对于<mark>半弹性模型</mark>：</p>
<p><span class="math display">\[\log(y) = \beta_{0} + \beta_{1}x +
u\]</span></p>
<p>有：</p>
<p><span class="math display">\[\widehat{\beta_{1} } =
\frac{\mathrm{\Delta}\log(y)}{\mathrm{\Delta}x} =
\frac{100\mathrm{\Delta}\log(y)}{100\mathrm{\Delta}x} =
\frac{\%\mathrm{\Delta}y}{100\mathrm{\Delta}x}\]</span></p>
<p><span class="math display">\[100\beta_{1} =
\frac{\%\mathrm{\Delta}y}{\mathrm{\Delta}x}\]</span></p>
<p>也就是，当<span class="math inline">\(x\)</span>变动1个单位时，<span
class="math inline">\(y\)</span>变动原来的100<span
class="math inline">\(\beta_{1}\%\)</span>。</p>
<p>例子：教育和工资（我们知道教育和工资一般不是线性增长的，而一般是随着教育的增加，工资增加的速度越来越快）</p>
<p><span class="math display">\[log(wage) = 0.584 + 0.083educ +
u\]</span></p>
<p>含义：每增加一年教育，工资提升8.3%。</p>
<p>对于<mark><u>第三类非线性公式</u></mark>：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}log(x) +
u\]</span></p>
<p>有：</p>
<p><span class="math display">\[\widehat{\beta_{1} } =
\frac{\mathrm{\Delta}y}{\mathrm{\Delta}log(x)} =
\frac{100\mathrm{\Delta}y}{100\mathrm{\Delta}log(x)} =
\frac{100\mathrm{\Delta}y}{\%\mathrm{\Delta}x}\]</span></p>
<p>也就是，当x变动原来的1%，y变动量为<span
class="math inline">\(\frac{\widehat{\beta_{1} }
}{100}\)</span>个单位。</p>
<h2 id="参数估计的统计性质">参数估计的统计性质</h2>
<p>OLS估计（<span class="math inline">\(\widehat{\beta_{1}
}\)</span>和<span class="math inline">\(\widehat{\beta_{0}
}\)</span>）的随机性</p>
<p><mark>统计性质是指：参数估计量从总体中抽取不同随机样本时的分布性质。</mark></p>
<p>我们着重关注统计性质中的两种：</p>
<p><mark><u>①无偏性</u></mark>：平均来讲（从期望来看），估计值是否接近真值？</p>
<p><mark><u>②方差</u></mark>：不同样本所得到的参数估计值的波动程度。</p>
<h3 id="ols估计的无偏性">OLS估计的无偏性</h3>
<p>假设一：总体模型中，因变量<span
class="math inline">\(y\)</span>与自变量<span
class="math inline">\(x\)</span>和误差<span
class="math inline">\(u\)</span>的关系需满足<span
class="math inline">\(y = \beta_{0} + \beta_{1}x + u\)</span>;</p>
<p>假设二：具有一个服从总体模型的随机样本<span
class="math inline">\(\{\left( x_{i},y_{i} \right):i = 1,2\ldots
n\}\)</span>，具有总体的代表性。</p>
<p>假设三：<span
class="math inline">\(x\)</span>的样本结果不是完全相同的数值。也就是<span
class="math inline">\(x\)</span>的方差<span class="math inline">\(var(x)
= \frac{\sum_{i = 1}^{N}{(x_{i} - \overline{x})}^{2} }{N} \neq
0\)</span>，保证<span class="math inline">\(\widehat{\beta_{1} } =
\frac{Cov(x，y)}{ {\sigma_{x} }^{2} } = \frac{\sum_{i = 1}^{N}{(x_{i} -
\overline{x})(y_{i} - \overline{y})} }{\sum_{i = 1}^{N}{(x_{i} -
\overline{x})}^{2} }\)</span>有意义。</p>
<p>假设四：零条件均值假设<span class="math inline">\(E\left( u \middle|
x \right) = 0\)</span></p>
<p>要证明OLS估计的无偏性，就是要证明<span
class="math inline">\(E(\widehat{\beta_{1} }) =
\beta_{1}\)</span>，<span class="math inline">\(E\left(
\widehat{\beta_{0} } \right) = \beta_{0}\)</span>。</p>
<p>首先证明：<span class="math inline">\(E(\widehat{\beta_{1} }) =
\beta_{1}\)</span></p>
<p>已知：</p>
<p><span class="math display">\[y_{i} = \beta_{0} + \beta_{1}x_{i} +
u_{i}\]</span></p>
<p>所以</p>
<p><span class="math display">\[\widehat{\beta_{1} } = \frac{\sum_{i =
1}^{n}{\left( x_{i} - \overline{x} \right)\left( y_{i} - \overline{y}
\right)} }{\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2} } =
\frac{\sum_{i = 1}^{n}{\left( x_{i} - \overline{x} \right)\left( y_{i}
\right)} }{\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2} } =
\frac{\sum_{i = 1}^{n}{\left( x_{i} - \overline{x} \right)\left( y_{i}
\right)} }{\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2} } =
\frac{\sum_{i = 1}^{n}{\left( x_{i} - \overline{x} \right)\left(
\beta_{0} + \beta_{1}x_{i} + u_{i} \right)} }{\sum_{i = 1}^{n}\left(
x_{i} - \overline{x} \right)^{2} } = \frac{\beta_{0}\sum_{i =
1}^{n}{\left( x_{i} - \overline{x} \right) + \beta_{1}\sum_{i =
1}^{n}{\left( x_{i} - \overline{x} \right)x_{i} + \sum_{i =
1}^{n}{\left( x_{i} - \overline{x} \right)u_{i} } } } }{\sum_{i =
1}^{n}\left( x_{i} - \overline{x} \right)^{2} } = 0 + \beta_{1} +
\frac{\sum_{i = 1}^{n}{\left( x_{i} - \overline{x} \right)u_{i} }
}{\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2} } = \beta_{1}
+ \frac{1}{ {SST}_{x} }\sum_{i = 1}^{n}{(x_{i} - \overline{x})u_{i}
}\]</span></p>
<p>在此证明中，期望值都以自变量的样本值作为条件，也就是给定一组<span
class="math inline">\(x_{i}\)</span>，将<span
class="math inline">\(x_{i}\)</span>看成常数。所以有：</p>
<p><span class="math display">\[E\left( \widehat{\beta_{1} } \right) =
\beta_{1} + \frac{\sum_{i = 1}^{n}\left( x_{i} - \overline{x}
\right)}{\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2}
}E(u_{i})\]</span></p>
<p>又因为零条件均值假设<span class="math inline">\(E\left( u \middle| x
\right) = E(u) = 0\)</span></p>
<p>所以：</p>
<p><span class="math display">\[E\left( \widehat{\beta_{1} } \right) =
\beta_{1}\]</span></p>
<p>然后证明：<span class="math inline">\(E\left( \widehat{\beta_{0} }
\right) = \beta_{0}\)</span></p>
<p>已知：</p>
<p><span class="math display">\[y_{i} = \beta_{0} + \beta_{1}x_{i} +
u_{i}\]</span></p>
<p>所以：</p>
<p><span class="math display">\[\widehat{\beta_{0} } = \overline{y} -
\widehat{\beta_{1} }\overline{x} = \frac{1}{n}\sum_{i = 1}^{n}y_{i} -
\widehat{\beta_{1} }\overline{x} = \frac{1}{n}\sum_{i = 1}^{n}\left(
\beta_{0} + \beta_{1}x_{i} + u_{i} \right) - \widehat{\beta_{1}
}\overline{x} = \frac{1}{n}\sum_{i = 1}^{n}\beta_{0} +
\frac{1}{n}\beta_{1}\sum_{i = 1}^{n}x_{i} + \frac{1}{n}\sum_{i =
1}^{n}u_{i} - \widehat{\beta_{1} }\overline{x} = \beta_{0} +
\beta_{1}\overline{x} + \overline{u_{i} } - \widehat{\beta_{1}
}\overline{x} = \beta_{0} + \left( \beta_{1} - \widehat{\beta_{1} }
\right)\overline{x} + \overline{u_{i} }\]</span></p>
<p>那么（<span class="math inline">\(\beta_{1}\)</span>真值常数）：</p>
<p><span class="math display">\[E\left( \widehat{\beta_{0} } \right) =
\beta_{0} + \overline{x}E\left( \beta_{1} - \widehat{\beta_{1} } \right)
+ E\left( \overline{u_{i} } \right) = \beta_{0}\]</span></p>
<p>因此OLS估计（<span class="math inline">\(\widehat{\beta_{1}
},\widehat{\beta_{0} }\)</span>）是无偏的，<span
class="math inline">\(\widehat{\beta_{1} },\widehat{\beta_{0}
}\)</span>的平均值就是总体真实的<span
class="math inline">\(\beta_{1}\)</span>，<span
class="math inline">\(\beta_{0}\)</span>。</p>
<p>其中需要注意：</p>
<p>①四个假设条件全部成立，才能保证估计量是无偏的（线性于参数/随机抽样/<span
class="math inline">\(x\)</span>有方差/<span
class="math inline">\(u\)</span>和<span
class="math inline">\(x\)</span>无关）；</p>
<p>②估计量的无偏性只能保证所有估计量的均值是真值，但不能保证具体某一个的估计量是真值。</p>
<p>③知道<span
class="math inline">\(\beta\)</span>的抽样分布是以真值为中心，也需要了解预期的<span
class="math inline">\(\widehat{\beta}\)</span>距离<span
class="math inline">\(\beta\)</span>大致有多元也很重要，也就是了解估计的方差。</p>
<h3 id="ols估计的方差">OLS估计的方差</h3>
<p>在上节四个假设的基础上，还需要增加<mark><u>假设五</u></mark>：</p>
<p>给定解释变量的任何值，误差都具有相同的方差。</p>
<p><span class="math display">\[var\left( u \middle| x \right) =
\sigma^{2}\]</span></p>
<p>从中可以推理：</p>
<p>①<mark><u>推理一</u></mark>：</p>
<p><span class="math display">\[\sigma^{2} = E\left( u^{2} \middle| x
\right) - E^{2}\left( u \middle| x \right) = E\left( u^{2} \middle| x
\right)\]</span></p>
<p>所以（<span class="math inline">\(E\left( E\left( Y \middle| X
\right) \right) = E(Y)\)</span>）：</p>
<p><span class="math display">\[E\left( u^{2} \right) =
\sigma^{2}\]</span></p>
<p>那么：</p>
<p><span class="math display">\[var(u) = E\left( u^{2} \right) -
E^{2}(u) = \sigma^{2}\]</span></p>
<p>所以<span
class="math inline">\(\sigma^{2}\)</span>叫做误差方差，不再加<span
class="math inline">\(x\)</span>的条件。</p>
<p>②<mark><u>推理二</u></mark>：</p>
<p>已知：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x +
u\]</span></p>
<p>那么：</p>
<p><span class="math display">\[E\left( y \middle| x \right) = E\left(
\beta_{0} + \beta_{1}x + u \middle| x \right) = E\left( \beta_{0}
\middle| x \right) + E\left( \beta_{1}x \middle| x \right) + E\left( u
\middle| x \right) = \beta_{0} + \beta_{1}x\]</span></p>
<p><span class="math display">\[var\left( y \middle| x \right) =
var\left( \beta_{0} + \beta_{1}x + u \middle| x \right) = var\left( u|x
\right) = \sigma^{2}\]</span></p>
<p>所以在线性函数下，<span class="math inline">\(y\)</span>的期望与<span
class="math inline">\(x\)</span>有线性关系，<span
class="math inline">\(y\)</span>的方差是一个常数，如下图所示，方差是一个常数体现在小山峰的形状是一致的：</p>
<p><img src="https://s2.loli.net/2025/01/28/wrEGDcICYZHLf7N.png"
style="width:5.76806in;height:4.36458in" /></p>
<p>③<mark><u>推理三</u></mark>：</p>
<p>如果是异方差，即：<span class="math inline">\(var\left( u \middle| x
\right) = f(x)\)</span>，那么<span class="math inline">\(var\left( y
\middle| x \right) = f(x)\)</span></p>
<p>那么有了以上五个假设，又已知：</p>
<p><span class="math display">\[\widehat{\beta_{1} } = \beta_{1} +
\frac{\sum_{i = 1}^{n}{\left( x_{i} - \overline{x} \right)u_{i} }
}{\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2} } = \beta_{1}
+ \frac{1}{ {SST}_{x} }\sum_{i = 1}^{n}{(x_{i} - \overline{x})u_{i}
}\]</span></p>
<p>则（由于给定<span
class="math inline">\(x_{i}\)</span>，才有估计出<span
class="math inline">\(\widehat{\beta_{1} }\)</span>，因此<span
class="math inline">\(x_{i}\)</span>是非随机的，看成常数；此外误差<span
class="math inline">\(u_{i}\)</span>之间是独立的，因此合的方差就等于方差的和）：</p>
<p><span class="math display">\[var\left( \widehat{\beta_{1} } \right) =
\frac{1}{ { {SST}_{x} }^{2} }var\left( \sum_{i = 1}^{n}{(x_{i} -
\overline{x})u_{i} } \right) = \frac{1}{ { {SST}_{x} }^{2} }\sum_{i =
1}^{n}{var\left( (x_{i} - \overline{x})u_{i} \right)} = \frac{1}{ {
{SST}_{x} }^{2} }\sum_{i = 1}^{n}{ {(x_{i} - \overline{x})}^{2}var\left(
u_{i} \right)} = \frac{\sigma^{2} }{ {SST}_{X} }\]</span></p>
<p>因此，如果想要较好的估计出<span
class="math inline">\(\widehat{\beta_{1}
}\)</span>（不要有太大的波动），则需要增加<span
class="math inline">\({SST}_{X}\)</span>（通常通过扩大样本量实现），减小<span
class="math inline">\(\sigma^{2}\)</span>（让误差项不要有太大的波动）</p>
<p>【推导出<span class="math inline">\(var\left( \widehat{\beta_{0} }
\right)\)</span>】</p>
<p><span class="math display">\[var\left( \widehat{\beta_{0} } \right) =
\frac{\sigma^{2}n^{- 1}\sum_{i = 1}^{n}{x_{i} }^{2} }{ {SST}_{X} } =
\frac{\sigma^{2}\sum_{i = 1}^{n}{x_{i} }^{2} }{n\sum_{i = 1}^{n}{(x_{i}
- \overline{x})}^{2} }\]</span></p>
<p>接着，我们要能够估计出<span class="math inline">\(var\left(
\widehat{\beta_{1} } \right)\)</span>是多少，就需要估计<span
class="math inline">\(\sigma^{2}\)</span>，而：</p>
<p><span class="math display">\[var\left( u \middle| x \right) = var(u)
= E\left( u^{2} \right) = \sigma^{2}\]</span></p>
<p>即：</p>
<p><span class="math display">\[\frac{1}{n}\sum_{i = 1}^{n}{u_{i} }^{2}
= \sigma^{2}\]</span></p>
<p>但由于<span
class="math inline">\(u_{i}\)</span>是误差项，不可能计算得出，因此只能通过根据实际观测到的一组<span
class="math inline">\((x_{i},y_{i})\)</span>所计算出来的<span
class="math inline">\(\widehat{u_{i} }\)</span>来进行估计。</p>
<p>但根据OLS回归曲线的数学性质，我们有：</p>
<p><span class="math display">\[\sum_{i = 1}^{n}\widehat{u_{i} } =
0\]</span></p>
<p><span class="math display">\[\sum_{i = 1}^{n}{x_{i}\widehat{u_{i} } }
= 0\]</span></p>
<p>因此，<span class="math inline">\(\widehat{u_{i}
}\)</span>的自由度为<span class="math inline">\((n - 2)\)</span>，则</p>
<p><span class="math display">\[{\widehat{\sigma} }^{2} = \frac{1}{n -
2}\sum_{i = 1}^{n}{\widehat{u_{i} } }^{2}\]</span></p>
<p>证明过程如下：</p>
<p>【下次再算】</p>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1PT41147Kr/?spm_id_from=333.337.search-card.all.click&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">九讲搞定计量经济学第二讲10---误差项的无偏估计量的证明（一元回归模型）_哔哩哔哩_bilibili</a></p>
<p>那么，有了估计的<span
class="math inline">\(\widehat{\sigma}\)</span>，我们就可以来估计<span
class="math inline">\(\widehat{\beta_{1} }\)</span>的方差。</p>
<p>由于：</p>
<p><span class="math display">\[var\left( \widehat{\beta_{1} } \right) =
\frac{\sigma^{2} }{ {SST}_{X} }\]</span></p>
<p>那么<span class="math inline">\(\widehat{\beta_{1}
}\)</span>的标准误是：</p>
<p><span class="math display">\[se\left( \widehat{\beta_{1} } \right) =
\frac{\widehat{\sigma} }{\sqrt{ {SST}_{X} } }\]</span></p>
<p>其中需要注意，<span class="math inline">\(\widehat{\beta_{1}
}\)</span>的标准差（一般没啥用）是：</p>
<p><span class="math display">\[sd\left( \widehat{\beta_{1} } \right) =
\frac{\sigma}{\sqrt{ {SST}_{X} } }\]</span></p>
<p>对于<span class="math inline">\(\widehat{\beta_{0}
}\)</span>同理。</p>
<table style="width:99%;">
<colgroup>
<col style="width: 8%" />
<col style="width: 37%" />
<col style="width: 51%" />
</colgroup>
<tbody>
<tr>
<td rowspan="2">====== $ <span class="math inline">\(u\)</span>$</td>
<td rowspan="2"><h1 id="公式">公式</h1>
<p>假设五：<span class="math inline">\(var\left( u \midd
le| x \right) = \sigma^{2}\)</span></p></td>
<td rowspan="2">估计 | =================================+ <span
class="math display">\[\frac{\sum_{i =               |
1}^{n}{\widehat{u_{i} } }^{2} }{n  |
- 2} = {\widehat{\sigma} }^{2}\]</span> |</td>
</tr>
<tr>
</tr>
<tr>
<td>$ <span class="math inline">\(\be
ta\)</span>$</td>
<td colspan="2"><span class="math display">\[var\left( \wideh          |
\]</span>se( ) = <span class="math display">\[
                            |                                 |
\]</span>var( ) = $$ |</td>
</tr>
</tbody>
</table>
<h2 id="本章复习">本章复习</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1T94y1Y7Dt/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">教材精讲-《计量经济学导论.现代观点》】第二章（5）简单线性回归全章精要复习_哔哩哔哩_bilibili</a></p>
<h3 id="简单线性回归模型">简单线性回归模型</h3>
<p>①模型形式</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x +
u\]</span></p>
<p>②参数的含义</p>
<p><span class="math inline">\(\beta_{0}\)</span>指的是当<span
class="math inline">\(x\)</span>为0时，<span
class="math inline">\(y\)</span>的取值</p>
<p><span
class="math inline">\(\beta_{1}\)</span>指的是当其他因素不变时（<span
class="math inline">\(\mathrm{\Delta}u = 0\)</span>），<span
class="math inline">\(\frac{\mathrm{\Delta}y}{\mathrm{\Delta}x}\)</span>的大小</p>
<p>其中<span
class="math inline">\(u\)</span>指的是总体回归模型中的误差项，而在OLS回归中有一个通过<span
class="math inline">\(y_{i} - \widehat{y_{i}
}\)</span>计算出来的残差项<span class="math inline">\(\widehat{u_{i}
}\)</span>，并且能够推导出<span class="math inline">\(\sum_{i =
1}^{n}\widehat{u_{i} } = 0\)</span>。</p>
<p>③零条件均值假设</p>
<p>对于总体模型中的<span
class="math inline">\(u\)</span>，我们有如下假设</p>
<p><span class="math display">\[E\left( u \middle| x \right) = 0\left\{
\begin{array}{r}
E\left( u \middle| x \right) = E(u) \\
E(u) = 0
\end{array} \right.\ \]</span></p>
<h3 id="最小二乘估计">最小二乘估计</h3>
<p>我们已经有了总体回归模型，接下来需要收集数据，对模型的参数进行估计。</p>
<p>数据也是从总体中随机抽样而来，因此我们样本上的模型为：</p>
<p><span class="math display">\[y_{i} = \beta_{0} + \beta_{1}x_{i} +
u_{i}\]</span></p>
<p>其中残差<span class="math inline">\(\widehat{u_{i} } = y_{i} -
\widehat{y_{i} } = y_{i} - (\widehat{\beta_{0} } + \widehat{\beta_{1}
}x_{i})\)</span></p>
<p>为了估计出参数<span class="math inline">\(\beta_{0}\)</span>和<span
class="math inline">\(\beta_{1}\)</span>，我们需要最小化目标函数<span
class="math inline">\(Q = \sum_{}^{}\widehat{u_{i}
}\)</span>。最终我们估计出参数为：</p>
<p><span class="math display">\[\widehat{\beta_{1} } = \frac{cov\left(
x_{i},y_{i} \right)}{ {\sigma_{x} }^{2} } = \frac{\sum_{}^{}{\left(
x_{i} - \overline{x} \right)\left( y_{i} - \overline{y} \right)}
}{\sum_{}^{}\left( x_{i} - \overline{x} \right)^{2} } =
\frac{\sum_{}^{}{x_{i}y_{i} } - n\overline{x}\overline{y} }{\sum_{}^{}{
{x_{i} }^{2} -}n{\overline{x} }^{2} }\]</span></p>
<p><span class="math display">\[\widehat{\beta_{0} } = \overline{y} -
\widehat{\beta_{1} }\overline{x}\]</span></p>
<h3 id="回归线">回归线</h3>
<p>①总体回归函数</p>
<p>当有<span class="math inline">\(E\left( u \middle| x \right) = E(u) =
0\)</span>和总体模型<span class="math inline">\(y = \beta_{0} +
\beta_{1}x + u\)</span>，我们有总体回归函数为：</p>
<p><span class="math display">\[E\left( y \middle| x \right) = \beta_{0}
+ \beta_{1}x\]</span></p>
<p>总体回归函数是我们最终想要估计出来的那条真实的回归线（但无法实现）。</p>
<p>②样本回归函数</p>
<p>如果我们得到了一组样本，就能估计出<span
class="math inline">\(\beta_{0}\)</span>和<span
class="math inline">\(\beta_{1}\)</span>，就有样本回归函数为：</p>
<p><span class="math display">\[\widehat{y} = \widehat{\beta_{0} } +
\widehat{\beta_{1} }x\]</span></p>
<p>因此随着样本抽取的不同，<span
class="math inline">\(\widehat{\beta_{0} }\)</span>和<span
class="math inline">\(\widehat{\beta_{1} }\)</span>是随机的。</p>
<h3 id="残差的数学性质">残差的数学性质</h3>
<p><span class="math display">\[\sum_{i = 1}^{n}\widehat{u_{i} } = 0
\rightarrow \overline{y} = \overline{\widehat{y} }\]</span></p>
<p><span class="math display">\[\sum_{i = 1}^{n}{x_{i}\widehat{u_{i} } }
= 0 \rightarrow \sum_{i = 1}^{n}{y_{i}\widehat{u_{i} } } =
0\]</span></p>
<p><span class="math display">\[\widehat{\beta_{0} } +
\widehat{\beta_{1} }\overline{x} = \overline{y}\]</span></p>
<h3 id="拟合优度">拟合优度</h3>
<p><span class="math display">\[SST = SSE + SSR\]</span></p>
<p><span class="math display">\[R^{2} = \frac{SSE}{SST} = 1 -
\frac{SSR}{SST}\]</span></p>
<h3 id="量纲变换-1">量纲变换</h3>
<p>如果<span class="math inline">\(y\)</span>*100，那么<span
class="math inline">\(\widehat{\beta_{0} }\)</span>和<span
class="math inline">\(\widehat{\beta_{1} }\)</span>也都扩大100倍；</p>
<p>如果<span class="math inline">\(x\)</span>*100，那么<span
class="math inline">\(\widehat{\beta_{0} }\)</span>不变，<span
class="math inline">\(\widehat{\beta_{1} }\)</span>缩小100倍。</p>
<h3 id="函数变换非线性和弹性">函数变换（非线性和弹性）</h3>
<p>基础公式：</p>
<p><span class="math display">\[100\mathrm{\Delta}\log(x) =
\%\mathrm{\Delta}x\]</span></p>
<p><span class="math display">\[log(y) = \beta_{0} + \beta_{1}log(x) +
u\]</span></p>
<p>解释：当<span class="math inline">\(x\)</span>变动原来的1%，<span
class="math inline">\(y\)</span>变为原来的<span
class="math inline">\(\beta_{1}\%\)</span></p>
<p><span class="math display">\[log(y) = \beta_{0} + \beta_{1}x +
u\]</span></p>
<p>解释：当<span class="math inline">\(x\)</span>变动1个单元，<span
class="math inline">\(y\)</span>变为原来的<span
class="math inline">\({100\beta}_{1}\%\)</span></p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}log(x) +
u\]</span></p>
<p>解释：当<span class="math inline">\(x\)</span>变动原来的1%，<span
class="math inline">\(y\)</span>变动<span
class="math inline">\(\frac{\beta_{1} }{100}\)</span>个单位。</p>
<h3 id="参数期望">参数期望</h3>
<p>研究参数期望的目的是，想要知道，当我们有无数组样本时，我们所估计出来的<span
class="math inline">\(\widehat{\beta_{0} }\)</span>和<span
class="math inline">\(\widehat{\beta_{1} }\)</span>有多接近真实的<span
class="math inline">\(\beta_{0}\)</span>和<span
class="math inline">\(\beta_{1}\)</span>。</p>
<p>①基本假设：</p>
<p>·参数是线性的；</p>
<p>·样本数据是随机抽样的，只有这样我们才能复刻设置的总体模型<span
class="math inline">\(y = \beta_{0} + \beta_{1}x +
u\)</span>到样本模型中<span class="math inline">\(y_{i} = \beta_{0} +
\beta_{1}x_{i} + u_{i}\)</span>，所以我们对<span
class="math inline">\(u\)</span>的假设才能复刻到对<span
class="math inline">\(u_{i}\)</span>的假设上。</p>
<p>·<span class="math inline">\(x_{i}\)</span>有方差，保证<span
class="math inline">\(\widehat{\beta_{1} }\)</span>有意义可以算；</p>
<p>·零条件均值假设。</p>
<p>②无偏性</p>
<p><span class="math display">\[E\left( \widehat{\beta_{1} } \right) =
\beta_{1}\]</span></p>
<p><span class="math display">\[E\left( \widehat{\beta_{0} } \right) =
\beta_{0}\]</span></p>
<p>其中在推导过程中需要记忆：</p>
<p><span class="math display">\[\widehat{\beta_{1} } = \beta_{1} +
\frac{\sum_{}^{}{\left( x_{i} - \overline{x} \right)u_{i} } }{ {SST}_{X}
}\]</span></p>
<p><span class="math display">\[\widehat{\beta_{0} } = \beta_{0} +
\overline{u} + (\widehat{\beta_{1} } -
\beta_{1})\overline{x}\]</span></p>
<h3 id="参数方差">参数方差</h3>
<p>假设5（同方差假设）：</p>
<p><span class="math display">\[var\left( u \middle| x \right) =
\sigma^{2}\]</span></p>
<p>从中可以知道：<span class="math inline">\(E\left( u \middle| x
\right) = 0\)</span>且<span class="math inline">\(var\left( u \middle| x
\right) = \sigma^{2}\)</span>；<span class="math inline">\(var\left( y
\middle| x \right) = \sigma^{2}\)</span>且<span
class="math inline">\(E\left( y \middle| x \right) = \beta_{0} +
\beta_{1}x_{i}\)</span>。</p>
<p>继而推导出：</p>
<p><span class="math display">\[var\left( \widehat{\beta_{1} } \right) =
\frac{\sigma^{2} }{ {SST}_{X} }\]</span></p>
<p><span class="math display">\[var\left( \widehat{\beta_{0} } \right) =
\frac{\sigma^{2} }{ {SST}_{X} }\frac{\sum_{}^{}{x_{i} }^{2}
}{n}\]</span></p>
<h3 id="方差估计">方差估计</h3>
<p>①对误差方差（<span class="math inline">\(\mathbf{\sigma}^{\mathbf{2}
}\)</span>）的估计（<span
class="math inline">\({\widehat{\mathbf{\sigma} } }^{\mathbf{2}
}\)</span>）</p>
<p><span class="math display">\[{\widehat{\sigma} }^{2} =
\frac{\sum_{}^{}{\widehat{u} }^{2} }{n - 2}\]</span></p>
<p>除以<span class="math inline">\(n - 2\)</span>是因为，对于<span
class="math inline">\(\widehat{u}\)</span>我们有如下两条推导出来的限制条件：</p>
<p><span class="math display">\[\sum_{i = 1}^{n}\widehat{u_{i} } = 0
\rightarrow \overline{y} = \overline{\widehat{y} }\]</span></p>
<p><span class="math display">\[\sum_{i = 1}^{n}{x_{i}\widehat{u_{i} } }
= 0 \rightarrow \sum_{i = 1}^{n}{y_{i}\widehat{u_{i} } } =
0\]</span></p>
<p>我们把<span
class="math inline">\(\widehat{\sigma}\)</span>就叫做<strong>回归标准误</strong>。</p>
<p>那么：<br />
<span class="math display">\[se\left( \widehat{\beta_{1} } \right) =
\frac{\widehat{\sigma} }{\sqrt{ {SST}_{x} } }\]</span></p>
<p><span class="math display">\[se\left( \widehat{\beta_{0} } \right) =
\frac{\widehat{\sigma} }{\sqrt{ {SST}_{x} } }\sqrt{n^{- 1}\sum_{i =
1}^{n}{x_{i} }^{2} }\]</span></p>
<h3 id="习题练习">习题练习</h3>
<p><img src="https://s2.loli.net/2025/01/28/vcPqrCd3ufY1knM.png"
style="width:5.76806in;height:3.16944in" /></p>
<h1 id="第3章-多元回归分析模型与估计">第3章
多元回归分析：模型与估计</h1>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1o34y1A7Ef/?spm_id_from=pageDriver&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第三章（1）:多元线性回归的模型与估计_哔哩哔哩_bilibili</a></p>
<h2 id="多元回归模型形式和假设">多元回归模型（形式和假设）</h2>
<p>在建模时为什么我们仍然希望加入更多变量？</p>
<p>在构建一元线性回归模型中，保证<span
class="math inline">\(\beta_{1}\)</span>可靠性的一个重要前提是"保持其他因素不变"。那我们是如何实现这一点的呢？靠假设！条件均值假设！</p>
<p>但是如果我们把这些"其他因素"观测出来，作为控制变量引入我们的模型中时，我们就能明确的控制！</p>
<p>因此，我们就有多元线性回归，形式如下：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + \beta_{3}x_{3} + \ldots + \beta_{k}x_{k} +
u\]</span></p>
<p>其中，<span class="math inline">\(u\)</span>代表<span
class="math inline">\(x_{1}\ldots x_{k}\)</span>以外，还能影响<span
class="math inline">\(y\)</span>的因素；<span
class="math inline">\(\beta_{0}\)</span>是截距，当所有自变量取值为0时，因变量的取值；<span
class="math inline">\(\beta_{1}\ldots\beta_{k}\)</span>是斜率参数，保持其他变量不变时，<span
class="math inline">\(y\)</span>相对于<span
class="math inline">\(x_{k}\)</span>的变化量。</p>
<p>并且我们仍然有假设：</p>
<p><span class="math display">\[E\left( u \middle| x_{1}\ldots x_{k}
\right) = 0\]</span></p>
<h2 id="系数估计与推导出的数学性质">系数估计与推导出的数学性质</h2>
<p>多元回归模型想要优化的函数仍然是残差平方和<span
class="math inline">\(\sum_{}^{}{\widehat{u} }^{2}\)</span></p>
<p><span class="math display">\[Q = \sum_{}^{}{\widehat{u} }^{2} =
\sum_{}^{}{(y_{i} - \widehat{\beta_{0} } - \widehat{\beta_{1} }x_{1i} -
\widehat{\beta_{2} }x_{2i} - \widehat{\beta_{3} }x_{3i} - \ldots -
\widehat{\beta_{k} }x_{ki})}^{2}\]</span></p>
<p>我们分别对<span class="math inline">\(\widehat{\beta_{1}
}\ldots\widehat{\beta_{k} }\)</span>求偏导，并令所有式子为0。</p>
<p>从中可以依次得出性质（对<span
class="math inline">\(\widehat{\beta_{0} }\)</span>求偏导）：</p>
<p><span class="math display">\[\sum_{}^{}\widehat{u_{i} } =
\sum_{}^{}{(y_{i} - \widehat{\beta_{0} } - \widehat{\beta_{1} }x_{1i} -
\widehat{\beta_{2} }x_{2i} - \widehat{\beta_{3} }x_{3i} - \ldots -
\widehat{\beta_{k} }x_{ki})} = 0\]</span></p>
<p><span class="math display">\[\sum_{}^{}{x_{li}\widehat{u_{i} } } = 0\
(l = 1,2\ldots,k)\]</span></p>
<p>(<span class="math inline">\(\overline{x_{1} },\ldots,\overline{x_{k}
},y\)</span>)也在回归线上（<span
class="math inline">\(\frac{1}{n}\sum_{}^{}{(y_{i} - \widehat{\beta_{0}
} - \widehat{\beta_{1} }x_{1i} - \widehat{\beta_{2} }x_{2i} -
\widehat{\beta_{3} }x_{3i} - \ldots - \widehat{\beta_{k} }x_{ki})} =
0\)</span>）。</p>
<p>从而有结论：</p>
<p><span class="math display">\[\overline{y_{i} } =
\frac{1}{n}\sum_{}^{}{(\widehat{\beta_{0} } + \widehat{\beta_{1} }x_{1i}
+ \widehat{\beta_{2} }x_{2i} + \widehat{\beta_{3} }x_{3i} + \ldots +
\widehat{\beta_{k} }x_{ki})} = \overline{\widehat{y_{i} } }\]</span></p>
<p><span class="math display">\[\sum_{}^{}\widehat{y_{i} }\widehat{u_{i}
} = 0(需要结论\sum_{}^{}\widehat{u_{i} } =
0,\sum_{}^{}{x_{li}\widehat{u_{i} } } = 0\ (l =
1,2\ldots,k))\]</span></p>
<p>从而有结论：</p>
<p><span class="math display">\[SST = SSE +
SSR(需要结论\sum_{}^{}\widehat{u_{i} } = 0,\sum_{}^{}\widehat{y_{i}
}\widehat{u_{i} } = 0)\]</span></p>
<p>接着就可以对估计系数进行解释：</p>
<p><span class="math display">\[\mathrm{\Delta}y = \widehat{\beta_{0} }
+ \widehat{\beta_{1} }{\mathrm{\Delta}x}_{1} + \widehat{\beta_{2}
}{\mathrm{\Delta}x}_{2} + \ldots + \widehat{\beta_{k}
}{\mathrm{\Delta}x}_{k}\]</span></p>
<p>当<span
class="math inline">\({\mathrm{\Delta}x}_{2},\ldots,{\mathrm{\Delta}x}_{k}
= 0\)</span>时，<span class="math inline">\(\widehat{\beta_{1} } =
\frac{\mathrm{\Delta}y}{ {\mathrm{\Delta}x}_{1} }\)</span></p>
<p>在一元线性回归中：</p>
<p><span class="math display">\[\widehat{\beta_{1} } =
\frac{\sum_{}^{}{(x_{i} - \overline{x})(y_{i} - \overline{y})}
}{\sum_{}^{}{(x_{i} - \overline{x})}^{2} } = \frac{\sum_{}^{}{(x_{i} -
\overline{x})y_{i} } }{\sum_{}^{}{(x_{i} - \overline{x})}^{2}
}\]</span></p>
<p>那么，对于二元回归模型<span class="math inline">\(y = \beta_{0} +
\beta_{1}x_{1} + \beta_{2}x_{2} +
u\)</span>，我们可以计算出多元线性回归中<span
class="math inline">\(\beta_{1}\)</span>的估计量<span
class="math inline">\(\widehat{\beta_{1} }\)</span>为：</p>
<p><span class="math display">\[\widehat{\beta_{1} } =
\frac{\sum_{}^{}{\widehat{r_{i1} }y_{i} } }{\sum_{}^{}{\widehat{r_{i1} }
}^{2} }\]</span></p>
<p>其中<span class="math inline">\(\widehat{r_{i1} }\)</span>是<span
class="math inline">\(x_{1}\)</span>对<span
class="math inline">\(x_{2}\)</span>进行OLS回归的残差，也就是估计出模型：</p>
<p><span class="math display">\[x_{1} = \widehat{\delta_{0} } +
\widehat{\delta_{1} }x_{2} + \widehat{r_{i1} }\]</span></p>
<p>在新估计出的模型中，<span class="math inline">\(\widehat{r_{i1}
}\)</span>代表了排除<span
class="math inline">\(x_{2}\)</span>后，对<span
class="math inline">\(x_{1}\)</span>有影响的因素。对于原二元线性回归函数<span
class="math inline">\(y = \beta_{0} + \beta_{1}x_{1} + \beta_{2}x_{2} +
u\)</span>，如果没有<span
class="math inline">\(x_{2}\)</span>变量（也就是将<span
class="math inline">\(x_{2}\)</span>一块涵盖在<span
class="math inline">\(u\)</span>中），那么<span
class="math inline">\(\widehat{r_{i1} }\)</span>的位置是只放关于<span
class="math inline">\(x_{1i}\)</span>的表达式，但如果有了<span
class="math inline">\(x_{2}\)</span>变量，则需要将排除<span
class="math inline">\(x_{2}\)</span>因素的，更纯净的关于<span
class="math inline">\(x_{1i}\)</span>的表达式。</p>
<h2 id="遗漏增加变量对回归系数的影响">遗漏/增加变量对回归系数的影响</h2>
<p>如果说真实的模型是一个二元模型：<span class="math inline">\(y =
\beta_{0} + \beta_{1}x_{1} + \beta_{2}x_{2} +
u\)</span>，对其进行估计，得到了估计值<span
class="math inline">\(\widehat{\beta_{1} }\)</span>和<span
class="math inline">\(\widehat{\beta_{2} }\)</span>。</p>
<p>但如果由于<span
class="math inline">\(x_{2}\)</span>的数据收集问题，另一个人只构建了一个一元模型<span
class="math inline">\(y = \beta_{0} + \beta_{1}x_{1} +
u\)</span>，对其进行估计，得到了估计值<span
class="math inline">\(\widetilde{\beta_{1} }\)</span>。那么<span
class="math inline">\(\widehat{\beta_{1} }\)</span>和<span
class="math inline">\(\widetilde{\beta_{1}
}\)</span>的差距在哪里？有多大？</p>
<p>有结论：<span class="math inline">\(\widetilde{\beta_{1}
}\)</span>=<span class="math inline">\(\widehat{\beta_{1}
}\)</span>+<span class="math inline">\(\widehat{\beta_{2}
}\widetilde{\delta_{1} }\)</span>，其中<span
class="math inline">\(\widetilde{\delta_{1} }\)</span>是<span
class="math inline">\(x_{2}\)</span>对<span
class="math inline">\(x_{1}\)</span>回归（<span
class="math inline">\(x_{2} = \delta_{0} + \delta_{1}x_{1} +
r\)</span>）的斜率系数的估计值。通过下图理解记忆：</p>
<p><span class="math display">\[y\]</span></p>
<p><span class="math display">\[x_{2}\]</span></p>
<p><span class="math display">\[\widehat{\beta_{2} }\]</span></p>
<p><span class="math display">\[\widehat{\beta_{1} }\]</span></p>
<p><span class="math display">\[\widetilde{\delta_{1} }\]</span></p>
<p><span class="math display">\[x_{1}\]</span></p>
<p>★其中，<span class="math inline">\(\widehat{\beta_{1}
}\)</span>代表在控制了<span
class="math inline">\(x_{2}\)</span>的条件下，<span
class="math inline">\(x_{1}\)</span>对<span
class="math inline">\(y\)</span>的影响；<span
class="math inline">\(\widehat{\beta_{2} }\)</span>表示<span
class="math inline">\(x_{2}\)</span>对<span
class="math inline">\(y\)</span>的影响；<span
class="math inline">\(\widetilde{\delta_{1} }\)</span>代表<span
class="math inline">\(x_{1}\)</span>对<span
class="math inline">\(x_{2}\)</span>的影响；所以在不控制<span
class="math inline">\(x_{2}\)</span>的条件下，<span
class="math inline">\(x_{1}\)</span>对<span
class="math inline">\(y\)</span>的影响将增大，<span
class="math inline">\(\widetilde{\beta_{1} }\)</span>=<span
class="math inline">\(\widehat{\beta_{1} }\)</span>+<span
class="math inline">\(\widetilde{\delta_{1} }\widehat{\beta_{2}
}\)</span>。因此，如果<span class="math inline">\(\widehat{\beta_{2} } =
0\)</span>，也就是<span class="math inline">\(x_{2}\)</span>对<span
class="math inline">\(y\)</span>没有影响，那么<span
class="math inline">\(\widetilde{\beta_{1} }\)</span>=<span
class="math inline">\(\widehat{\beta_{1} }\)</span>；又或者<span
class="math inline">\(\widetilde{\delta_{1} } = 0\)</span>，也就是<span
class="math inline">\(x_{1}\)</span>对<span
class="math inline">\(x_{2}\)</span>没有影响，<span
class="math inline">\(x_{1}\)</span>和<span
class="math inline">\(x_{2}\)</span>完全不相关，那么仍然<span
class="math inline">\(\widetilde{\beta_{1} }\)</span>=<span
class="math inline">\(\widehat{\beta_{1} }\)</span>。</p>
<h2 id="系数期望">系数期望</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1S34y1u7i4/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第三章（2）多元线性回归系数估计的期望与方差_哔哩哔哩_bilibili</a></p>
<p>前提概念回顾，我们是要研究系数的统计性质，何谓统计性质？有如下解释：</p>
<p>根据OLS回归求解最小残差平方和的方法，我们能对系数的估计量进行表示，如：</p>
<p><span class="math display">\[\widehat{\beta_{1} } =
\frac{cov(x_{i},y_{i})}{ {\sigma_{x} }^{2} }\]</span></p>
<p>也就是根据这一组样本<span
class="math inline">\((x_{i},y_{i})\)</span>，我们能估计出这一组样本的<span
class="math inline">\(\widehat{\beta_{1}
}\)</span>。那么进行多次抽样，就有多组<span
class="math inline">\((x_{i},y_{i})\)</span>，从而能估计出多个<span
class="math inline">\(\widehat{\beta_{1}
}\)</span>，我们就是要研究这些<span
class="math inline">\(\widehat{\beta_{1}
}\)</span>的统计性质，即它们的期望和方差。</p>
<h3 id="四个前提假设">四个前提假设</h3>
<p>与简单线性回归一致，统计量期望的得出需要很多假定条件：</p>
<p><mark>假设一（线性假定</mark>，是指<span
class="math inline">\(y\)</span>对参数线性，而不是要求<span
class="math inline">\(y\)</span>对<span
class="math inline">\(x\)</span>线性。因为我们可以将自变量<span
class="math inline">\(x\)</span>转换成如<span
class="math inline">\(log(n)\)</span>等非线性形式，但仍然能用以下这个模型来计算表示。）：总体模型，也就是背后的真实模型，可以设置成：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + \beta_{3}x_{3} + \ldots + \beta_{k}x_{k} +
u\]</span></p>
<p><mark>假设二（随机假定）</mark>：只有样本是从总体随机抽取出来的，那么样本的模型表示才能写成总体模型的形式，即假设一中的形式。<u>那么总体模型中对于</u><span
class="math inline">\(u\)</span><u>的假设（零条件均值）才能延续到样本模型中的</u><span
class="math inline">\(u_{i}\)</span><u>中。</u></p>
<p>对于一组样本<span class="math inline">\(\{
x_{i1},x_{i2},\ldots,x_{ik},y_{i}:i =
1,2,\ldots,n\}\)</span>，有每一组样本模型：</p>
<p><span class="math display">\[y_{i} = \beta_{0} + \beta_{1}x_{i1} +
\beta_{2}x_{i2} + \beta_{3}x_{i3} + \ldots + \beta_{k}x_{ik} +
u_{i}\]</span></p>
<p>其中<span class="math inline">\(n\)</span>代表了这一组样本有<span
class="math inline">\(n\)</span>组观测，<span
class="math inline">\(i\)</span>代表的是这一组样本第<span
class="math inline">\(i\)</span>个观测。</p>
<p><mark>假设三（估计量有效假定）</mark>：在样本中，没有一个自变量是常数，自变量之间也不存在严格的线性关系。</p>
<p>①为什么自变量之间不能存在严格的线性关系？</p>
<p>自变量之间存在严格的线性关系（多重共线性）指的是有一个自变量<span
class="math inline">\(x_{j} = \delta_{0} + \delta_{1}x_{1} +
\delta_{2}x_{2} + \delta_{3}x_{3} + \ldots +
\delta_{k}x_{k}\)</span>。</p>
<p>之所以做出这个假定是因为，对于<span
class="math inline">\(x_{j}\)</span>的系数估计量有：<em><br />
</em><span class="math display">\[\widehat{\beta_{j} } =
\frac{\sum_{}^{}{\widehat{r_{ij} }y_{i} } }{\sum_{}^{}{\widehat{r_{ij} }
}^{2} }\]</span></p>
<p>其中，<span class="math inline">\(\widehat{r_{ij} }\)</span>是<span
class="math inline">\(x_{j}\)</span>对其他<span
class="math inline">\(x_{i}\)</span>进行OLS回归后的残差。那如果<span
class="math inline">\(x_{j}\)</span>能被其他变量（任一或任一些或全部）线性表达，那么残差就为0，也就是<span
class="math inline">\(\widehat{r_{ij} } = 0\)</span>不能作为分母，<span
class="math inline">\(\widehat{\beta_{j} }\)</span>没有意义。</p>
<p>②为什么自变量不能为常数？</p>
<p>【再翻书确定一下】自变量为常数那么就一定能在自变量中找到线性关系。</p>
<p>需要注意：</p>
<p>这一条假设中是指不能有"严格"的线性关系，不是说不能有相关；其次，如果有对自变量有进行变换操作，需要尤其注意这条假设，比如原始模型的自变量为<span
class="math inline">\(x\)</span>和<span
class="math inline">\(x^{2}\)</span>，它们是不存在多重共线性，但如果我们对这个模型进行<span
class="math inline">\(log()\)</span>变换操作，那此时自变量就存在多重共线性<span
class="math inline">\(2\log(x) = \log\left( x^{2} \right)\)</span>。</p>
<p><mark>假设四（零条件期望）</mark>：给定解释变量的任何值，误差的期望值都为零，<span
class="math inline">\(E\left( u|x_{1},x_{2},\ldots,x_{k} \right) =
0\)</span>。根据自变量取值是否相同进行分组，不同组别之间的误差期望应该是相同的。以下情况有可能出现违背零条件期望假设。</p>
<p>情况一：模型误设，<span class="math inline">\(y\)</span>与<span
class="math inline">\(x\)</span>不是线性关系，而是如<span
class="math inline">\(\log\)</span>、二次方等关系；</p>
<p>情况二：<span class="math inline">\(u\)</span>与<span
class="math inline">\(x\)</span>相关；</p>
<p>情况三：<span class="math inline">\(x\)</span>存在测量误差；</p>
<p>情况四：<span class="math inline">\(x\)</span>和<span
class="math inline">\(y\)</span>是同时决定的。</p>
<h3 id="估计量期望推导">估计量期望推导</h3>
<p>根据上述的四个假设，我们就能推导出系数的无偏性，即</p>
<p><span class="math display">\[E\left( \widehat{\beta_{j} } \right) =
\beta_{j},j = 0,1,2,\ldots,k\]</span></p>
<p>推导过程：</p>
<p>已知：</p>
<p><span class="math display">\[y_{i} = \beta_{0} + \beta_{1}x_{i1} +
\beta_{2}x_{i2} + \beta_{3}x_{i3} + \ldots + \beta_{k}x_{ik} +
u_{i}\]</span></p>
<p><span class="math display">\[\widehat{\beta_{j} } =
\frac{\sum_{}^{}{\widehat{r_{ij} }y_{i} } }{\sum_{}^{}{\widehat{r_{ij} }
}^{2} }\]</span></p>
<p>其中，<span class="math inline">\(\widehat{r_{ij} }\)</span>是<span
class="math inline">\(x_{j}\)</span>对其他<span
class="math inline">\(x_{i}\)</span>进行OLS回归后的残差。</p>
<p><span class="math display">\[x_{ij} = \delta_{0} + \delta_{1}x_{i1} +
\delta_{2}x_{i2} + \delta_{3}x_{i3} + \ldots + \delta_{k}x_{ik} +
r_{ij}\]</span></p>
<p>那么有：</p>
<p><span class="math display">\[\sum_{}^{}\widehat{r_{ij} } =
0\]</span></p>
<p><span class="math display">\[\sum_{}^{}{x_{il}\widehat{r_{ij} } } =
0,l = 1,2,\ldots,k(except\ j)\]</span></p>
<p>又因为：<span class="math inline">\(\widehat{x_{ij} } =
\widehat{\delta_{0} } + \widehat{\delta_{1} }x_{i1} +
\widehat{\delta_{2} }x_{i2} + \widehat{\delta_{3} }x_{i3} + \ldots +
\widehat{\delta_{k} }x_{ik}\)</span></p>
<p>所以：</p>
<p><span class="math display">\[\sum_{}^{}{\widehat{x_{ij}
}\widehat{r_{ij} } } = 0\]</span></p>
<p>那么：</p>
<p><span class="math display">\[\widehat{\beta_{j} } =
\frac{\sum_{}^{}{\widehat{r_{ij} }y_{i} } }{\sum_{}^{}{\widehat{r_{ij} }
}^{2} } = \frac{\sum_{}^{}{\widehat{r_{ij} }(\beta_{0} + \beta_{1}x_{i1}
+ \beta_{2}x_{i2} + \beta_{3}x_{i3} + \ldots + \beta_{k}x_{ik} + u_{i})}
}{\sum_{}^{}{\widehat{r_{ij} } }^{2} } =
\frac{\sum_{}^{}{\widehat{r_{ij}(}\beta_{j}x_{ij} + u_{i})}
}{\sum_{}^{}{\widehat{r_{ij} } }^{2} } =
\frac{\sum_{}^{}{\widehat{r_{ij}(}\beta_{j}(\widehat{x_{ij} } +
\widehat{r_{ij} }) + u_{i})} }{\sum_{}^{}{\widehat{r_{ij} } }^{2} } =
\beta_{j} + \frac{\sum_{}^{}{\widehat{r_{ij} }u_{i} }
}{\sum_{}^{}{\widehat{r_{ij} } }^{2} }\]</span></p>
<p>这个式子的前提条件是给定一组样本<span
class="math inline">\((x_{i},y_{i})\)</span>，因此<span
class="math inline">\(\widehat{r_{ij}
}\)</span>能够算出来，相当于常数。所以：</p>
<p><span class="math display">\[E\left( \widehat{\beta_{j} } \right) =
\beta_{j}\]</span></p>
<p>从中我们能够得出：</p>
<p>·平均来看，每一组样本估计出来的<span
class="math inline">\(\widehat{\beta_{j} }\)</span>接近真值；</p>
<p>·但具体到一个特定样本估计出的<span
class="math inline">\(\widehat{\beta_{j} }\)</span>与真实<span
class="math inline">\(\beta_{j}\)</span>的差距，我们是不清楚的。</p>
<h3
id="无关遗漏变量对期望的影响偏误">无关/遗漏变量对期望的影响（偏误）</h3>
<p>在以下的一些特殊情况：</p>
<h4 id="在回归模型中包含了无关变量">在回归模型中包含了无关变量</h4>
<p>言之，以三元回归为例，在模型<span class="math inline">\(y = \beta_{0}
+ \beta_{1}x_{1} + \beta_{2}x_{2} + \beta_{3}x_{3} + u\)</span>中，<span
class="math inline">\(\beta_{3} = 0\)</span>。这会不会影响<span
class="math inline">\(\beta_{1}\)</span>和<span
class="math inline">\(\beta_{2}\)</span>的估计？不会！</p>
<h4 id="遗漏变量的偏误简单情形">遗漏变量的偏误：简单情形</h4>
<p>真实模型：<span class="math inline">\(y = \beta_{0} + \beta_{1}x_{1}
+ \beta_{2}x_{2} + u\)</span>，对其进行估计：<span
class="math inline">\(y = \widehat{\beta_{0} } + \widehat{\beta_{1}
}x_{1} + \widehat{\beta_{2} }x_{2} +
\widehat{u}\)</span>；遗漏变量：<span class="math inline">\(y =
\widetilde{\beta_{0} } + \widetilde{\beta_{1} }x_{1} +
\widetilde{u}\)</span></p>
<p>已知有结论：</p>
<p><span class="math display">\[\widetilde{\beta_{1} } =
\widehat{\beta_{1} } + \widehat{\beta_{2} }\widetilde{\delta_{1}
}\]</span></p>
<p>其中<span class="math inline">\(\widetilde{\delta_{1}
}\)</span>是<span class="math inline">\(x_{2}\)</span>对<span
class="math inline">\(x_{1}\)</span>回归的回归系数。</p>
<p><span class="math inline">\(\widetilde{\beta_{1}
}\)</span>的偏误<span class="math inline">\(Bias\left(
\widetilde{\beta_{1} } \right) = E\left( \widetilde{\beta_{1} } \right)
- \beta_{1} = E\left( \widehat{\beta_{1} } + \widehat{\beta_{2}
}\widetilde{\delta_{1} } \right) - \beta_{1} = E\left(
\widehat{\beta_{2} }\widetilde{\delta_{1} } \right) =
\beta_{2}\widetilde{\delta_{1} }\)</span></p>
<p>最后一步是因为<span class="math inline">\(E\left( \widehat{\beta_{2}
} \right) = \beta_{2}\)</span>，并且研究统计量的估计时我们把<span
class="math inline">\(x_{i}\)</span>看成一组已知的常数，那么它们之间的系数也是已知的，可以看成常数。</p>
<p>因此，</p>
<p>·如果<span class="math inline">\(\beta_{2} = 0/\widetilde{\delta_{1}
} = 0\)</span>，那么偏误为0</p>
<p><span class="math display">\[\widetilde{\delta_{1} }\]</span></p>
<p>·</p>
<p><span class="math display">\[downward\ bias\]</span></p>
<p><span class="math display">\[upward\ bias\]</span></p>
<p><span class="math display">\[E\left( \widetilde{\beta_{1} } \right)
&lt; \beta_{1}\]</span></p>
<p><span class="math display">\[E\left( \widetilde{\beta_{1} } \right)
&gt; \beta_{1}\]</span></p>
<p><span class="math display">\[\beta_{2}\]</span></p>
<p><span class="math display">\[E\left( \widetilde{\beta_{1} } \right)
&lt; \beta_{1}\]</span></p>
<p><span class="math display">\[E\left( \widetilde{\beta_{1} } \right)
&gt; \beta_{1}\]</span></p>
<p><span class="math display">\[upward\ bias\]</span></p>
<p><span class="math display">\[downward\ bias\]</span></p>
<h4 id="遗漏变量的偏误更一般的情形">遗漏变量的偏误：更一般的情形</h4>
<p>真实模型：<span class="math inline">\(y = \beta_{0} + \beta_{1}x_{1}
+ \beta_{2}x_{2} + \beta_{3}x_{3} + u\)</span></p>
<p>遗漏了的错误模型的估计：<span class="math inline">\(y =
\widetilde{\beta_{0} } + \widetilde{\beta_{1} }x_{1} +
\widetilde{\beta_{2} }x_{2} + \widetilde{u}\)</span></p>
<p>如果<span class="math inline">\(x_{1}\)</span>和<span
class="math inline">\(x_{3}\)</span>相关，即使<span
class="math inline">\(x_{2}\)</span>与<span
class="math inline">\(x_{3}\)</span>不相关，<span
class="math inline">\(\beta_{1}\)</span>和<span
class="math inline">\(\beta_{2}\)</span>的估计量一般仍然都会发生偏误，因为大概率<span
class="math inline">\(x_{1}\)</span>与<span
class="math inline">\(x_{2}\)</span>有关（多元线性回归的偏误具有传导性质）。特殊的，如果<span
class="math inline">\(x_{1}\)</span>与<span
class="math inline">\(x_{2}\)</span>无关，那么就可以相当于上述的简单情形<span
class="math inline">\(E\left( \widetilde{\beta_{1} } \right) - \beta_{1}
= \beta_{3}\widetilde{\delta_{1} }\)</span>。</p>
<h2 id="系数方差与标准误">系数方差与标准误</h2>
<p><mark>假设五（同方差性）</mark>：<span
class="math inline">\(var\left( u \middle|
x_{1},x_{2},x_{3},\ldots,x_{k} \right) = \sigma^{2}\)</span></p>
<p>假设一到假设五我们称作<u>高斯马尔可夫假设</u>。</p>
<p>从假设五我们能推出：</p>
<p><span class="math display">\[var\left( u \middle|
x_{1},x_{2},x_{3},\ldots,x_{k} \right) = E\left( u^{2} \middle|
x_{1},x_{2},x_{3},\ldots,x_{k} \right) - E^{2}\left( u \middle|
x_{1},x_{2},x_{3},\ldots,x_{k} \right) = E\left( u^{2} \middle|
x_{1},x_{2},x_{3},\ldots,x_{k} \right) = \sigma^{2}\]</span></p>
<p>又根据期望迭代法则<span class="math inline">\(E\left( E\left( Y
\middle| X \right) \right) = E(Y)\)</span>，所以：</p>
<p><span class="math display">\[E{(u}^{2}) = E\left( E\left( u^{2}
\middle| x_{1},x_{2},x_{3},\ldots,x_{k} \right) \right) =
\sigma^{2}\]</span></p>
<p>因此：</p>
<p><span class="math display">\[var(u) = E\left( u^{2} \right) -
E^{2}(u) = \sigma^{2}\]</span></p>
<p>因此：</p>
<p><span class="math display">\[var\left( y \middle|
x_{1},x_{2},x_{3},\ldots,x_{k} \right) = var\left( \beta_{0} +
\beta_{1}x_{1} + \beta_{2}x_{2} + \beta_{3}x_{3} + \ldots +
\beta_{k}x_{k} + u \middle| x_{1},x_{2},x_{3},\ldots,x_{k} \right) = =
var(u) = \sigma^{2}\]</span></p>
<h3 id="系数估计量的方差推导">系数估计量的方差推导</h3>
<p>那么，我们就能推出OLS斜率估计量的抽样方差：</p>
<p><span class="math display">\[var\left( \widehat{\beta_{j} } \right) =
\frac{\sigma^{2} }{ {SST}_{j}(1 - {R_{j} }^{2})},j =
1,\ldots,k\]</span></p>
<p>其中，<span class="math inline">\({R_{j} }^{2}\)</span>是<span
class="math inline">\(x_{ij}\)</span>对其余自变量进行回归（<span
class="math inline">\(x_{ij} = \widehat{\delta_{0} } +
\widehat{\delta_{1} }x_{i1} + \widehat{\delta_{2} }x_{i2} +
\widehat{\delta_{3} }x_{i3} + \ldots + \widehat{\delta_{k} }x_{ik
+}\widehat{r_{ij} }\)</span>）的拟合优度/可决系数，<span
class="math inline">\({R_{j} }^{2} = \frac{ {SSE}_{j} }{ {SST}_{j} } = 1
- \frac{ {SSR}_{j} }{ {SST}_{j} } = 1 - \frac{\sum_{}^{}{\widehat{r_{ij}
} }^{2} }{ {SST}_{j} }\)</span>，因此：</p>
<p><span class="math display">\[\sum_{}^{}{\widehat{r_{ij} } }^{2} =
{SST}_{j}(1 - {R_{j} }^{2})\]</span></p>
<p>证明过程如下：</p>
<p>已知：</p>
<p><span class="math display">\[\widehat{\beta_{j} } = \beta_{j} +
\frac{\sum_{}^{}{\widehat{r_{ij} }u_{i} } }{\sum_{}^{}{\widehat{r_{ij} }
}^{2} }\]</span></p>
<p>那么：</p>
<p><span class="math display">\[var\left( \widehat{\beta_{j} }|X \right)
= \frac{1}{ {(\sum_{}^{}{ {\widehat{r_{ij} } }^{2})} }^{2} }var\left(
\sum_{}^{}{\widehat{r_{ij} }u_{i} }|X \right) = \frac{1}{ {(\sum_{}^{}{
{\widehat{r_{ij} } }^{2})} }^{2} }\sum_{}^{}{ {\widehat{r_{ij} }
}^{2}var\left( u_{i}|X \right)} = \frac{1}{\sum_{}^{}{\widehat{r_{ij} }
}^{2} }\sigma^{2} = \frac{\sigma^{2} }{ {SST}_{j}(1 - {R_{j}
}^{2})}\]</span></p>
<p>其中由于给定<span class="math inline">\(x\)</span>所以<span
class="math inline">\(\widehat{r_{ij}
}\)</span>是常数，可以被提到外面并平方。又因为是随机抽样，所以<span
class="math inline">\(u_{i}\)</span>在<span
class="math inline">\(i\)</span>上是独立的随机变量，因此和的方差等于方差的和。</p>
<p>在一元回归中：</p>
<p><span class="math display">\[var\left( \widehat{\beta_{i} } \right) =
\frac{\sigma^{2} }{ {SST}_{x} }\]</span></p>
<p>而在多元回归中，系数估计量的方差多乘了一个<span
class="math inline">\(\frac{1}{1 - {R_{j} }^{2}
}\)</span>（VIF，方差膨胀因子）</p>
<h3 id="膨胀因子mathbfvmathbfif">膨胀因子<span
class="math inline">\(\mathbf{V}\mathbf{IF}\)</span></h3>
<p>从中我们就能得出以下三点启示：</p>
<p><strong>①</strong><span class="math inline">\({\mathbf{R}_{\mathbf{j}
} }^{\mathbf{2} }\)</span><strong>不能等于1</strong></p>
<p><span class="math display">\[{R_{j} }^{2} \neq 1\]</span></p>
<p>这也是再次印证假设三（多重共线性），因为如果出现多重共线性，那么<span
class="math inline">\({SSR}_{x} = \sum_{}^{}{ {\widehat{r_{ij} } }^{2} =
0}\)</span>，导致<span class="math inline">\({R_{j} }^{2} =
1\)</span>。那如果<span class="math inline">\({R_{j}
}^{2}\)</span>十分接近1，也就是<span
class="math inline">\(x_{ij}\)</span>在很大程度上能被其余自变量表示，那么<span
class="math inline">\(VIF\)</span>将会特别大，从而导致<span
class="math inline">\(x_{ij}\)</span>的系数估计量的方差<span
class="math inline">\(var\left( \widehat{\beta_{i} }
\right)\)</span>特别大，换言之估计量不准确的概率很高。</p>
<p><strong>②一般要求</strong><span
class="math inline">\(\mathbf{V}\mathbf{IF &lt; 10}\)</span></p>
<p><span class="math inline">\(VIF &gt; 10\)</span>意味着<span
class="math inline">\({R_{j} }^{2} &gt; 90\%\)</span>，换言之，<span
class="math inline">\(x_{ij}\)</span>在90%的程度上能被其余自变量表示，这种情况我们一般认为<span
class="math inline">\(x_{ij}\)</span>的系数估计量的方差<span
class="math inline">\(var\left( \widehat{\beta_{i} }
\right)\)</span>就可能过大，但我们还要考虑<span
class="math inline">\(\frac{\sigma^{2} }{ {SST}_{j}
}\)</span>的影响。</p>
<p><strong>③如果我们只关心</strong><span
class="math inline">\(\mathbf{x}_{\mathbf{i}\mathbf{j}
}\)</span><strong>，那么其余自变量的</strong><span
class="math inline">\(\mathbf{V}\mathbf{IF}\)</span><strong>过大是没有影响的。</strong></p>
<h3
id="遗漏增加变量对偏误和方差的影响">遗漏/增加变量对偏误和方差的影响</h3>
<p>那么有了上面的结论，我们对遗漏变量所产生的偏误就有了更深的理解：</p>
<p>假设：</p>
<p>真实模型：<span class="math inline">\(y = \beta_{0} + \beta_{1}x_{1}
+ \beta_{2}x_{2} + u\)</span></p>
<p>真实模型的估计：<span class="math inline">\(y = \widehat{\beta_{0} }
+ \widehat{\beta_{1} }x_{1} + \widehat{\beta_{2} }x_{2} +
\widehat{u}\)</span></p>
<p>遗漏了变量的错误模型的估计：<span class="math inline">\(y =
\widetilde{\beta_{0} } + \widetilde{\beta_{1} }x_{1} +
\widetilde{u}\)</span></p>
<table style="width:99%;">
<colgroup>
<col style="width: 10%" />
<col style="width: 38%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr>
<th></th>
<th style="text-align: left;">偏误</th>
<th style="text-align: left;">方差</th>
</tr>
</thead>
<tbody>
<tr>
<td>真实模型估计</td>
<td style="text-align: left;"><span class="math display">\[E\left(
\widehat{\beta_{1} } \right) = \beta_{1}\]</span></td>
<td style="text-align: left;"><span class="math display">\[var\left(
\widehat{\beta_{1} } \right) = \frac{ {\sigma_{\widehat{u} } }^{2} }{
{SST}_{x_{1} }(1 - {R_{x_{1} } }^{2})}\]</span></td>
</tr>
<tr>
<td>遗漏了变量的模型估计</td>
<td style="text-align: left;"><span class="math display">\[E\left(
\widetilde{\beta_{1} } \right) = \beta_{1} +
\beta_{2}\widetilde{\delta_{1} }\]</span></td>
<td style="text-align: left;"><span class="math display">\[var\left(
\widetilde{\beta_{1} } \right) = \frac{ {\sigma_{\widetilde{u} } }^{2}
}{ {SST}_{x_{1} } }\]</span></td>
</tr>
</tbody>
</table>
<p>那么，我们在抉择是否加入变量的时候就会陷入一个两难境地：一方面不加入变量，就会产生偏误，但方差是较小的；另一方面加入变量，不会产生偏误，但方差会加入膨胀因子导致偏大。那我们该如何抉择呢？</p>
<p>我们仍然选择加入变量！原因有以下两点（方差可以通过以下其余两种方式相对减小，但偏误只能看是否添加变量）：</p>
<p>①我们所研究的一般是大样本数据，随着样本数据量<span
class="math inline">\(n\)</span>的增加，会导致<span
class="math inline">\({SST}_{x_{1}
}\)</span>增大，那么方差就会减小，但偏误是不随着样本量而改变的，因此我们首选减小偏误；</p>
<p>②两个模型中方差的<span
class="math inline">\(\sigma^{2}\)</span>，也就是误差的平方和是不一样的。加入了变量，一般误差会更小一些，<span
class="math inline">\(\sigma^{2}\)</span>也会较小一些，即<span
class="math inline">\({\sigma_{\widehat{\beta_{1} } } }^{2} &lt;
{\sigma_{\widetilde{\beta_{1} } }
}^{2}\)</span>，这也在一定程度上缓解了由于膨胀因子出现而导致的方差偏大。</p>
<h3 id="系数估计量的方差估计">系数估计量的方差估计</h3>
<p>接下来我们对<span
class="math inline">\(\sigma^{2}\)</span>进行估计，进而去估计<span
class="math inline">\(var\left( \widehat{\beta_{1} }
\right)\)</span>：</p>
<p><span class="math display">\[{\widehat{\sigma} }^{2} =
\frac{\sum_{}^{}{\widehat{u_{i} } }^{2} }{n - k - 1}\]</span></p>
<p>其中，分母减去<span class="math inline">\(k +
1\)</span>是因为对于<span class="math inline">\(\widehat{u_{i}
}\)</span>一共有<span class="math inline">\(k +
1\)</span>个已有的约束条件（通过OLS估计中对各个系数求偏导而推导出来的数学性质），如下：</p>
<p><em><br />
</em><span class="math display">\[\sum_{}^{}\widehat{u_{i} } =
0\]</span></p>
<p><span class="math display">\[\sum_{}^{}{x_{li}\widehat{u_{i} } } = 0\
(l = 1,2\ldots,k)\]</span></p>
<p>那么系数估计量的标准误<span class="math inline">\(se\)</span>为：</p>
<p><span class="math display">\[se\left( \widehat{\beta_{1} } \right) =
\sqrt{var(\widehat{\beta_{1} })} = \sqrt{var(\widehat{\beta_{1} })} =
\sqrt{\frac{ {\widehat{\sigma} }^{2} }{ {SST}_{j}(1 - {R_{j} }^{2})} } =
\sqrt{\frac{\sum_{}^{}{\widehat{u_{i} } }^{2} }{ {SST}_{j}(1 - {R_{j}
}^{2})(n - k - 1)} }\]</span></p>
<p>标准差<span class="math inline">\(sd\)</span>（没啥用）为：</p>
<p><span class="math display">\[sd\left( \widehat{\beta_{1} } \right) =
\sqrt{var(\widehat{\beta_{1} })} = \sqrt{var(\widehat{\beta_{1} })} =
\sqrt{\frac{\sigma^{2} }{ {SST}_{j}(1 - {R_{j} }^{2})} }\]</span></p>
<h3 id="高斯马尔可夫定理">高斯马尔可夫定理</h3>
<p>在假设一到假设五的前提下，OLS估计是<mark>最优线性无偏</mark>估计量：</p>
<p><mark>线性</mark>是指，每一个<span
class="math inline">\(\widehat{\beta_{j}
}\)</span>都能写成关于因变量的线性组合<span
class="math inline">\(\widehat{\beta_{j} } = \sum_{}^{}{w_{ij}y_{i}
}\)</span>（<span
class="math inline">\(w_{ij}\)</span>为常数）。已知：</p>
<p><span class="math display">\[\widehat{\beta_{j} } =
\frac{\sum_{}^{}{\widehat{r_{ij} }y_{i} } }{\sum_{}^{}{\widehat{r_{ij} }
}^{2} }\]</span></p>
<p>其中，由于我们是确定了一组<span
class="math inline">\(x_{i1},x_{i2},\ldots,x_{ik}\)</span>，因此<span
class="math inline">\(x_{ij}\)</span>对其他自变量回归的每一个残差<span
class="math inline">\(\widehat{r_{ij}
}\)</span>也是确定的，可以看成常数。</p>
<p><mark>最优</mark>是指OLS方法估计出来的<span
class="math inline">\(\widehat{\beta_{j}
}\)</span>的方差小于其他所有线性无偏估计出来的系数估计量的方差。</p>
<h2 id="章末复习下次再看">章末复习【下次再看】</h2>
<h1 id="第4章-多元回归分析推断">第4章 多元回归分析：推断</h1>
<h2 id="ols估计量的抽样分布">OLS估计量的抽样分布</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1YG411C7KH/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第四章
4.1 单参数推断之【OLS估计量抽样分布】_哔哩哔哩_bilibili</a></p>
<p>新增<mark><u>假设六（误差正态性假设）</u></mark>：总体误差<span
class="math inline">\(u\)</span>独立于解释变量，并且服从于均值为0，方差为<span
class="math inline">\(\sigma^{2}\)</span>的正态分布。</p>
<p>这是一个非常强的假设，如果满足假设六，那么假设四（零条件均值）和假设五（同方差假设）将自动满足！</p>
<p>那么假设一到假设六被集体称作<span
class="math inline">\(CLM\)</span>假定（<u>经典线性模型假定</u>）</p>
<p>在高斯-马尔可夫假定下，OLS估计量是最优线性无偏估计量；而在<span
class="math inline">\(CLM\)</span>假定（经典线性模型假定）下，OLS估计量是最小方差无偏估计量（不再局限于线性）。</p>
<p>用图形来总结<span class="math inline">\(CLM\)</span>总体假定：</p>
<p><img src="https://s2.loli.net/2025/01/28/l3ar8eMPvZG5jsE.png"
style="width:3.64866in;height:2.65457in" /></p>
<p>其中，误差<span class="math inline">\(u\sim
N(0,\sigma^{2})\)</span>，那么<span class="math inline">\(y|x\sim
N(\beta_{0} + \beta_{1}x_{1} + \beta_{2}x_{2} +
\beta_{3}x_{3},\sigma^{2})\)</span>。图中在给定<span
class="math inline">\(x\)</span>后，<span
class="math inline">\(y\)</span>的取值满足正态分布。</p>
<p>因此，估计量<span class="math inline">\(\widehat{\beta_{j}
}\)</span>也是服从正态分布：</p>
<p><span class="math display">\[\widehat{\beta_{j} }\sim
N(\beta_{j},var(\widehat{\beta_{j} }))\]</span></p>
<p>证明：</p>
<p>已知：</p>
<p><span class="math display">\[\widehat{\beta_{j} } = \beta_{j} +
\frac{\sum_{}^{}r_{ij}u_{i} }{\sum_{}^{}{r_{ij} }^{2} }\]</span></p>
<p>在给定<span class="math inline">\(x\)</span>的条件下，<span
class="math inline">\(\widehat{\beta_{j} }\)</span>是<span
class="math inline">\(u_{i}\)</span>的线性组合，已知<span
class="math inline">\(u_{i}\)</span>服从正态分布，那么<span
class="math inline">\(\widehat{\beta_{j}
}\)</span>也肯定服从正态分布。</p>
<p>①系数估计量的正态分布标准化</p>
<p>那么我对<span class="math inline">\(\widehat{\beta_{j}
}\)</span>进行标准化：</p>
<p><span class="math display">\[\frac{\widehat{\beta_{j} } - \beta_{j}
}{sd(\widehat{\beta_{j} })}\sim N(0,1)\]</span></p>
<p>②系数估计量的联合正态分布性质</p>
<p>其次，由于任何一个系数估计量都服从正态分布，那么它们的线性组合也是同样服从联合正态分布的。</p>
<h2 id="ols估计量的假设检验">OLS估计量的假设检验</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1kc411f7wz/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第四章
4.1 单参数推断之【假设检验】_哔哩哔哩_bilibili</a></p>
<p>前提知识</p>
<p><mark>假设检验（</mark><span class="math inline">\(Hypothesis\
Test\)</span><mark>）</mark>的概念：事先对<u>总体参数</u>或总体分布形式作出某种假设，然后利用<u>样本信息</u>来判断原假设是否成立。其中总体参数是指总体数据的期望、方差等，对于样本是没有"参数"一说，与之对应的是"统计量"。"样本信息"指的就是样本统计量或者说是检验统计量。</p>
<p>基本逻辑：反证。基于原假设，得到现有样本结果的可能性有多大。</p>
<p>基本原理：小概率原理。小概率事件在一次事件中几乎不可能发生。在一次试验中小概率事件一旦发生了，我们就有理由拒绝原假设。</p>
<p>具体来说，我们基于原假设，去判断得到现有样本结果的概率有多大。如果出现这样的样本的概率很小，根据小概率原理我们认为其发生的概率应该为0，但事实上这样的样本已经出现了，矛盾了，那么说明原假设有问题了，因此就有理由去拒绝原假设。那么我们如何计算出"得到现有样本结果的可能性"呢？就需要计算样本/检验统计量的分布。</p>
<p>那接下来正式进入OLS估计量的假设检验：</p>
<p>·检验目标。<span
class="math inline">\(\beta_{j}\)</span>总体参数；</p>
<p>·零假设。<span class="math inline">\(H_{0}:\beta_{j} =
0\)</span>，也就是假设保持其他变量不变的情况下，<span
class="math inline">\(x_{j}\)</span>对<span
class="math inline">\(y\)</span>的偏效应为0。这样设计的原因在于我们最后想要拒绝原假设，也就是在其他变量都给定的情况下，<span
class="math inline">\(x_{j}\)</span>对<span
class="math inline">\(y\)</span>的偏效不为0，也就是有影响；</p>
<p>·备择假设<span
class="math inline">\(H_{1}\)</span>。区分为单侧假设检验（<span
class="math inline">\(\beta_{j} &gt; 0\)</span>或<span
class="math inline">\(\beta_{j} &lt; 0\)</span>）和双侧假设检验（<span
class="math inline">\(\beta_{j} \neq 0\)</span>）；</p>
<p>·检验统计量。其目标在于帮助我们判断样本出现的可能性，如<span
class="math inline">\(\widehat{\beta_{j} }\)</span>。</p>
<p>在<span
class="math inline">\(CLM\)</span>的假定下，我们有如下定理（标准化估计量的<span
class="math inline">\(t\)</span>分布）：</p>
<p><span class="math display">\[\frac{\widehat{\beta_{j} } - \beta_{j}
}{se(\widehat{\beta_{j} })}\sim t_{n - k - 1} = t_{df}\]</span></p>
<p><span class="math inline">\(\widehat{\beta_{j}
}\)</span>减去其期望，再除以标准误后（标准化估计量），符合自由度为<span
class="math inline">\(n - k - 1\)</span>的<span
class="math inline">\(t\)</span>分布，也可以记作<span
class="math inline">\(t_{df}\)</span>。其中需要注意：</p>
<p>·上面我们有：统计量<span
class="math inline">\(\frac{\widehat{\beta_{j} } - \beta_{j}
}{sd(\widehat{\beta_{j} })}\)</span>是服从正态分布，而在这里统计量<span
class="math inline">\(\frac{\widehat{\beta_{j} } - \beta_{j}
}{se(\widehat{\beta_{j} })}\)</span>是服从<span
class="math inline">\(t\)</span>分布。</p>
<p>·对于某个具体的样本，我们能够算出<span
class="math inline">\(\widehat{\beta_{j} }\)</span>和<span
class="math inline">\(se(\widehat{\beta_{j}
})\)</span>，同时基于前面的零假设（一般是<span
class="math inline">\(\beta_{j} = 0\)</span>），我们就能够计算出<span
class="math inline">\(\frac{\widehat{\beta_{j} } - \beta_{j}
}{se(\widehat{\beta_{j} })}\)</span>，我们把这个值叫做<span
class="math inline">\(t\)</span>统计量/<span
class="math inline">\(t\)</span>比率。</p>
<p>·那么<span
class="math inline">\(t\)</span>统计量如何帮我们判断样本出现的概率？每一个t统计量对应一个概率，那么我们就能够得出在t统计量大于多少时，概率足够小，小到我们认为应该拒绝原假设。</p>
<p>因此，通过构造<u>拒绝域</u>来构建假设检验的具体流程如下：</p>
<p>①确定一个临界值<span class="math inline">\(C\)</span>，<span
class="math inline">\(C\)</span>值受到<span
class="math inline">\(t\)</span><u>分布的自由度（形状）</u>和<u>显著性水平</u>的影响，从而确定拒绝域。显著性水平指的是<span
class="math inline">\(H_{0}\)</span>成立时，把<span
class="math inline">\(H_{0}\)</span>拒绝的概率（也叫做第一类错误，即将概率小的事件看作概率为0）</p>
<p>②计算样本<span class="math inline">\(t\)</span>统计量/比率；</p>
<p>③对比<span
class="math inline">\(t\)</span>统计量是否处于拒绝域，得出结论。如果计算出<span
class="math inline">\(t\)</span>统计量处于拒绝域中，我们就有理由拒绝原假设；如果不在拒绝域中，我们就没有理由拒绝原假设。</p>
<p>需要注意的是，根据备择假设的不同，拒绝域的位置也有所不同，如下图（<span
class="math inline">\(\beta_{j}\)</span>&gt;0所以<span
class="math inline">\(t\)</span>统计量才计算出为正的）：</p>
<p><img src="https://s2.loli.net/2025/01/28/p9xPdyhO4RSMmZs.jpg"
style="width:5.76806in;height:3.57917in" /></p>
<p>备择假设<span class="math inline">\(H_{1}：\beta_{j} \neq
0\)</span></p>
<p>备择假设<span class="math inline">\(H_{1}：\beta_{j} &lt;
0\)</span></p>
<p>备择假设<span class="math inline">\(H_{1}：\beta_{j} &gt;
0\)</span></p>
<p>通过拒绝域来进行假设检验是一个经典的方法，但也存在一定问题。因为这种办法需要预设显著性水平和拒绝域，而不同研究者偏好不同的显著性水平。比如，研究结论是在5%的显著性水平下，未能拒绝该假设。那么在10%显著性水平之下能够拒绝呢？我们就会有这样的疑问。我们更想要了解的问题是，既然已经能够计算出<span
class="math inline">\(t\)</span>统计量，那么能够拒绝原假设的最小显著性水平是多少呢？</p>
<p>这个最小的显著性水平就是计算出<span
class="math inline">\(t\)</span>统计量所对应的概率，或者说大于计算出<span
class="math inline">\(t\)</span>统计量的概率，即<span
class="math inline">\(P\)</span>值。</p>
<p>因此，<span
class="math inline">\(P\)</span>值是指当原假设成立时，观察到的<span
class="math inline">\(t\)</span>统计量至少和我们所得到的<span
class="math inline">\(t\)</span>统计量一样大的概率。</p>
<p>那么通过<span
class="math inline">\(P\)</span>值进行假设检验的步骤如下：</p>
<p>①计算样本<span class="math inline">\(t\)</span>比率；</p>
<p>②计算样本<span class="math inline">\(t\)</span>比率所对应的<span
class="math inline">\(P\)</span>值；</p>
<p>如果时双侧就是计算<span class="math inline">\(P(|T| \geq
t)\)</span>；如果时单侧，当<span class="math inline">\(H_{1}：\beta_{j}
&gt; 0\)</span>，则计算<span class="math inline">\(P(T \geq
t)\)</span>，当<span class="math inline">\(H_{1}：\beta_{j} &lt;
0\)</span>，则计算<span class="math inline">\(P(T \leq t)\)</span></p>
<p>③将<span class="math inline">\(P\)</span>值与显著性水平（<span
class="math inline">\(\alpha\)</span>）进行对比。常用<span
class="math inline">\(\alpha = 0.05或0.01或0.1\)</span>。</p>
<p>有如下注意要点：</p>
<p>·要注意是单侧还是双侧备择假设。一般软件给出的是双侧检验的<span
class="math inline">\(P\)</span>值，那如果使用单侧检验的话，就是除以2。</p>
<p>·如果使用的样本特别小（不超过40个），那么这可以酌情把<span
class="math inline">\(\alpha\)</span>扩展到20%。其原因是，样本量很小，导致<span
class="math inline">\({SST}_{j}\)</span>很小，<span
class="math inline">\(var\left( \widehat{\beta_{j} } \right) =
\frac{\sigma^{2} }{ {SST}_{j}(1 - {R_{j} }^{2})}\)</span>很大，<span
class="math inline">\(se\left( \widehat{\beta_{j} }
\right)\)</span>很大，<span class="math inline">\(t\)</span>统计量<span
class="math inline">\(|\frac{\widehat{\beta_{j} } - \beta_{j} }{se\left(
\widehat{\beta_{j} } \right)}|\)</span>的绝对值很小，导致<span
class="math inline">\(P\)</span>值很大，很难显著。</p>
<p>·拒绝了原假设，则说明<span
class="math inline">\(\beta_{j}\)</span>具有统计显著性，也就是考虑了<span
class="math inline">\(\widehat{\beta_{j}
}\)</span>的不确定性和随机性之后，还能说<span
class="math inline">\(\beta_{j}\)</span>是大于零还是小于零。但在实际问题中，还需要关注其经济显著性，观察它的大小、量纲、是否为对数形式等。</p>
<h2 id="ols估计量的置信区间">OLS估计量的置信区间</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1sa4y1X7oG/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第四章
4.1 单参数推断之【区间估计】_哔哩哔哩_bilibili</a></p>
<p>在多元回归中，我们通过一组样本，能够估计出<span
class="math inline">\(\beta_{j}\)</span>：</p>
<p><span class="math display">\[\widehat{\beta_{j} } =
\frac{\sum_{}^{}r_{ij}y_{i} }{\sum_{}^{}{r_{ij} }^{2} }\]</span></p>
<p>这个就叫做点估计。但是我们无法通过<span
class="math inline">\(\widehat{\beta_{j} }\)</span>去验证<span
class="math inline">\(\beta_{j}\)</span>到底是多少，只能通过无偏性和方差来验证估计量能够代表真值的程度。但是，我们更想要知道的，是<span
class="math inline">\(\beta_{j}\)</span>大致处于什么范围。出于这个目的，我们设计出区间估计，即为<span
class="math inline">\(\beta_{j}\)</span>构造一个置信区间，表示总体参数<span
class="math inline">\(\beta_{j}\)</span>可能的取值范围，如<span
class="math inline">\(P\left( \beta_{j}\epsilon 区间 \right) =
95\%\)</span>，这里的"95%"就叫做"置信度/水平"</p>
<p>在上一节已经有：</p>
<p><span class="math display">\[\frac{\widehat{\beta_{j} } - \beta_{j}
}{se(\widehat{\beta_{j} })}\sim t_{n - k - 1}\]</span></p>
<p>左式中有<span
class="math inline">\(\beta_{j}\)</span>，而其余的量又是可以求出的。因此，我们希望构造出以下这样的式子：</p>
<p><span class="math display">\[P\left( \left| \frac{\widehat{\beta_{j}
} - \beta_{j} }{se\left( \widehat{\beta_{j} } \right)} \right| \leq C
\right) = 95\%\]</span></p>
<p>对其进行去绝对值变换：</p>
<p><span class="math display">\[P\left( {\widehat{\beta_{j} } - se\left(
\widehat{\beta_{j} } \right)*C \leq \beta}_{j} \leq \widehat{\beta_{j} }
+ se\left( \widehat{\beta_{j} } \right)*C \right) = 95\%\]</span></p>
<p>或者表示成：</p>
<p><span class="math display">\[P\left( \beta_{j} \in
(\widehat{\beta_{j} } \pm se\left( \widehat{\beta_{j} } \right)*C)
\right) = 95\%\]</span></p>
<p><img src="https://s2.loli.net/2025/01/28/5HuaepMcw7vgr6z.png"
style="width:3.85188in;height:2.12569in" /></p>
<p>那么，对于这个式子我们有以下几点需要注意：</p>
<p>①计算这个置信区间需要计算三个量：<span
class="math inline">\(\widehat{\beta_{j} }\)</span>、<span
class="math inline">\(se\left( \widehat{\beta_{j} }
\right)\)</span>、<span
class="math inline">\(C\)</span>（根据置信度和自由度查<span
class="math inline">\(t\)</span>分布表得出）</p>
<p>②我们计算出的这个置信区间实际上是一个随机区间，对于每一组样本都有不同的<span
class="math inline">\(\widehat{\beta_{j} }\)</span>、<span
class="math inline">\(se\left( \widehat{\beta_{j} }
\right)\)</span>，那么计算出的置信区间就是不同的。</p>
<p>③那么我们就可以对<span class="math inline">\(P\left(
\beta_{j}\epsilon 区间 \right) =
95\%\)</span>进一步理解，即通过样本构造的所有置信区间中，有95%的置信区间覆盖了真值<span
class="math inline">\(\beta_{j}\)</span>。</p>
<p>④置信区间和假设检验的关系。举例，已知<span
class="math inline">\(P\left( \beta_{j}\epsilon(0.02,0.05) \right) =
95\%\)</span>，那么原假设<span class="math inline">\(\beta_{j} =
0\)</span>能否在5%的显著性水平下能否被拒绝？可以被拒绝！原因如下：</p>
<p>先看置信区间，由于<span class="math inline">\(P\left(
\beta_{j}\epsilon(0.02,0.05) \right) =
95\%\)</span>，置信度为95%，也就是检验出的<span
class="math inline">\(t\)</span>统计量落在<span class="math inline">\((
- C_{1},C_{1})\)</span>之间，其中<span class="math inline">\(P( -
C_{1},C_{1})\)</span>=95%，那么<span class="math inline">\(P\left\lbrack
\left( - \infty, - C_{1} \right) \cup \left( C_{1}, + \infty \right)
\right\rbrack = 5\%\)</span>。</p>
<p>再看假设检验，由于显著性水平设置为5%，那么对于双侧检验来说，<span
class="math inline">\(P(拒绝域) = P\left\lbrack \left( - \infty, - C_{2}
\right) \cup \left( C_{2}, + \infty \right) \right\rbrack =
5\%\)</span>，从而得出<span class="math inline">\(C_{1} =
C_{2}\)</span>。那么置信区间所对应的<span class="math inline">\(( -
C_{1},C_{1})\)</span>就是假设检验中的接受域。只有当假设检验中的原假设<span
class="math inline">\(\beta_{j}\)</span>的值落在置信区间时，假设检验计算出的<span
class="math inline">\(t\)</span>统计量才落在接受域中，但是原假设<span
class="math inline">\(\beta_{j} =
0不属于(0.02,0.05)\)</span>，所以其计算出的<span
class="math inline">\(t\)</span>统计量不在接受域而在拒绝域中，因此拒绝原假设。在这个问题中有两个点需要注意：一是是否<span
class="math inline">\(C_{1} =
C_{2}\)</span>；二是置信区间和假设检验的<span
class="math inline">\(t\)</span>统计量是不同的，置信区间算的是<span
class="math inline">\(t\)</span>统计量的一个范围，假设检验是利用原假设算出<span
class="math inline">\(t\)</span>统计量的一个值。</p>
<h2 id="多参数检验">多参数检验</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV14M411Q7M4/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第四章
4.2 多参数推断_哔哩哔哩_bilibili</a></p>
<h3 id="检验参数的线性组合">检验参数的线性组合</h3>
<p>例子：教育的经济回报</p>
<p><span class="math display">\[\log(wage) = \beta_{0} + \beta_{1}jc +
\beta_{2}univer + \beta_{3}exper + u\]</span></p>
<p>其中，<span class="math inline">\(jc\)</span>表示读大专的年份，<span
class="math inline">\(univer\)</span>表示读大学的年份。</p>
<p>如果我们要检验：上大学是否对工资有影响？那么这就是一个单参数检验，原假设<span
class="math inline">\(H_{0}:\beta_{2} = 0\)</span>。</p>
<p>如果我们要检验：在大专上一年学是否与在大学上一年学效应相同？那么这就是一个多参数检验。原假设<span
class="math inline">\(H_{0}:\beta_{1} =
\beta_{2}\)</span>，备择假设可以是：<span
class="math inline">\(H_{1}:\beta_{1} &lt; \beta_{2}\)</span>。</p>
<p>那么如何对多参数进行检验呢？有如下两种方法：</p>
<p><mark>方法一</mark>：直接求解</p>
<p>我们将多参数检验的原假设变换为我们熟悉的单参数检验原假设，即变换为：</p>
<p><span class="math display">\[H_{0}:\beta_{1} - \beta_{2} =
0\]</span></p>
<p><span class="math display">\[H_{1}:\beta_{1} - \beta_{2} &lt;
0\]</span></p>
<p>那么，我们构造检验<span class="math inline">\(t\)</span>统计量：</p>
<p><span class="math display">\[\frac{\left( \widehat{\beta_{1} } -
\widehat{\beta_{2} } \right) - (\beta_{1} -
\beta_{2})}{se(\widehat{\beta_{1} } - \widehat{\beta_{2}
})}\]</span></p>
<p>其中，<span class="math inline">\(\beta_{1} - \beta_{2} =
0\)</span>，<span class="math inline">\(\widehat{\beta_{1} } -
\widehat{\beta_{2} }\)</span>能够通过一组数据估计出来，<span
class="math inline">\(se\left( \widehat{\beta_{1} } - \widehat{\beta_{2}
} \right) = \sqrt{ {se}^{2}\left( \widehat{\beta_{1} } \right) +
{se}^{2}\left( \widehat{\beta_{2} } \right) - 2s_{12}
}\)</span>，其中<span class="math inline">\(s_{12}\)</span>表示<span
class="math inline">\(cov(\widehat{\beta_{1} } - \widehat{\beta_{2}
})\)</span>的一个估计值，也能够直接算出。</p>
<p><mark>方法二</mark>：模型变换法（更常用）</p>
<p>我们假设<span class="math inline">\({\theta_{1} = \beta}_{1} -
\beta_{2}\)</span>，那么有<span class="math inline">\(\beta_{1} =
\beta_{2} + \theta_{1}\)</span>。</p>
<p>那么，我们的原假设、备择假设和<span
class="math inline">\(t\)</span>统计量分别是：</p>
<p><span class="math display">\[H_{0}:\theta_{1} = 0\]</span></p>
<p><span class="math display">\[H_{0}:\theta_{1} &lt; 0\]</span></p>
<p><span class="math display">\[\frac{\widehat{\theta_{1} }
}{se(\widehat{\theta_{1} })}\]</span></p>
<p>由此，我们可以将原模型进行改写为：</p>
<p><span class="math display">\[\log(wage) = \beta_{0} + \theta_{1}jc +
\beta_{2}(jc + univer) + \beta_{3}exper + u\]</span></p>
<p>模型中共有三个变量：<span class="math inline">\(jc\)</span>、<span
class="math inline">\(jc + univer\)</span>、<span
class="math inline">\(exper\)</span>。对这个模型中的参数<span
class="math inline">\(\theta_{1}\)</span>进行检验统计，就有我们想要的<span
class="math inline">\(t\)</span>统计量<span
class="math inline">\(\frac{\widehat{\theta_{1} }
}{se(\widehat{\theta_{1} })}\)</span>。</p>
<h3 id="对多个线性约束的检验">对多个线性约束的检验</h3>
<p>对于上述的单参数或者多参数的线性组合检验，我们都能够看成是一个线性约束（<span
class="math inline">\(H_{0}:\theta_{1} =
0\)</span>）的检验，那么对于多个线性约束（如<span
class="math inline">\(H_{0}:\beta_{1} = 0,\beta_{2} =
0\)</span>）我们该如何进行假设检验呢？</p>
<h4 id="对排除性约束的检验">对排除性约束的检验</h4>
<p>排除性约束是指：排除一组自变量对<span
class="math inline">\(y\)</span>的影响的约束。</p>
<p>举例：</p>
<p><span class="math display">\[\log(salary)\]</span></p>
<p><span class="math display">\[= \beta_{0} + \beta_{1}years +
\beta_{2}gamesyr + \beta_{3}bavg + \beta_{4}hrunsyr + \beta_{5}rbisyr +
u\]</span></p>
<p>我们想要检验：当控制了其中两个变量（<span
class="math inline">\(years\)</span>和<span
class="math inline">\(gamesyr\)</span>），其余的变量都无法影响因变量了。此时，我们的假设检验原假设和备择假设就是：</p>
<p><span class="math display">\[H_{0}:\beta_{3} = 0,\beta_{4} =
0,\beta_{5} = 0\]</span></p>
<p><span class="math display">\[H_{1}:H_{0}不正确\]</span></p>
<p>此时，原假设就叫做<mark><u>排除性约束</u></mark>，是多重约束（多个线性约束）的一个特例。对多重约束进行检验就叫做多重假设检验，或者是联合假设检验。为了对排序性约束进行假设检验，我们需要设定一下两个模型：</p>
<p>模型一：不受约束的模型（即原始模型）</p>
<p><span class="math display">\[\log(salary)\]</span></p>
<p><span class="math display">\[= \beta_{0} + \beta_{1}years +
\beta_{2}gamesyr + \beta_{3}bavg + \beta_{4}hrunsyr + \beta_{5}rbisyr +
u\]</span></p>
<p>模型二：受约束的模型（满足原假设条件的模型）</p>
<p><span class="math display">\[\log(salary)\]</span></p>
<p><span class="math display">\[= \beta_{0} + \beta_{1}years +
\beta_{2}gamesyr + u\]</span></p>
<p>比较两个模型，我们能够得出模型二的残差平方和<span
class="math inline">\(SSR\)</span>至少是大于模型一的残差平方和，因为模型二减少了三个变量，必定有一些波动是无法被解释到的（或者这样去想，假设模型二估计出了最优的系数，那么模型一至少能在模型二最优系数的基础上再进一步优化，去逼近真实值）。那么，我们的问题是：<span
class="math inline">\(SSR\)</span>增加到什么程度，我们有理由拒绝原假设？换言之，<span
class="math inline">\(SSR\)</span>的增加反映出变量的相关性，<span
class="math inline">\(SSR\)</span>越大，说明被约束的变量发挥了越大的作用（导致两个模型的解释力差距大），我们就有理由拒绝原假设（被约束的变量对因变量是没有影响的）。</p>
<p>因此我们需要验证，当原假设<span
class="math inline">\(H_{0}\)</span>成立时，检验统计量<span
class="math inline">\(SSR\)</span>的变化幅度。</p>
<p>我们构造出<span class="math inline">\(F\)</span>统计量如下：</p>
<p><span class="math display">\[\frac{({SSR}_{r} - {SSR}_{ur})/q}{
{SSR}_{ur}/(n - k - 1)}\]</span></p>
<p>其中，<span
class="math inline">\({SSR}_{r}\)</span>是指受约束的模型的残差平方和。<span
class="math inline">\({SSR}_{ur}\)</span>是指不受约束的模型的残差平方和。<span
class="math inline">\(q\)</span>指的是原假设的约束条件个数，在上面的例子中<span
class="math inline">\(q = 3\)</span>。<span class="math inline">\(n - k
- 1\)</span>是自由度。其符合<span class="math inline">\(F_{q,n - k -
1}\)</span>分布。计算出的<span
class="math inline">\(F\)</span>统计量越大，则<span
class="math inline">\({SSR}_{r}\)</span>相对于<span
class="math inline">\({SSR}_{ur}\)</span>的比例就越大，我们就越有理由去拒绝原假设。</p>
<p>其中有以下这些要点需要注意：</p>
<p>①<span
class="math inline">\(F\)</span>检验也可以对单约束进行检验；</p>
<p>②统计量<span class="math inline">\(t^{2} = F\)</span>，分布<span
class="math inline">\({t_{n - k - 1} }^{2} = F_{q，n - k -
1}\)</span>；</p>
<p>③<span class="math inline">\(F\)</span>检验和<span
class="math inline">\(t\)</span>检验的结果并不完全一致，可能出现在<span
class="math inline">\(t\)</span>检验中，不能拒绝<span
class="math inline">\(\beta_{3} = 0\)</span>；但在<span
class="math inline">\(F\)</span>检验中，可以拒绝<span
class="math inline">\(\beta_{3} = 0,\beta_{4} = 0,\beta_{5} =
0\)</span>（其原因可能是<span
class="math inline">\(\beta_{4}\)</span>或<span
class="math inline">\(\beta_{5}\)</span>带来的，也有可以是<span
class="math inline">\(x_{4}\)</span>、<span
class="math inline">\(x_{5}\)</span>和<span
class="math inline">\(x_{3}\)</span>存在相关性，导致<span
class="math inline">\(se(\widehat{\beta_{3} })\)</span>很大，<span
class="math inline">\(t\)</span>统计量就很小）；也有很能出现在<span
class="math inline">\(t\)</span>检验中，拒绝<span
class="math inline">\(\beta_{3} = 0\)</span>；但在<span
class="math inline">\(F\)</span>检验中，不能拒绝<span
class="math inline">\(\beta_{3} = 0,\beta_{4} = 0,\beta_{5} =
0\)</span>。因此可以说，<span
class="math inline">\(F\)</span>检验的功效是低于<span
class="math inline">\(t\)</span>检验的。一个检验的"功效"是指一个检验拒绝错误假设的能力，即功效<span
class="math inline">\(\pi(\theta) = P\left( 拒绝\theta_{0} \middle|
\theta_{0} \right) = 1 -
P(犯第二类错误)\)</span>。"犯第二类错误"是指接受错误假设。（第一类错误是指拒绝正确假设）。</p>
<p>④可以将<span class="math inline">\(F\)</span>统计量进行改写：</p>
<p><span class="math display">\[\frac{({SSR}_{r} - {SSR}_{ur})/q}{
{SSR}_{ur}/(n - k - 1)} = \frac{({R_{ur} }^{2} - {R_{r} }^{2})/q}{(1 -
{R_{ur} }^{2})/n - k - 1}\]</span></p>
<p>其中需要注意，不受约束的模型的<span class="math inline">\({R_{ur}
}^{2}\)</span>至少大于受约束的模型<span class="math inline">\({R_{r}
}^{2}\)</span>的。因为两个模型的<span
class="math inline">\(SST\)</span>相同，不受约束的模型的解释力至少大于受约束模型的解释力。</p>
<h4 id="回归整体显著性的mathbff统计量">回归整体显著性的<span
class="math inline">\(\mathbf{F}\)</span>统计量</h4>
<p>回归整体显著性就是指模型中的所有<span
class="math inline">\(x\)</span>都是不显著的。</p>
<p>那么，不受约束的模型是：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + \ldots + \beta_{k}x_{k} + u\]</span></p>
<p>原假设是：</p>
<p><span class="math display">\[H_{0}:\beta_{i} = 0,i = 1\ldots
k\]</span></p>
<p>受约束的模型是：</p>
<p><span class="math display">\[y = \beta_{0} + u\]</span></p>
<p><span class="math inline">\(F\)</span>统计量是：</p>
<p><span class="math display">\[\frac{ {R_{ur} }^{2}/k}{(1 - {R_{ur}
}^{2})/n - k - 1}\]</span></p>
<p>在实际问题中，回归整体显著性的<span
class="math inline">\(F\)</span>统计量检验应该是高度显著的，否则大概率说明模型构建错误，不能反映自变量和因变量的关系。</p>
<h4 id="检验一般性的线性约束">检验一般性的线性约束</h4>
<p>举例：</p>
<p><span class="math display">\[\log(price) = \beta_{0} +
\beta_{1}log(assess) + \beta_{2}log(lotsize) + \beta_{3}log(sqrft) +
\beta_{4}bdrms + u\]</span></p>
<p>其中，<span class="math inline">\(price\)</span>是住房价格，<span
class="math inline">\(assess\)</span>是住房的评估价值，<span
class="math inline">\(lotsize\)</span>是占地面积（以英尺为单位），<span
class="math inline">\(sqrft\)</span>是平方英尺数，<span
class="math inline">\(bdrms\)</span>是卧室数。我们想要知道，<span
class="math inline">\(assess\)</span>是不是一个理性的定价，即<span
class="math inline">\(assess\)</span>变化原来的1%，<span
class="math inline">\(price\)</span>也变化原来的1%，并且是在控制其他变量的前提下。那么原假设是：</p>
<p><span class="math display">\[H_{0}:\beta_{1} = 1,\beta_{2} =
\beta_{3} = \beta_{4} = 0\]</span></p>
<p>为了解决这个问题，我们同样使用<span
class="math inline">\(F\)</span>检验，需要写出不受约束的模型和受约束的模型：</p>
<p>不受约束的模型：<br />
<span class="math display">\[\log(price) = \beta_{0} +
\beta_{1}log(assess) + \beta_{2}log(lotsize) + \beta_{3}log(sqrft) +
\beta_{4}bdrms + u\]</span></p>
<p>受约束的模型：<br />
<span class="math display">\[\log(price) = \beta_{0} + log(assess) +
u\]</span></p>
<p>我们将受约束的模型进一步变换有：</p>
<p><span class="math display">\[\log(price) - log(assess) = \beta_{0} +
u\]</span></p>
<p>此时我们构建<span class="math inline">\(F\)</span>统计量：</p>
<p><span class="math display">\[\frac{({SSR}_{r} - {SSR}_{ur})/q}{
{SSR}_{ur}/(n - k - 1)}\]</span></p>
<p>在这里我们需要使用原始的构建公式，而不能使用<span
class="math inline">\(R^{2}\)</span>进行转换，其原因是变换后的受约束模型的<span
class="math inline">\(y\)</span>和不受约束模型的<span
class="math inline">\(y\)</span>不一样了，那么两者的<span
class="math inline">\(SST\)</span>也是不一样的。</p>
<h4 id="回归结果的一般报告形式">回归结果的一般报告形式</h4>
<p>伍德里奇建议在报告回归结果时，需要包括加入自变量的系数、标准误，总体模型的<span
class="math inline">\(R^{2}\)</span>，以及观测数。如下图所示：</p>
<p><img src="https://s2.loli.net/2025/01/28/oklTgECsJFv3Ya6.png"
style="width:5.76806in;height:2.77014in" /></p>
<p>4.5章末复习【下次再看】</p>
<h1 id="第5章-多元回归分析ols的渐近性质">第5章
多元回归分析：OLS的渐近性质</h1>
<h2 id="ols估计量的一致性假设1-4">OLS估计量的一致性（假设1-4）</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1vQ4y1J7ft/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第五章
5.1 OLS估计量的渐近性质【一致性】_哔哩哔哩_bilibili</a></p>
<p>需要一些预备知识：</p>
<p>在本节课，我们探讨的是大样本性质，也称作渐近性质（Asymptotic
Properties），即考虑样本量无限增加的情况。而在前面，我们所探讨的是小样本性质，即有限样本或精确性质，针对特定样本量。</p>
<p><mark>尤其注意，在这一章中我们讨论一致性都是基于大样本的前提下，也就是在总体数据中进行讨论</mark>。</p>
<p><img src="https://s2.loli.net/2025/01/28/gyP2kzdpES1WNAr.png"
style="width:6.06409in;height:1.7949in" /></p>
<h3 id="一致性的定义">一致性的定义：</h3>
<p><img src="https://s2.loli.net/2025/01/28/eg1BjREVoFNsuGf.png"
style="width:5.76806in;height:1.06389in" /></p>
<p>上述定义中的<span
class="math inline">\(\theta\)</span>相当于系数真值<span
class="math inline">\(\beta_{j}\)</span>，而<span
class="math inline">\(W_{n}\)</span>相当于对<span
class="math inline">\(\beta_{j}\)</span>的估计量<span
class="math inline">\(\widehat{\beta_{j}
}\)</span>（n表示一个样本中一共有<span
class="math inline">\(n\)</span>个观测），则有<span
class="math inline">\(plim\left( \widehat{\beta_{j} } \right) =
\beta_{j}\)</span>，<span
class="math inline">\(\beta_{j}\)</span>是<span
class="math inline">\(\widehat{\beta_{j} }\)</span>的概率极限。</p>
<p>对我们可以通过以下这张图进行理解。图中共有样本观测量分别为4，16，40的三条曲线，纵坐标为系数估计量的抽样概率密度。由于估计的无偏性，三条曲线的期望都是真实值<span
class="math inline">\(\theta\)</span>，但随着样本容量越来越大，估计量<span
class="math inline">\(W_{n}\)</span>离开真实值<span
class="math inline">\(\theta\)</span>很远的可能性越来越小，换言之，估计值<span
class="math inline">\(W_{n}\)</span>与真实值<span
class="math inline">\(\theta\)</span>的距离大于<span
class="math inline">\(\varepsilon\)</span>的可能性越来越小趋于零，由下图可知蓝色面积（<span
class="math inline">\(n = 4\)</span>）大于绿色面积（<span
class="math inline">\(n = 16\)</span>）大于红色面积（<span
class="math inline">\(n = 40\)</span>）。</p>
<p>从中能够看出，期望是一个静态的点，而概率极限是动态的变化趋势。</p>
<p><img src="https://s2.loli.net/2025/01/28/IbHvYLoi4CqhXM8.png"
style="width:5.38222in;height:4.19466in" /></p>
<h3 id="一致性的性质">一致性的性质</h3>
<p>①性质一：估计量的函数的概率极限=估计量的概率极限的函数</p>
<p><img src="https://s2.loli.net/2025/01/28/gvWsQe1MYdn5qrj.png"
style="width:5.76806in;height:1.1in" /></p>
<p>例子：</p>
<p>我们在估计系数方差时，假设了在确定一组样本时，误差的方差是<span
class="math inline">\(\sigma^{2}\)</span>，即<span
class="math inline">\(var\left( u_{i} \middle|
x_{i1},x_{i2},x_{i3},\ldots,x_{ik} \right) =
\sigma^{2}\)</span>。对<span
class="math inline">\(\sigma^{2}\)</span>进行估计得到<span
class="math inline">\({\widehat{\sigma} }^{2} =
\frac{\sum_{}^{}{\widehat{u_{i} } }^{2} }{n - k -
1}\)</span>，这是一个无偏估计量，可以证明<span
class="math inline">\(E\left( {\widehat{\sigma} }^{2} \right) =
\sigma^{2}\)</span>，但是基于这个等式，我们无法继续推出<span
class="math inline">\(E\left( \widehat{\sigma} \right) =
\sigma\)</span>，因为期望不能进行开根号运算。</p>
<p>但是，如果我们从概率极限的角度思考。因为<span
class="math inline">\(plim\left( {\widehat{\sigma} }^{2} \right) =
\sigma^{2}\)</span>，那么我们对估计量<span
class="math inline">\({\widehat{\sigma}
}^{2}\)</span>施加一个开根号的函数，估计量的函数的概率极限等于估计量的概率极限的函数，所以我们能够对其概率极限也施加一个开根号的运算，则有<span
class="math inline">\(plim\left( \widehat{\sigma} \right) =
\sigma\)</span>。这就是概率极限与期望所不一样的地方。</p>
<p>②性质二：线性运算</p>
<p>估计量之间运算的概率极限=估计量的概率极限的运算</p>
<p><img src="https://s2.loli.net/2025/01/28/uwe2orQHn1IySF4.png"
style="width:3.29878in;height:1.50008in" /></p>
<p>根据上述关于"一致性"的定义和性质，我们能够推导出以下的定理</p>
<h3
id="一致性的定理mathbfplimleft-widehatmathbfbeta_mathbfj-rightmathbfmathbfbeta_mathbfj">一致性的定理<span
class="math inline">\(\mathbf{plim}\left(
\widehat{\mathbf{\beta}_{\mathbf{j} } }
\right)\mathbf{=}\mathbf{\beta}_{\mathbf{j} }\)</span></h3>
<p>在假设一到假设四成立（<span
class="math inline">\(y\)</span>对参数线性假设、随机抽样、估计量分母不为零/无多重共线性假设、零条件均值假设）的条件下，可以证明<span
class="math inline">\(plim\left( \widehat{\beta_{j} } \right) =
\beta_{j}\)</span>。以一元线性回归进行证明，过程如下：</p>
<p>已知：</p>
<p><span class="math display">\[\widehat{\beta_{j} } = \beta_{j} +
\frac{\sum_{}^{}{(x_{i} - \overline{x})}u_{i} }{\sum_{}^{}{(x_{i} -
\overline{x})}^{2} }\]</span></p>
<p>那么，当<span class="math inline">\(n \rightarrow
\infty\)</span>：</p>
<p><span class="math display">\[plim\left( \widehat{\beta_{j} } \right)
= plim\left( \beta_{j} + \frac{\sum_{}^{}{(x_{i} - \overline{x})}u_{i}
}{\sum_{}^{}{(x_{i} - \overline{x})}^{2} } \right) = \beta_{j} +
plim\left( \frac{\frac{1}{n}\sum_{}^{}\left( x_{i} - \overline{x}
\right)(u_{i} - \overline{u_{i} })}{\frac{1}{n}\sum_{}^{}{(x_{i} -
\overline{x})}^{2} } \right) = \beta_{j} +
\frac{cov(x_{i},u_{i})}{var(x_{i})}\]</span></p>
<p>又因为<a href="#证明x和u的协方差为零">由零条件均值假设可以推出<span
class="math inline">\(cov\left( x_{i},u_{i} \right) =
0\)</span></a>，因此定理一得证。</p>
<p>从中我们进一步思考，证明系数估计的一致性，我们只需要<span
class="math inline">\(cov\left( x_{i},u_{i} \right) =
0\)</span>，但是为了推至总体回归方程以及证明系数估计量的无偏性，我们仍然需要一个更加的假设，及零条件均值假设<span
class="math inline">\(E\left( u \middle| x \right) = E(u) =
0\)</span>。</p>
<h3 id="遗漏变量时对不一致性的影响">遗漏变量时对不一致性的影响</h3>
<p>假设原模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + v\]</span></p>
<p>对其进行OLS估计，分别得到系数估计量：<span
class="math inline">\(\widehat{\beta_{0} }\)</span>、<span
class="math inline">\(\widehat{\beta_{1} }\)</span>、<span
class="math inline">\(\widehat{\beta_{2} }\)</span></p>
<p>遗漏变量<span
class="math inline">\(\beta_{2}\)</span>后，模型为：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
u\]</span></p>
<p>对遗漏变量模型进行估计，得到系数估计量分别为：<span
class="math inline">\(\widetilde{\beta_{0} }\)</span>、<span
class="math inline">\(\widetilde{\beta_{1} }\)</span>。</p>
<p>由上文已知：</p>
<p><span class="math display">\[plim\left( \widetilde{\beta_{1} }
\right) = \beta_{1} + \frac{cov(x_{1},u)}{var(x_{1})} = \beta_{1} +
\frac{cov(x_{1},\beta_{2}x_{2} + v)}{var(x_{1})} = \beta_{1} +
\frac{cov\left( x_{1},\beta_{2}x_{2} \right) + cov(x_{1},v)}{var(x_{1})}
= \beta_{1} + \frac{cov\left( x_{1},\beta_{2}x_{2} \right)}{var(x_{1})}
= \beta_{1} + \beta_{2}\frac{cov\left( x_{1},x_{2}
\right)}{var(x_{1})}\]</span></p>
<p>又因为，在总体中，<span class="math inline">\(x_{2}\)</span>对<span
class="math inline">\(x_{1}\)</span>进行回归后，系数<span
class="math inline">\(\delta_{1} = \frac{cov\left( x_{1},x_{2}
\right)}{var(x_{1})}\)</span>（使用总体数据计算出来的真实值），则：</p>
<p><span class="math display">\[plim\left( \widetilde{\beta_{1} }
\right) = \beta_{1} + \beta_{2}\delta_{1}\]</span></p>
<p>而在计算期望的偏误中：</p>
<p><span class="math display">\[\widetilde{\beta_{1} } =
\widehat{\beta_{1} } + \widehat{\beta_{2} }\widetilde{\delta_{1}
}\]</span></p>
<p><span class="math display">\[E\left( \widetilde{\beta_{1} } \right) =
\beta_{1} + \beta_{2}\widetilde{\delta_{1} }\]</span></p>
<p>可以发现不同于概率极限中用总体数据估计出来的真实值<span
class="math inline">\(\delta_{1}\)</span>（<span
class="math inline">\(\delta_{1} = \frac{cov\left( x_{1},x_{2}
\right)}{var(x_{1})}\)</span>），期望中的<span
class="math inline">\(\widetilde{\delta_{1}
}\)</span>是通过样本数据估计出来的。因此，如果在总体中<span
class="math inline">\(x_{1}\)</span>和<span
class="math inline">\(x_{2}\)</span>不相关，其相关系数为0，那么遗漏变量不会导致概率极限的不一样，但是经过随机抽样的样本中，<span
class="math inline">\(x_{1}\)</span>和<span
class="math inline">\(x_{2}\)</span>仍然可能存在关系，系数不为零，遗漏变量就会导致期望偏误。</p>
<h3
id="单个系数不一致对其余系数的不一致性的影响">单个系数不一致对其余系数的不一致性的影响</h3>
<p>考虑三元回归模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + \beta_{3}x_{3} + u\]</span></p>
<p>如果，已知<span class="math inline">\(x_{1}\)</span>与<span
class="math inline">\(u\)</span>相关，则<span
class="math inline">\(cov(x_{1},u) \neq 0\)</span>，从而：</p>
<p><span class="math display">\[plim\left( \widehat{\beta_{1} } \right)
\neq \beta_{1}\]</span></p>
<p>那么，即使<span class="math inline">\(x_{2}\)</span>、<span
class="math inline">\(x_{3}\)</span>与<span
class="math inline">\(u\)</span>不相关，仍然有：<em><br />
</em><span class="math display">\[plim\left( \widehat{\beta_{2} }
\right) \neq \beta_{2}\]</span></p>
<p><span class="math display">\[plim\left( \widehat{\beta_{3} } \right)
\neq \beta_{3}\]</span></p>
<p>只有当<span class="math inline">\(x_{2}\)</span>、<span
class="math inline">\(x_{3}\)</span>与<span
class="math inline">\(x_{1}\)</span>、<span
class="math inline">\(u\)</span>都不相关时，它们的估计系数才是一致的。</p>
<p>证明过程如下：</p>
<p>由多元线性回归进行OLS估计可知：</p>
<p><span class="math display">\[\widehat{\beta_{j} } = \beta_{j} +
\frac{\sum_{}^{}\widehat{r_{ij} }u_{i} }{\sum_{}^{}{\widehat{r_{ij} }
}^{2} }\]</span></p>
<p>其中，<span class="math inline">\(r_{ij}\)</span>是<span
class="math inline">\(x_{j}\)</span>对其他自变量进行回归估计后的残差。那么：</p>
<p><span class="math display">\[plim\left( \widehat{\beta_{j} } \right)
= \beta_{j} + \frac{\sum_{}^{}\left( \widehat{r_{ij} } -
\overline{\widehat{r_{ij} } } \right)(u_{i} - \overline{u_{i}
})}{\sum_{}^{}\left( \widehat{r_{ij} } - \overline{\widehat{r_{ij} } }
\right)^{2} } = \beta_{j} + \frac{cov(\widehat{r_{ij}
},u_{i})}{var(\widehat{r_{ij} })} = \beta_{j} + \frac{cov(x_{ij} -
\widehat{x_{ij} },u_{i})}{var(\widehat{r_{ij} })} = \beta_{j} +
\frac{cov\left( x_{ij},u_{i} \right) - cov(\widehat{x_{ij}
},u_{i})}{var(\widehat{r_{ij} })}\]</span></p>
<p>如果，<span class="math inline">\(x_{ij}\)</span>与<span
class="math inline">\(u\)</span>独立，那么<span
class="math inline">\(cov\left( x_{ij},u_{i} \right) = 0\)</span>，<span
class="math inline">\(\widehat{x_{ij} }\)</span>可以看成除<span
class="math inline">\(x_{ij}\)</span>外其余自变量的线性组合，如果其中有一个自变量与<span
class="math inline">\(u\)</span>相关，那么<span
class="math inline">\(cov(\widehat{x_{ij} },u_{i}) \neq
0\)</span>。如果以<span class="math inline">\(j =
2\)</span>为例，那么<span class="math inline">\(cov\left( x_{2},u_{i}
\right) = 0\)</span>，但<span class="math inline">\(\widehat{x_{2}
}\)</span>是关于<span class="math inline">\(x_{1}\)</span>和<span
class="math inline">\(x_{3}\)</span>的线性组合，而<span
class="math inline">\(cov(x_{1},u_{i}) \neq 0\)</span>，所以<span
class="math inline">\(cov(\widehat{x_{2} },u_{i}) \neq
0\)</span>，因此<span class="math inline">\(plim\left(
\widehat{\beta_{2} } \right) \neq \beta_{2}\)</span></p>
<h2 id="ols估计量的渐近正态假设1-5">OLS估计量的渐近正态（假设1-5）</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV16G411X7ZU/?p=17&amp;spm_id_from=pageDriver">【教材精讲-《计量经济学导论.现代观点》】第五章
5.2 OLS估计量的渐近性质【渐近正态性】_哔哩哔哩_bilibili</a></p>
<p>渐近正态性的定义：</p>
<p><img src="https://s2.loli.net/2025/01/28/5jcdxCgIqaoLuHK.png"
style="width:5.76806in;height:0.79792in" /></p>
<p>随着<span class="math inline">\(n\)</span>趋向于正无穷，<span
class="math inline">\(Z_{n}\)</span>越趋近于标准正态分布。</p>
<p>有以下定理：</p>
<p><img src="https://s2.loli.net/2025/01/28/VevgfDbwa83kirp.png"
style="width:5.76806in;height:1.62014in" /></p>
<p><img src="https://s2.loli.net/2025/01/28/NiGedhY7kZ8yIsO.png"
style="width:5.76806in;height:0.6513in" /></p>
<h3
id="证明定理①sqrtmathbfn-left-widehatmathbfbeta_mathbf1-mathbf-mathbfbeta_mathbf1-right趋近于正态分布">证明定理①：<span
class="math inline">\(\sqrt{\mathbf{n} }\left(
\widehat{\mathbf{\beta}_{\mathbf{1} }
}\mathbf{-}\mathbf{\beta}_{\mathbf{1} }
\right)\)</span>趋近于正态分布</h3>
<p>对于定理①</p>
<p>我们已经知道：</p>
<p><span class="math display">\[var\left( \widehat{\beta_{j} } \right) =
\frac{\sigma^{2} }{ {SST}_{j}(1 - {R_{j} }^{2})} = \frac{\sigma^{2}
}{\sum_{}^{}{r_{ij} }^{2} } = \frac{\sigma^{2} }{ {SSR}_{j}
}\]</span></p>
<p>那么：</p>
<p><span class="math display">\[var\left( \sqrt{n}\left(
\widehat{\beta_{j} } - \beta_{j} \right) \right) = var\left(
\sqrt{n}\widehat{\beta_{j} } \right) = nvar\left( \widehat{\beta_{j} }
\right) = \frac{\sigma^{2} }{\frac{1}{n}\sum_{}^{}{r_{ij} }^{2}
}\]</span></p>
<p>证明过程如下（在简单回归的情况下进行证明）：</p>
<p>在证明过程中需要用到中心极限定理和大数定律。中心极限定理表明任何（具有有限方差的）总体的一个随机样本的均值经过标准化后，都服从一个渐近标准正态分布。大数定律认为，对于一组已知总体均值为<span
class="math inline">\(\mu\)</span>的独立同分布的随机变量，当<span
class="math inline">\(n \rightarrow
\infty\)</span>时，样本均值的概率极限是<span
class="math inline">\(\mu\)</span>。</p>
<p><img src="https://s2.loli.net/2025/01/28/QUIiEczquaWtV1Y.png"
style="width:5.76806in;height:1.3in" /></p>
<p><img src="https://s2.loli.net/2025/01/28/3oxBV67s2HJYAtD.png"
style="width:5.76806in;height:0.69861in" /></p>
<p>我们使用简单线性回归进行证明：</p>
<p>已知：</p>
<p><span class="math display">\[\widehat{\beta_{1} } = \beta_{1} +
\frac{\sum_{}^{}{\left( x_{i} - \overline{x} \right)u_{i} }
}{\sum_{}^{}\left( x_{i} - \overline{x} \right)^{2} }\]</span></p>
<p>那么：</p>
<p><span class="math display">\[\sqrt{n}\left( \widehat{\beta_{1} } -
\beta_{1} \right) = \sqrt{n}\frac{\frac{1}{n}\sum_{}^{}{\left( x_{i} -
\overline{x} \right)u_{i} } }{\frac{1}{n}\sum_{}^{}\left( x_{i} -
\overline{x} \right)^{2} } = n^{- \frac{1}{2}
}\frac{1}{\frac{1}{n}\sum_{}^{}\left( x_{i} - \overline{x} \right)^{2}
}\sum_{}^{}{\lbrack\left( x_{i} - \mu) + (\mu - \overline{x}
\right)\rbrack u_{i} } = n^{- \frac{1}{2} }\frac{1}{ {\sigma_{x} }^{2}
}\sum_{}^{}{\lbrack\left( x_{i} - \mu)u_{i} + (\mu - \overline{x}
\right)u_{i}\rbrack} = \frac{1}{ {\sigma_{x} }^{2} }\lbrack n^{-
\frac{1}{2} }\sum_{}^{}{\left( x_{i} - \mu \right)u_{i} } + n^{-
\frac{1}{2} }\left( \mu - \overline{x}
\right)\sum_{}^{}u_{i}\rbrack\]</span></p>
<p>其中<span class="math inline">\({\sigma_{x} }^{2}\)</span>是<span
class="math inline">\(x_{i}\)</span>的方差，<span
class="math inline">\(\mu\)</span>是总体中<span
class="math inline">\(x_{i}\)</span>的平均值。另外需要强调的是，由于假设二随机抽样，因此<span
class="math inline">\(u_{i}\)</span>具有独立同分布性，不同<span
class="math inline">\(u_{i}\)</span>之间是独立的，且都服从一个分布（从总体继承而来的分布），而由于有假设五同方差假设，因此<span
class="math inline">\(var(u_{i}) = \sigma^{2}\)</span>。</p>
<p>先看<mark>绿色</mark>部分，当<span class="math inline">\(n
\rightarrow \infty\)</span>时，<span
class="math inline">\(\overline{x}\)</span>（样本中<span
class="math inline">\(x_{i}\)</span>的平均值）趋近于<span
class="math inline">\(\mu\)</span>，因此<span
class="math inline">\(\left( \mu - \overline{x} \right) =
0\)</span>，所以绿色部分为零；</p>
<p>再看<mark>红色</mark>部分，<span class="math inline">\(\left( x_{i} -
\mu \right)u_{i}\)</span>是一个随机变量，接着来看它的期望和方法，<span
class="math inline">\(E\left( \left( x_{i} - \mu \right)u_{i} \right) =
E\left( x_{i}u_{i} \right) - \mu E\left( u_{i}
\right)\)</span>，又由于<span
class="math inline">\(x_{i}\)</span>和<span
class="math inline">\(u_{i}\)</span>是不相关的，所以<span
class="math inline">\(E(ux) = E\left( E\left( ux \middle| x \right)
\right) = E\left( xE\left( u \middle| x \right) \right) =
0\)</span>，因此</p>
<p><span class="math display">\[E\left( \left( x_{i} - \mu \right)u_{i}
\right) = 0\]</span></p>
<p><span class="math inline">\(var\left( \left( x_{i} - \mu \right)u_{i}
\right) = E\lbrack\left( x_{i} - \mu \right)^{2}{u_{i} }^{2}\rbrack -
E^{2}\lbrack\left( x_{i} - \mu \right)u_{i}\rbrack = E\lbrack\left(
x_{i} - \mu \right)^{2}{u_{i} }^{2}\rbrack = E\lbrack\left( x_{i} - \mu
\right)^{2}\rbrack E({u_{i} }^{2}) = {\sigma_{x}
}^{2}\sigma^{2}\)</span>。</p>
<p>根据中心极限定理，将随机变量<span class="math inline">\(\left( x_{i}
- \mu \right)u_{i}\)</span>加总后其分布将满足正态分布，所以：</p>
<p><span class="math display">\[\sum_{}^{}{\left( x_{i} - \mu
\right)u_{i} }\sim^{a}N(n*0,{ {n\sigma}_{x}
}^{2}\sigma^{2})\]</span></p>
<p>所以：<br />
<span class="math display">\[n^{- \frac{1}{2} }\sum_{}^{}{\left( x_{i} -
\mu \right)u_{i} }\sim^{a}N(0,{\sigma_{x} }^{2}\sigma^{2})\]</span></p>
<p>因此，当<span class="math inline">\(n \rightarrow
\infty\)</span>，原式即可化为：</p>
<p><span class="math display">\[\sqrt{n}\left( \widehat{\beta_{1} } -
\beta_{1} \right) = = \frac{1}{ {\sigma_{x} }^{2} }\left\lbrack n^{-
\frac{1}{2} }\sum_{}^{}{\left( x_{i} - \mu \right)u_{i} } + n^{-
\frac{1}{2} }\left( \mu - \overline{x} \right)\sum_{}^{}u_{i}
\right\rbrack = \frac{1}{ {\sigma_{x} }^{2} }n^{- \frac{1}{2}
}\sum_{}^{}{\left( x_{i} - \mu \right)u_{i} }\]</span></p>
<p>因此有：</p>
<p><span class="math display">\[E\left( \sqrt{n}\left(
\widehat{\beta_{1} } - \beta_{1} \right) \right) = 0\]</span></p>
<p><span class="math display">\[var\left( \sqrt{n}\left(
\widehat{\beta_{1} } - \beta_{1} \right) \right) = \left( \frac{1}{
{\sigma_{x} }^{2} } \right)^{2}var\left( n^{- \frac{1}{2}
}\sum_{}^{}{\left( x_{i} - \mu \right)u_{i} } \right) = \frac{\sigma^{2}
}{ {\sigma_{x} }^{2} }\]</span></p>
<p>所以：</p>
<p><span class="math display">\[\sqrt{n}\left( \widehat{\beta_{1} } -
\beta_{1} \right)\sim^{a}N(0,\frac{\sigma^{2} }{ {\sigma_{x} }^{2}
})\]</span></p>
<p>在上述性质中<span class="math inline">\({a_{j} }^{2} = plim(n^{-
1}\sum_{}^{}{\widehat{r_{ij} } }^{2})\)</span>，其中<span
class="math inline">\(\widehat{r_{ij} }\)</span>是<span
class="math inline">\(x_{j}\)</span>对其他自变量回归后的残差，如果只有一个自变量<span
class="math inline">\(x_{1}\)</span>的话，那么<span
class="math inline">\(plim(n^{- 1}\sum_{}^{}{\widehat{r_{ij} } }^{2}) =
{\sigma_{x} }^{2} = n^{- 1}\sum_{}^{}{({x_{i1} - \overline{x_{i1}
})}^{2} }\)</span>。因此，我们证明了性质一。</p>
<p>此外，对于<span class="math inline">\(\widehat{r_{ij} } = x_{1} -
\overline{x_{1} }\)</span>也可以进行证明，此时<span
class="math inline">\(x_{j}\)</span>对其他自变量的回归方程为：</p>
<p><span class="math display">\[x_{1} = \delta_{0} + r_{1}\]</span></p>
<p>使用OLS进行估计：</p>
<p><span class="math display">\[\sum_{}^{}{\widehat{r_{i1} } }^{2} =
\sum_{}^{}{(x_{i1} - \widehat{x_{i1} })}^{2} = \sum_{}^{}{(x_{i1} -
\widehat{\delta_{0} })}^{2}\]</span></p>
<p>对<span class="math inline">\(\widehat{\delta_{0}
}\)</span>求导，并令其等于0，则：</p>
<p><span class="math display">\[- 2\sum_{}^{}\left( x_{i1} -
\widehat{\delta_{0} } \right) = 0\]</span></p>
<p><span class="math display">\[\sum_{}^{}x_{i1} =
\sum_{}^{}\widehat{\delta_{0} } = n\widehat{\delta_{0} }\]</span></p>
<p>所以<span class="math inline">\(\widehat{\delta_{0} } =
\overline{x_{1} }\)</span>，带入原式则有：<span
class="math inline">\(\widehat{x_{1} } = \overline{x_{1}
}\)</span>，那么<span class="math inline">\(\widehat{r_{1} } = x_{1} -
\widehat{x_{1} } = x_{1} - \overline{x_{1} }\)</span>，那么<span
class="math inline">\(\sum_{}^{}{\widehat{r_{i1} } }^{2} =
\sum_{}^{}{({x_{i1} - \overline{x_{i1} })}^{2} }\)</span>。</p>
<h3
id="证明定理②mathbfplimleft-widehatmathbfsigma-mathbf2-rightmathbfmathbfsigmamathbf2-后续补充">证明定理②<span
class="math inline">\(\mathbf{plim}\left( {\widehat{\mathbf{\sigma} }
}^{\mathbf{2} } \right)\mathbf{=}\mathbf{\sigma}^{\mathbf{2}
}\)</span>【后续补充】</h3>
<p>对于定理②</p>
<p>从直观上进行理解，当<span class="math inline">\(n \rightarrow
\infty\)</span>，<span class="math inline">\(plim\left(
{\widehat{\sigma} }^{2} \right) =
\sigma^{2}\)</span>。也可以进行证明，已知<span
class="math inline">\({\widehat{\sigma} }^{2}\)</span>是<span
class="math inline">\(\sigma^{2}\)</span>的无偏估计量，即<span
class="math inline">\(E\left( {\widehat{\sigma} }^{2} \right) =
\sigma^{2}\)</span>，其中<span class="math inline">\({\widehat{\sigma}
}^{2} = \frac{\sum_{}^{}{\widehat{u_{i} } }^{2} }{n - k -
1}\)</span>，只需要再证明当<span class="math inline">\(n \rightarrow
\infty\)</span>，时<span class="math inline">\(var\left(
{\widehat{\sigma} }^{2} \right) = var\left(
\frac{\sum_{}^{}{\widehat{u_{i} } }^{2} }{n - k - 1} \right) \rightarrow
0\)</span>，这个证明过程需要用到大数定律。</p>
<h3
id="证明定理③widehatmathbfbeta_mathbfj-经过标准化后渐近标准正态分布">证明定理③：<span
class="math inline">\(\widehat{\mathbf{\beta}_{\mathbf{j} }
}\)</span>经过标准化后渐近标准正态分布</h3>
<p><img src="https://s2.loli.net/2025/01/28/DT1NGkzQbisXBUO.png"
style="width:5.76806in;height:1.13264in" /></p>
<p>由定理①已知<span class="math inline">\(\widehat{\beta_{1}
}\)</span>是渐近正态分布，因此我们对其标准化（减去期望，除以标准差）后渐近标准正态分布。当<span
class="math inline">\(n \rightarrow
\infty\)</span>时，标准误趋近于标准差。</p>
<p>上面三个定理中，有几点<mark><u>注意点</u></mark>：</p>
<p>一是定理①的证明使用的中心极限定理，其中要求样本中误差项<span
class="math inline">\(u\)</span>是独立同分布的，这一点可以由假设二（随机抽样性假定）保证。因此也并不需要假设六（<span
class="math inline">\(u\)</span>服从正态分布）；</p>
<p>二是定理③中，当<span class="math inline">\(n \rightarrow
\infty\)</span>，那么<span class="math inline">\(\widehat{\sigma}
\rightarrow \sigma\)</span>，因此<span class="math inline">\(se\left(
\widehat{\beta_{j} } \right) \rightarrow
\beta_{j}\)</span>。也可以从另外一个方面理解，<span
class="math inline">\(\frac{\widehat{\beta_{j} } - \beta_{j}
}{se(\widehat{\beta_{j} })}\)</span>是服从<span
class="math inline">\(t\)</span>分布的，而当<span
class="math inline">\(n \rightarrow \infty\)</span>时，<span
class="math inline">\(t\)</span>分布接近标准正态分布；</p>
<p>三是我们所强调的大样本，其最终目的不是想要<span
class="math inline">\(n \rightarrow \infty\)</span>，而是想让自由度<span
class="math inline">\(n - k - 1\)</span>变大。因为比如<span
class="math inline">\(n =
1000\)</span>，但我们有998个参数需要估计，那么我们的自由度是<span
class="math inline">\(1\)</span>，就相当于样本量近似为1个，这还是一个很小的样本。</p>
<p>四是渐近正态性需要假定一到假定五，也就是在样本量增大的情况下，不需要假定误差为正态分布，只需要同方差即可，但如果误差项是异方差的话（违背假定五），增大样本是无法解决这个问题（在第8章会详细讨论）。</p>
<p>有了上述的结论，我们能够对估计量的方差/标准差有一个更深层次的理解，当<span
class="math inline">\(n \rightarrow \infty\)</span>时，我们有：</p>
<p><span class="math display">\[\widehat{var\left( \widehat{\beta_{j} }
\right) =}\frac{ {\widehat{\sigma} }^{2} }{ {SST}_{j}(1 - {R_{j} }^{2})}
\rightarrow \frac{\sigma^{2} }{n{\sigma_{j} }^{2}(1 - {\rho_{j}
}^{2})}\]</span></p>
<p>其中，<span class="math inline">\({\sigma_{j} }^{2}\)</span>是<span
class="math inline">\(x_{j}\)</span>的方差，<span
class="math inline">\({\rho_{j} }^{2}\)</span>是在总体中<span
class="math inline">\(x_{j}\)</span>对其余自变量回归所得出的真实<span
class="math inline">\(R^{2}\)</span>。因此，在总体样本中，可以近似将<span
class="math inline">\(\frac{\sigma^{2} }{ {\sigma_{j} }^{2}(1 -
{\rho_{j} }^{2})}\)</span>看成常数，那么随着样本容量的增加，<span
class="math inline">\(\widehat{var\left( \widehat{\beta_{j} }
\right)}\)</span>就以<span
class="math inline">\(\frac{1}{n}\)</span>的速度收缩至零。</p>
<p>而标准误：</p>
<p><span class="math display">\[se\left( \widehat{\beta_{j} } \right) =
\frac{\sigma}{\sqrt{n}\sqrt{ {\sigma_{j} }^{2}(1 - {\rho_{j} }^{2})}
}\]</span></p>
<p>因此，随着样本容量的增加，<span class="math inline">\(se\left(
\widehat{\beta_{j} } \right)\)</span>就以<span
class="math inline">\(\frac{1}{\sqrt{n} }\)</span>的速度收缩至零。</p>
<h2 id="朗格朗日统计量">朗格朗日统计量</h2>
<p>此外，还要简单介绍一下拉格朗日统计量（<span
class="math inline">\(LM\)</span>统计量，也叫做得分统计量）。其目标在于检验多元的排除性约束。其具体过程如下：</p>
<p>假设不受约束的模型如下：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + \ldots + \beta_{k}x_{k} + u\]</span></p>
<p>我们施加<span class="math inline">\(q\)</span>个约束：</p>
<p><span class="math display">\[H_{0}:\beta_{k - q + 1} = \beta_{k - q +
2} = \ldots = \beta_{k} = 0\]</span></p>
<p>受约束的模型就是：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + \ldots + \beta_{k - q}x_{k - q} + v\]</span></p>
<p>如果我们使用<span
class="math inline">\(F\)</span>统计量进行检验（根据两个模型残差平方和的变化），那么就需要构造<span
class="math inline">\(F\)</span>统计量：</p>
<p><span class="math display">\[\frac{ {(SSR}_{r} - {SSR}_{ur})/q}{
{SSR}_{ur}/(n - k - 1)}\]</span></p>
<p>那如果我们使用拉格朗日统计量进行检验，就只需要对受约束的模型进行估计。其背后的原理是，如果所有自变量（<span
class="math inline">\(x_{1}\ldots
x_{k}\)</span>）还能够在较大程度上对受约束的模型的残差项进行解释，那么就拒绝去除残差项所代表的自变量</p>
<p>具体流程如下：</p>
<p><span
class="math inline">\(step1:\)</span>估计受约束的模型，计算出残差项<span
class="math inline">\(\widehat{u_{i} }\)</span>；</p>
<p><span class="math inline">\(step2:\)</span>做计算出的残差项<span
class="math inline">\(\widehat{u_{i}
}\)</span>对所有自变量的辅助回归（我们的本意是将<span
class="math inline">\(\widehat{u_{i} }\)</span>对被约束的<span
class="math inline">\(q\)</span>个自变量进行回归，但这无法构建出有效的检验统计量，因为约束模型中遗漏的回归元通常与其中出现的回归元有关。换个角度来看，根据<span
class="math inline">\(step1\)</span>，<span
class="math inline">\(\widehat{u_{i}
}\)</span>中应该不包含未遗漏自变量的影响。所以即使将这些出现的自变量加入残差项<span
class="math inline">\(\widehat{u_{i}
}\)</span>的回归中，这些自变量的系数也应该是近似无关的。），并计算出<span
class="math inline">\({R_{\widehat{u_{i} } } }^{2}\)</span>；</p>
<p><span class="math inline">\(step2:{R_{\widehat{u_{i} } }
}^{2}\)</span>越大，意味着<span
class="math inline">\(H_{0}\)</span>约束的自变量蕴含的信息越大，被约束的自变量仍然能够在一定程度上解释<span
class="math inline">\(y\)</span>，因此不能说它们的系数为0，所以越有理由拒绝<span
class="math inline">\(H_{0}\)</span>。构建统计量<span
class="math inline">\(LM = n{R_{\widehat{u_{i} } }
}^{2}\)</span>服从自由度为<span
class="math inline">\(q\)</span>的卡方分布，计算出<span
class="math inline">\(P\)</span>值，与显著性水平（1%，5%，10%）进行对比（或者使用拒绝域，先设定一个显著性水平，计算出其临界值，如果计算出的<span
class="math inline">\(LM\)</span>统计量小于临界值，我们就拒绝原假设）。</p>
<h2 id="ols估计量的渐近有效性">5.3 OLS估计量的渐近有效性</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1wM411Q7Tf/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第五章
5.3 OLS估计量的渐近性质【渐近有效性】_哔哩哔哩_bilibili</a></p>
<p>在某一类估计量中，OLS估计量具有渐近有效性（具有一致性且方差最小）。书中的定义如下。其中尤其需要注意划红线的部分。</p>
<p><img src="https://s2.loli.net/2025/01/28/vbkxg52pD48tuRc.png"
style="width:5.76806in;height:0.98333in" /></p>
<p><img src="https://s2.loli.net/2025/01/28/LiarsPfQXbw2GC3.png"
style="width:5.76806in;height:0.64028in" /></p>
<p><img src="https://s2.loli.net/2025/01/28/Lv95RwjaGkO1Az3.png"
style="width:5.76806in;height:0.88194in" /></p>
<p>具体分析及在一元回归中的证明过程如下：</p>
<p>我们已经知道，在高斯-马尔可夫假设（假设一到假设五）下，OLS估计量是最优线性无偏估计，这是<span
class="math inline">\(\widehat{\beta_{j}
}\)</span>的小样本中的性质（即无偏性，在大样本中不存在无偏性，我们讨论的是一致性）。而当<span
class="math inline">\(n \rightarrow
\infty\)</span>时，我们可以证明，在某一类估计量中，OLS估计量具有渐近有效性（具有一致性且方差最小），即方差最小。</p>
<p>我们以下在一元回归中进行讨论。这一类估计量<span
class="math inline">\(\widetilde{\beta_{j} }\)</span>是如下：</p>
<p><span class="math display">\[\widetilde{\beta_{j} } =
\frac{\sum_{}^{}{(z_{i} - \overline{z})y_{i} } }{\sum_{}^{}{(z_{i} -
\overline{z})x_{i} } }\]</span></p>
<p>其中，<span class="math inline">\(z_{i}\)</span>是<span
class="math inline">\(x_{i}\)</span>的一个变换，即<span
class="math inline">\(z_{i} = g\left( x_{i} \right)\)</span></p>
<p>已知<span class="math inline">\(E\left( u \middle| x \right) =
E(u)\)</span>，可以推出<span class="math inline">\(g(x)\)</span>与<span
class="math inline">\(u\)</span>无关，即<span
class="math inline">\(cov\left( z_{i},x_{i} \right) =
0\)</span>，其中有一个限定，即<span
class="math inline">\(g(x)\)</span>要与<span
class="math inline">\(x\)</span>有关（指的是皮尔逊相关，有些变换会让<span
class="math inline">\(g(x)\)</span>与<span
class="math inline">\(x\)</span>的皮尔逊相关系数为0，如<span
class="math inline">\(g(x) = x^{2}\)</span>与<span
class="math inline">\(x\)</span>）。满足这个条件，我们可以构造出上述这个估计量<span
class="math inline">\(\widetilde{\beta_{j} } = \frac{\sum_{}^{}{(z_{i} -
\overline{z})y_{i} } }{\sum_{}^{}{(z_{i} - \overline{z})x_{i} }
}\)</span>。</p>
<p>能够证明出：<span class="math inline">\(plim\left(
\widetilde{\beta_{j} } \right) = \beta_{j}\)</span>，证明过程如下：</p>
<p><span class="math display">\[plim\left( \widetilde{\beta_{j} }
\right) = plim\left( \frac{\sum_{}^{}{\left( z_{i} - \overline{z}
\right)\left( \beta_{0} + \beta_{1}x_{1} + u_{i} \right)}
}{\sum_{}^{}{\left( z_{i} - \overline{z} \right)x_{i} } } \right) =
plim\left( \beta_{1} + \frac{\frac{1}{n}\sum_{}^{}{\left( z_{i} -
\overline{z} \right)u_{i} } }{\frac{1}{n}\sum_{}^{}{\left( z_{i} -
\overline{z} \right)x_{i} } } \right) = plim\left( \beta_{1} +
\frac{cov(z_{i},u_{i})}{cov(z_{i},x_{i})} \right) =
\beta_{1}\]</span></p>
<p>所以，我们构造出的这种统计量是一致的。那么接下来我们就需要比较我们能构造出来的统计量与OLS估计出来的统计量谁的方差更小。</p>
<p>我们能够推导出，当<span class="math inline">\(n \rightarrow
\infty\)</span>：</p>
<p><span class="math display">\[var\left( \widetilde{\beta_{j} } \right)
= var\left( \beta_{1} + \frac{\frac{1}{n}\sum_{}^{}{\left( z_{i} -
\overline{z} \right)u_{i} } }{\frac{1}{n}\sum_{}^{}{\left( z_{i} -
\overline{z} \right)x_{i} } } \right) = var\left(
\frac{\sum_{}^{}{\left( z_{i} - \overline{z} \right)u_{i} }
}{\sum_{}^{}{\left( z_{i} - \overline{z} \right)x_{i} } } \right) =
\frac{1}{ {\lbrack\sum_{}^{}{\left( z_{i} - \overline{z}
\right)x_{i}\rbrack} }^{2} }\sum_{}^{}\left( z_{i} - \overline{z}
\right)^{2}var\left( u_{i} \right) = \frac{var(z)\sigma^{2} }{
{ncov}^{2}(z,x)}\]</span></p>
<p>而在一元OLS估计量的方差为：</p>
<p><span class="math display">\[var\left( \widehat{\beta_{j} } \right) =
\frac{\sigma^{2} }{ {SST}_{x} } = \frac{\sigma^{2}
}{nvar(x)}\]</span></p>
<p>根据柯西施瓦兹不等式，我们对于任意两个随机变量<span
class="math inline">\(X\)</span>和<span
class="math inline">\(Y\)</span>，有：</p>
<p><span class="math display">\[|cov(X,Y)| \leq sd(X)sd(Y)\]</span></p>
<p>将不等式两边进行平方：</p>
<p><span class="math display">\[{cov}^{2}(X,Y) \leq
var(X)var(Y)\]</span></p>
<p>那么，我们所构造的一类统计量的方差<span
class="math inline">\(var\left( \widetilde{\beta_{j} }
\right)\)</span>就有：</p>
<p><span class="math display">\[var\left( \widetilde{\beta_{j} } \right)
= \frac{var(z)\sigma^{2} }{n{cov}^{2}(z,x)} \geq \frac{var(z)\sigma^{2}
}{nvar(z)var(x)} = \frac{\sigma^{2} }{nvar(x)} = var\left(
\widehat{\beta_{j} } \right)\]</span></p>
<p>因此，我们在一元估计中证明了，对于一类统计量，OLS统计量是近似有效性的（具有一致性，且方差最小）。</p>
<h1 id="第6章-多元回归分析深入专题">第6章 多元回归分析：深入专题</h1>
<h2
id="数据测度变换测度单位标准化mathbfbeta系数">6.1数据测度变换（测度单位、标准化<span
class="math inline">\(\mathbf{\beta}\)</span>系数）</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1aj411a7VV/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第六章
6.1 数据测度单位的影响_哔哩哔哩_bilibili</a></p>
<h3 id="mathbfx和mathbfy发生测度单位上的变化"><span
class="math inline">\(\mathbf{x}\)</span>和<span
class="math inline">\(\mathbf{y}\)</span>发生测度单位上的变化</h3>
<p><mark><u>改变一：</u></mark><span
class="math inline">\(y\)</span><mark><u>改变，</u></mark><span
class="math inline">\(x\)</span><mark><u>不变。</u></mark>观察<span
class="math inline">\(\widehat{\beta_{j} }\)</span>、<span
class="math inline">\(\widehat{u_{i} }\)</span>、<span
class="math inline">\(\widehat{\sigma}\)</span>、<span
class="math inline">\(se(\widehat{\beta_{j} })\)</span>、<span
class="math inline">\(t_{统计量}\)</span>、<span
class="math inline">\(R^{2}\)</span>是否会改变？以一元线性回归为例进行计算。假设原式为：<span
class="math inline">\(y = \beta_{0} + \beta_{1}x +
u\)</span>，现在新的因变量为<span class="math inline">\(\widetilde{y} =
cy\)</span>，其中<span
class="math inline">\(c\)</span>是一个常数。我们可以将原式两边同时乘以<span
class="math inline">\(c\)</span>，即：<span class="math inline">\(cy =
{c\beta}_{0} + c\beta_{1}x + cu\)</span>，那么就有<span
class="math inline">\(\widetilde{\beta_{1} } = c\widehat{\beta_{1}
}\)</span>，<span class="math inline">\(\widetilde{u_{i} } =
c\widehat{u_{i} }\)</span>。继而就有：</p>
<p><span class="math display">\[\widetilde{\sigma} = \sqrt{
{\widetilde{\sigma} }^{2} } = \sqrt{\frac{\sum_{}^{}{\widetilde{u_{i} }
}^{2} }{n - 2} } = \sqrt{\frac{c^{2}\sum_{}^{}{\widehat{u_{i} } }^{2}
}{n - 2} } = c\sqrt{\frac{\sum_{}^{}{\widehat{u_{i} } }^{2} }{n - 2} } =
c\widehat{\sigma}\]</span></p>
<p><span class="math display">\[se\left( \widetilde{\beta_{1} } \right)
= \sqrt{\frac{ {\widetilde{\sigma} }^{2} }{ {SST}_{x} } } =
\sqrt{\frac{\frac{c^{2}\sum_{}^{}{\widehat{u_{i} } }^{2} }{n - 2} }{
{SST}_{x} } } = c\sqrt{\frac{ {\widehat{\sigma} }^{2} }{ {SST}_{x} } } =
cse\left( \widehat{\beta_{1} } \right)\]</span></p>
<p><span class="math display">\[t_{统计量（新）} =
\frac{\widetilde{\beta_{1} } - \beta_{1} }{se\left( \widetilde{\beta_{1}
} \right)} = \frac{\widetilde{\beta_{1} } }{se\left(
\widetilde{\beta_{1} } \right)} = \frac{c\widehat{\beta_{1} }
}{cse\left( \widehat{\beta_{1} } \right)} =
t_{统计量（原）}\]</span></p>
<p><span class="math display">\[{R^{2} }_{新} = \frac{ {SSE}_{新} }{
{SST}_{新} } = \frac{c^{2}{SSE}_{旧} }{c^{2}{SST}_{旧} } = {R^{2}
}_{旧}\]</span></p>
<p>关于新的真实<span
class="math inline">\(\beta_{1}\)</span>的置信区间<span
class="math inline">\(\left\lbrack \widetilde{\beta_{1} } - Cse\left(
\widetilde{\beta_{1} } \right),\widetilde{\beta_{1} } + Cse\left(
\widetilde{\beta_{1} } \right) \right\rbrack \rightarrow \left\lbrack
c\widehat{\beta_{1} } - cse\left( \widehat{\beta_{1} }
\right),c\widehat{\beta_{1} } + cse\left( \widehat{\beta_{1} } \right)
\right\rbrack \rightarrow c\lbrack\widehat{\beta_{1} } - se\left(
\widehat{\beta_{1} } \right),\widehat{\beta_{1} } + se\left(
\widehat{\beta_{1} }
\right)\rbrack\)</span>，所以新的置信区间也变化了<span
class="math inline">\(c\)</span>倍。</p>
<p><mark><u>改变二：</u></mark><span
class="math inline">\(y\)</span><mark><u>不变，</u></mark><span
class="math inline">\(x\)</span><mark><u>变化。</u></mark>同样观察<span
class="math inline">\(\widehat{\beta_{j} }\)</span>、<span
class="math inline">\(\widehat{u_{i} }\)</span>、<span
class="math inline">\(\widehat{\sigma}\)</span>、<span
class="math inline">\(se(\widehat{\beta_{j} })\)</span>、<span
class="math inline">\(t_{统计量}\)</span>、<span
class="math inline">\(R^{2}\)</span>是否会改变？以一元线性回归为例进行计算。假设原式为：<span
class="math inline">\(y = \beta_{0} + \beta_{1}x +
u\)</span>，现在新的自变量为<span class="math inline">\(\widetilde{x} =
cx\)</span>，其中<span
class="math inline">\(c\)</span>是一个常数。那么，原始就可以改写为：<span
class="math inline">\(y = \beta_{0} +
{\frac{1}{c}\beta}_{1}\widetilde{x} + u\)</span>。因此就有<span
class="math inline">\(\widetilde{\beta_{1} } =
\frac{1}{c}\widehat{\beta_{1} }\)</span>，<span
class="math inline">\(\widetilde{u_{i} } = \widehat{u_{i}
}\)</span>。继而就有：</p>
<p><span class="math display">\[\widetilde{\sigma} = \sqrt{
{\widetilde{\sigma} }^{2} } = \sqrt{\frac{\sum_{}^{}{\widetilde{u_{i} }
}^{2} }{n - 2} } = \sqrt{\frac{\sum_{}^{}{\widehat{u_{i} } }^{2} }{n -
2} } = \widehat{\sigma}\]</span></p>
<p><span class="math display">\[se\left( \widetilde{\beta_{1} } \right)
= \sqrt{\frac{ {\widetilde{\sigma} }^{2} }{ {SST}_{x} } } = \sqrt{\frac{
{\widehat{\sigma} }^{2} }{\sum_{}^{}{(\widetilde{x_{i} } -
\overline{\widetilde{x} })}^{2} } } = \sqrt{\frac{ {\widehat{\sigma}
}^{2} }{\sum_{}^{}{(cx_{i} - c\overline{x})}^{2} } } =
\frac{1}{c}se\left( \widehat{\beta_{1} } \right)\]</span></p>
<p><span class="math display">\[t_{统计量（新）} =
\frac{\widetilde{\beta_{1} } - \beta_{1} }{se\left( \widetilde{\beta_{1}
} \right)} = \frac{\widetilde{\beta_{1} } }{se\left(
\widetilde{\beta_{1} } \right)} = \frac{\frac{1}{c}\widehat{\beta_{1} }
}{\frac{1}{c}se\left( \widehat{\beta_{1} } \right)} =
t_{统计量（原）}\]</span></p>
<p><span class="math display">\[{R^{2} }_{新} = \frac{ {SSE}_{新} }{
{SST}_{新} } = \frac{ {SSE}_{旧} }{ {SST}_{旧} } = {R^{2}
}_{旧}\]</span></p>
<p>同理，置信区间也变化为原来的<span
class="math inline">\(\frac{1}{c}\)</span>倍。</p>
<p><mark><u>改变三</u></mark>：如果原模型为<span
class="math inline">\(log(y)\)</span>对<span
class="math inline">\(x\)</span>的回归函数，当<span
class="math inline">\(y\)</span>变化为原来的<span
class="math inline">\(c\)</span>倍，或者是<span
class="math inline">\(y\)</span>对<span
class="math inline">\(log(x)\)</span>的回归函数，<span
class="math inline">\(x\)</span>变化为原来的<span
class="math inline">\(c\)</span>倍，那么系数估计和残差项都不会发生改变，只有截距项会发生改变。</p>
<h3 id="标准化系数mathbfbeta系数">标准化系数（<span
class="math inline">\(\mathbf{\beta}\)</span>系数）</h3>
<p>对于一个多元线性回归模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + \beta_{3}x_{3} + \ldots + \beta_{k}x_{k} +
u\]</span></p>
<p>我们一般不关心<span
class="math inline">\(x\)</span>变动一个单位会对<span
class="math inline">\(y\)</span>产生的影响，因为这需要另外考虑单位和量纲的影响；而是关心<span
class="math inline">\(x\)</span>变动一个<mark><u>标准差</u></mark>会对<span
class="math inline">\(y\)</span>产生的影响。同时由于我们使用标准差作为衡量标准，那么就可以比较不同自变量之间的影响大小（如果不使用标准差，单位和量纲会导致这样的比较是没有意义的）。具体操作过程是将=<span
class="math inline">\(x\)</span>和<span
class="math inline">\(y\)</span>进行标准化后放回方程中进行回归，估计出来的系数就是标准化系数。如下：</p>
<p>针对上述原模型的估计：</p>
<p><span class="math display">\[y_{i} = \widehat{\beta_{0} } +
\widehat{\beta_{1} }x_{i1} + \widehat{\beta_{2} }x_{i2} +
\widehat{\beta_{3} }x_{i3} + \ldots + \widehat{\beta_{k} }x_{ik} +
{\widehat{u} }_{i}\]</span></p>
<p>我们希望将<span class="math inline">\(x\)</span>和<span
class="math inline">\(y\)</span>分别转化成如下标准化形式：</p>
<p><span class="math display">\[y \rightarrow \frac{y - \overline{y}
}{\sigma_{y} }\]</span></p>
<p><span class="math display">\[x \rightarrow \frac{x - \overline{x}
}{\sigma_{x} }\]</span></p>
<p>因此，基于这个目标，我们首先将原方程两边都取平均：</p>
<p><span class="math display">\[\overline{y_{i} } = \widehat{\beta_{0} }
+ \widehat{\beta_{1} }\overline{x_{i1} } + \widehat{\beta_{2}
}\overline{x_{i2} } + \widehat{\beta_{3} }\overline{x_{i3} } + \ldots +
\widehat{\beta_{k} }\overline{x_{ik} } + \overline{ {\widehat{u} }_{i}
}\]</span></p>
<p>我们再用原估计模型减去平均后的模型：</p>
<p><span class="math display">\[y_{i} - \overline{y_{i} } =
\widehat{\beta_{1} }\left( x_{i1} - \overline{x_{i1} } \right) +
\widehat{\beta_{2} }\left( x_{i2} - \overline{x_{i2} } \right) + \ldots
+ \widehat{\beta_{k} }\left( x_{ik} - \overline{x_{ik} } \right) +
{\widehat{u} }_{i}\]</span></p>
<p>再将两边同时除以<span
class="math inline">\(\sigma_{y}\)</span>，并把自变量的每一项对应除以<span
class="math inline">\(\sigma_{x_{j} }\)</span>：</p>
<p><span class="math display">\[\frac{y_{i} - \overline{y_{i} }
}{\sigma_{y} } = \frac{\widehat{\beta_{1} }\sigma_{x_{1} } }{\sigma_{y}
}\frac{\left( x_{i1} - \overline{x_{i1} } \right)}{\sigma_{x_{1} } } +
\frac{\widehat{\beta_{2} }\sigma_{x_{2} } }{\sigma_{y} }\frac{\left(
x_{i2} - \overline{x_{i2} } \right)}{\sigma_{x_{2} } } + \ldots +
\frac{\widehat{\beta_{k} }\sigma_{x_{k} } }{\sigma_{y} }\frac{\left(
x_{ik} - \overline{x_{ik} } \right)}{\sigma_{x_{k} } } + \frac{
{\widehat{u} }_{i} }{\sigma_{y} }\]</span></p>
<p>我们令<span class="math inline">\(\widehat{b_{j} } =
\frac{\widehat{\beta_{j} }\sigma_{x_{j} } }{\sigma_{y}
}\)</span>，这就是标准化系数。</p>
<h2
id="函数形式变换对数二次项交互项">函数形式变换（对数、二次项、交互项）</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1ve411D7Nk/?spm_id_from=333.788">【教材精讲-《计量经济学导论.现代观点》】第六章
6.2 函数形式变换对参数估计的影响_哔哩哔哩_bilibili</a></p>
<h3 id="对数变换">对数变换</h3>
<p>首先回忆2.3.4非线性变换和弹性的内容。在哪里我们时使用泰勒公式进行了近似估计，即当<span
class="math inline">\(x \rightarrow 0\)</span>时，<span
class="math inline">\(log(1 + x) \approx x\)</span>。因此，当<span
class="math inline">\(\frac{x_{1} - x_{0} }{x_{0} } \rightarrow
0\)</span>时，即<span class="math inline">\(x_{1} \rightarrow
x_{0}\)</span>时，<span class="math inline">\(\frac{x_{1} - x_{0}
}{x_{0} } \approx \log\left( \frac{x_{1} }{x_{0} } \right) = \log\left(
x_{1} \right) - \log\left( x_{0} \right) =
\mathrm{\Delta}log(x)\)</span>。那么对于半弹性线性回归方程<span
class="math inline">\(\log(y) = \beta_{0} + \beta_{1}x +
u\)</span>，则有<span class="math inline">\(\beta_{1} =
\frac{\mathrm{\Delta}\log(y)}{\mathrm{\Delta}x} =
\frac{100\mathrm{\Delta}\log(y)}{100\mathrm{\Delta}x} \approx
\frac{\%\mathrm{\Delta}y}{100\mathrm{\Delta}x}\)</span>。所以当<span
class="math inline">\(x\)</span>变化1个单位时，<span
class="math inline">\(y\)</span>变化<span
class="math inline">\(100\beta_{1}\%\)</span>倍。所以，以上的计算都是基于泰勒展开的近似计算，其中要求<span
class="math inline">\(x_{1} \rightarrow x_{0}\)</span>，如果<span
class="math inline">\(x_{1}\)</span>到<span
class="math inline">\(x_{0}\)</span>变化较多，则这种方法的近似是不准确的。因此，在这一节，我们希望精确计算出<span
class="math inline">\(x\)</span>的变化会对<span
class="math inline">\(y\)</span>带来多大的影响。</p>
<p>以半弹性一元线性回归为例：</p>
<p><span class="math display">\[\log(y) = \beta_{0} + \beta_{1}x +
u\]</span></p>
<p>我们有：</p>
<p><span class="math display">\[\mathrm{\Delta}\log(y) =
\beta_{1}\mathrm{\Delta}x\]</span></p>
<p><span class="math display">\[\log\left( y_{1} \right) - \log\left(
y_{0} \right) = \beta_{1}\mathrm{\Delta}x\]</span></p>
<p><span class="math display">\[\log\left( \frac{y_{1} }{y_{0} } \right)
= \beta_{1}\mathrm{\Delta}x\]</span></p>
<p><span class="math display">\[100(\frac{y_{1} }{y_{0} } - 1) =
100(\exp\left\{ \beta_{1}\mathrm{\Delta}x \right\} - 1)\]</span></p>
<p><span class="math display">\[\%\mathrm{\Delta}y = 100(\exp\left\{
\beta_{1}\mathrm{\Delta}x \right\} - 1)\]</span></p>
<p>因此，<span class="math inline">\(x\)</span>每变动1个单位，<span
class="math inline">\(y\)</span>变为原来的<span
class="math inline">\(100\left( \exp\left\{ \beta_{1} \right\} - 1
\right)\%\)</span>倍。</p>
<p>在什么情况下我们选择对数变换？</p>
<p>①当我们对<span class="math inline">\(x\)</span>和<span
class="math inline">\(y\)</span>取对数时，<span
class="math inline">\(\widehat{\beta_{j} }\)</span>是不随着<span
class="math inline">\(x\)</span>和y的量纲变化而变化的，只有截距项发生改变；</p>
<p>②当<span class="math inline">\(y &gt; 0\)</span>，<span
class="math inline">\(log(y)\)</span>能够更加接近于<span
class="math inline">\(CLM\)</span>假设，即更加符合正态。但需要注意，如果<span
class="math inline">\(y\)</span>的范围是在0-1之间的话，就不宜取<span
class="math inline">\(log(y)\)</span>因为这样会导致数据量很大，同时波动也很大，达不到我们压缩数据值域，是指更接近正态的目的。</p>
<p>③取<span
class="math inline">\(\log\)</span>能够缩小变量取值范围。因为我们所使用的<span
class="math inline">\(OLS\)</span>估计是最小化残差平方和<span
class="math inline">\(\sum_{}^{}{\widehat{u_{i} }
}^{2}\)</span>，其对异常值是比较敏感的。</p>
<p>因此，我们一般对较大的正数取<span
class="math inline">\(\log\)</span>运算，而不对在0-1之间的，或者较小的正数取<span
class="math inline">\(\log\)</span>。</p>
<h3 id="变化为二次项">变化为二次项</h3>
<p>对于简单的包含二次项的回归方程：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x +
\beta_{2}x^{2} + u\]</span></p>
<p>估计出的方程为：</p>
<p><span class="math display">\[y = \widehat{\beta_{0} } +
\widehat{\beta_{1} }x + \widehat{\beta_{2} }x^{2} +
\widehat{u}\]</span></p>
<p>我们有：</p>
<p><span
class="math display">\[\frac{\mathrm{\Delta}y}{\mathrm{\Delta}x} =
\widehat{\beta_{1} } + 2\widehat{\beta_{2} }x\]</span></p>
<p>我们有如下注意点：</p>
<p>①<span class="math inline">\(\widehat{\beta_{1} }\)</span>表示当<span
class="math inline">\(x = 0\)</span>时，<span
class="math inline">\(x\)</span>对<span
class="math inline">\(y\)</span>的偏效应。在图像中体现为曲线与<span
class="math inline">\(y\)</span>轴交点处斜率的正/负；</p>
<p>②<span class="math inline">\(\widehat{\beta_{2}
}\)</span>表示斜率的变化率；</p>
<p>③在实际问题中，我们一般带入一个有意义的<span
class="math inline">\(x\)</span>值对斜率进行分析，如<span
class="math inline">\(x = \overline{x}\)</span>，或者<span
class="math inline">\(x = t\)</span>，其中<span
class="math inline">\(t\)</span>为实际问题中设定的某一个标准；</p>
<p>④我们尤其需要关注曲线的拐点，即<span class="math inline">\(x = -
\frac{\widehat{\beta_{1} } }{2\widehat{\beta_{2} }
}\)</span>，也就是斜率为0的点。如果我们的样本范围不包括斜率为0的点，则不需要过多关注，但如果包括，则需要推敲其合理性。</p>
<p><img src="https://s2.loli.net/2025/01/28/TQtyA1BjN4g7FIk.png"
style="width:3.84971in;height:1.92486in" /></p>
<h3 id="变换为交互项">变换为交互项</h3>
<p>我们有一个典型的包含交互项的模型：</p>
<p><span class="math display">\[y = \widehat{\beta_{0} } +
\widehat{\beta_{1} }x_{1} + \widehat{\beta_{2} }x_{2} +
\widehat{\beta_{3} }(x_{1}*x_{2}) + \widehat{u}\]</span></p>
<p>假如我们想要研究<span class="math inline">\(x_{1}\)</span>对于<span
class="math inline">\(y\)</span>的影响，则有：</p>
<p><span
class="math display">\[\frac{\mathrm{\Delta}y}{\mathrm{\Delta}x_{1} } =
\widehat{\beta_{1} } + \widehat{\beta_{3} }x_{2}\]</span></p>
<p>换言之<span class="math inline">\(x_{1}\)</span>对于<span
class="math inline">\(y\)</span>的偏效应与<span
class="math inline">\(x_{2}\)</span>有关。因此，此时我们不能只看<span
class="math inline">\(x_{1}\)</span>的系数及其标准误，因为这是在<span
class="math inline">\(x_{2} =
0\)</span>的前提条件下，而在很多实际问题中，<span
class="math inline">\(x_{2} =
0\)</span>可能是没有意义的。此外，如果我们在这种情况下，也不能仅看对<span
class="math inline">\(\widehat{\beta_{1} }\)</span>和<span
class="math inline">\(\widehat{\beta_{3} }\)</span>分别进行的<span
class="math inline">\(t\)</span>检验，而是需要在联合假设中使用<span
class="math inline">\(F\)</span>检验。</p>
<p>在实际处理中，我们常做的是取<span class="math inline">\(x_{2} =
\overline{x_{2} }\)</span>下，计算<span
class="math inline">\(\frac{\mathrm{\Delta}y}{\mathrm{\Delta}x_{1} } =
\widehat{\beta_{1} } + \widehat{\beta_{3} }\overline{x_{2}
}\)</span>。但为了更加方便判断<span
class="math inline">\(\frac{\mathrm{\Delta}y}{\mathrm{\Delta}x_{1} } =
\widehat{\beta_{1} } + \widehat{\beta_{3} }\overline{x_{2}
}\)</span>是否在统计意义上显著，我们常对模型进行以下改写：</p>
<p><span class="math display">\[y = \widehat{\delta_{0} } +
\widehat{\delta_{1} }x_{1} + \widehat{\delta_{2} }x_{2} +
\widehat{\delta_{3} }(x_{1} - \mu_{x_{1} })(x_{2} - \mu_{x_{2} }) +
\widehat{u}\]</span></p>
<p>其中<span class="math inline">\(\mu_{x_{1} }\)</span>、<span
class="math inline">\(\mu_{x_{2} }\)</span>是<span
class="math inline">\(x_{1}\)</span>、<span
class="math inline">\(x_{2}\)</span>的样本期望，。在此模型估计中：<em><br />
</em><span
class="math display">\[\frac{\mathrm{\Delta}y}{\mathrm{\Delta}x_{1} } =
\widehat{\delta_{1} } + \widehat{\delta_{3} }(x_{2} - \mu_{x_{2}
})\]</span></p>
<p>因此，此时<span class="math inline">\(\widehat{\delta_{1}
}\)</span>衡量的是：当<span
class="math inline">\(x_{2}\)</span>取其样本期望时，<span
class="math inline">\(x_{1}\)</span>对于<span
class="math inline">\(y\)</span>的偏效应。同时模型还会给我们输出<span
class="math inline">\(\widehat{\delta_{1}
}\)</span>的标准误，就方便在<span
class="math inline">\(x_{2}\)</span>的均值水平上，对其进行<span
class="math inline">\(t\)</span>检验，观察其是否在统计意义上显著。除了取<span
class="math inline">\(x_{2} = \overline{x_{2}
}\)</span>，我们根据具体问题还需要对<span
class="math inline">\(x_{2}\)</span>取不同的值，并在这些水平上对<span
class="math inline">\(\widehat{\delta_{1} }\)</span>进行<span
class="math inline">\(t\)</span>检验。而为了综合观察，不同<span
class="math inline">\(x_{2}\)</span>取值下的<span
class="math inline">\(x_{1}\)</span>对于<span
class="math inline">\(y\)</span>的偏效应，我们提出平均偏效应的概念。</p>
<p>如上述问题中，变量<span class="math inline">\(x_{1}\)</span>对<span
class="math inline">\(y\)</span>的平均偏效应（<span
class="math inline">\(APE\)</span>）为：</p>
<p><span class="math display">\[APE =
\frac{1}{n}\sum_{}^{}{(\widehat{\beta_{1} } + \widehat{\beta_{3}
}x_{2.n})} = \widehat{\beta_{1} } + \widehat{\beta_{3} }\overline{x_{2}
}\]</span></p>
<h2 id="拟合优度与回归元选择">拟合优度与回归元选择</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV12N4y1D7FY/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第六章
6.3 拟合优度与回归元选择_哔哩哔哩_bilibili</a></p>
<h3 id="拟合优度调整mathbfrmathbf2">拟合优度（调整<span
class="math inline">\(\mathbf{R}^{\mathbf{2} }\)</span>）</h3>
<p>我们已经知道：</p>
<p><span class="math display">\[R^{2} = \frac{SSE}{SST} = 1 -
\frac{SSR}{SST}\]</span></p>
<p><span
class="math inline">\(R^{2}\)</span>衡量的是模型中我们能够观测到的所有<span
class="math inline">\(x\)</span>总体对<span
class="math inline">\(y\)</span>的解释力。但计量经济学家更关心的是某一个<span
class="math inline">\(x\)</span>对<span
class="math inline">\(y\)</span>的影响系数<span
class="math inline">\(\beta\)</span>能否被精确估计，而不是关心所有<span
class="math inline">\(x\)</span>的总体对<span
class="math inline">\(y\)</span>的解释力如何。因为我们无法穷尽所有影响<span
class="math inline">\(y\)</span>的自变量，因此常常<span
class="math inline">\(R^{2}\)</span>是不大的，在一些经济问题研究中<span
class="math inline">\(R^{2}\)</span>处于0.3~0.4之间也是能被接受的。</p>
<p>虽然，我们说<span
class="math inline">\(R^{2}\)</span>太小确实会使<span
class="math inline">\(SSR\)</span>太大，继而使估计的<span
class="math inline">\({\widehat{\sigma}
}^{2}\)</span>很大，继而影响<span
class="math inline">\(var(\widehat{\beta_{j} })\)</span>。但是<span
class="math inline">\(var\left( \widehat{\beta_{j} } \right) = \frac{
{\widehat{\sigma} }^{2} }{ {SST}_{j}(1 - {R^{2}
}_{j})}\)</span>，我们可以通过增大样本量，继而增大<span
class="math inline">\({SST}_{j}(1 - {R^{2} }_{j})\)</span>从而抵消<span
class="math inline">\({\widehat{\sigma} }^{2}\)</span>增大对<span
class="math inline">\(var\left( \widehat{\beta_{j} }
\right)\)</span>的影响。</p>
<p>所以说<span
class="math inline">\(R^{2}\)</span>一般没有那么重要，但<span
class="math inline">\(R^{2}\)</span>的变化就不一样。例如，我们在进行<span
class="math inline">\(F\)</span>检验时：</p>
<p><span class="math display">\[F = \frac{ {SSR}_{r} - {SSR}_{ur}/q}{
{SSR}_{ur}/(n - k - 1)} = \frac{\left( {R_{ur} }^{2} - {R_{r} }^{2}
\right)q}{(1 - {R_{ur} }^{2})/(n - k - 1)}\]</span></p>
<p><span
class="math inline">\(R^{2}\)</span>的变化就会带来显著性的改变。</p>
<p>这些内容是我们已经知道的。在这一节我们将介绍调整<span
class="math inline">\(R^{2}\)</span>，用<span
class="math inline">\({\overline{R} }^{2}\)</span>进行表示：</p>
<p><span class="math display">\[{\overline{R} }^{2} = 1 - \frac{SSR/(n -
k - 1)}{SST/(n - 1)}\]</span></p>
<p>设置调整<span
class="math inline">\(R^{2}\)</span>有以下两点原因：</p>
<p>①次要原因：<span
class="math inline">\(R^{2}\)</span>实际上也是通过一组样本计算出来的，因此也需要去估计总体中实际的真实<span
class="math inline">\(R^{2}\)</span>，我们记作<span
class="math inline">\(\rho^{2} = 1 - \frac{ {\sigma_{u} }^{2} }{
{\sigma_{y} }^{2} }\)</span>。能够发现在<span
class="math inline">\({\overline{R} }^{2}\)</span>的计算公式中，<span
class="math inline">\(SSR/(n - k - 1)\)</span>是<span
class="math inline">\({\sigma_{u} }^{2}\)</span>的无偏估计量（<span
class="math inline">\(E(SSR/(n - k - 1) = {\sigma_{u} }^{2})\)</span>）,
<span class="math inline">\(SST/(n - 1)\)</span>是<span
class="math inline">\({\sigma_{y}
}^{2}\)</span>的无偏估计量，但是需要注意无偏性是不能通过除法运算进行传导的，因此<span
class="math inline">\({\overline{R} }^{2}\)</span>并不是<span
class="math inline">\(\rho^{2}\)</span>的无偏估计量。因此，这是一个次要原因，只具有一定的说服力；</p>
<p>②主要原因：<span class="math inline">\({\overline{R}
}^{2}\)</span>能够给向模型中增加变量给予一个惩罚。计量经济学家是不希望自己的模型相当的复杂，希望它尽可能地简洁。但是，如果以原始的<span
class="math inline">\(R^{2} = \frac{SSE}{SST} = 1 -
\frac{SSR}{SST}\)</span>作为评估条件，我们发现随着自变量的不断增加，<span
class="math inline">\(SST\)</span>不变，但<span
class="math inline">\(SSR\)</span>是不会增加的（只会不变或减少），因此就可以通过不断地增加自变量来增加<span
class="math inline">\(R^{2}\)</span>，这与我们的初衷是不相符合的。但是，如果使用<span
class="math inline">\({\overline{R} }^{2} = 1 - \frac{SSR/(n - k -
1)}{SST/(n - 1)}\)</span>，虽然随着自变量的增加，<span
class="math inline">\(SSR\)</span>仍然会减少，但其分母<span
class="math inline">\(n - k - 1\)</span>也同样会减少，<span
class="math inline">\(SSR/(n - k -
1)\)</span>的值就不一定是减小还是增大了。</p>
<p>③我们知道<span
class="math inline">\(R^{2}\)</span>的范围在0~1之间，但<span
class="math inline">\({\overline{R}
}^{2}\)</span>有可能是小于0的。因为<span class="math inline">\(R^{2} =
\frac{SSE}{SST} = 1 - \frac{SSR}{SST}\)</span>，所以<span
class="math inline">\(SSR = SST(1 - R^{2})\)</span>，那么<span
class="math inline">\({\overline{R} }^{2} = 1 - \frac{\frac{SSR}{n - k -
1} }{\frac{SST}{(n - 1)} } = 1 - \frac{\frac{SST\left( 1 - R^{2}
\right)}{n - k - 1} }{\frac{SST}{(n - 1)} } = 1 - \frac{\left( 1 - R^{2}
\right)(n - 1)}{(n - k - 1)}\)</span>，其中<span class="math inline">\(1
- R^{2}\)</span>在0~1的范围，<span class="math inline">\(\frac{(n -
1)}{(n - k - 1)}\)</span>大于1。如果<span class="math inline">\(\frac{(n
- 1)}{(n - k - 1)}\)</span>特别大，就有可能使<span
class="math inline">\({\overline{R} }^{2} &lt; 0\)</span>。但当<span
class="math inline">\({\overline{R} }^{2} &lt;
0\)</span>需要注意模型设置是否有问题了。</p>
<p>④<span class="math inline">\({\overline{R}
}^{2}\)</span>可以用来对比非嵌套模型。嵌套模型举例如下：</p>
<p>模型一：<span class="math inline">\(y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + u\)</span>；模型二：<span class="math inline">\(y =
\beta_{0} + \beta_{1}x_{1} +
u\)</span>。那么模型二就被嵌套在模型一里面。</p>
<p>我们再假设模型三：<span class="math inline">\(y = \beta_{0} +
\beta_{1}x_{1} + \beta_{3}x_{3} + u\)</span>；模型四：<span
class="math inline">\(y = \beta_{0} + \beta_{1}x_{1} + \beta_{2}{x_{2}
}^{2} + u\)</span></p>
<p>此时模型三和模型四和模型一就没有嵌套关系。可以用<span
class="math inline">\({\overline{R}
}^{2}\)</span>来比较模型的优劣。能够<span
class="math inline">\({\overline{R}
}^{2}\)</span>来进行比较的依据是在<span
class="math inline">\(SST\)</span>不变的情况下，比较估计的误差方差<span
class="math inline">\({\widehat{\sigma} }^{2} = \frac{SSR}{n - k -
1}\)</span>。<span class="math inline">\({\overline{R}
}^{2}\)</span>越大，则估计的误差方差<span
class="math inline">\({\widehat{\sigma} }^{2} = \frac{SSR}{n - k -
1}\)</span>越小，在一定程度上说明模型拟合效果越好。</p>
<h3 id="回归元的选择">回归元的选择</h3>
<p>究竟应不应该将变量加入模型中？到底什么是其他条件不变？这一节会对这两个问题有更深入的理解。</p>
<p>我们讨论加变量与不加变量两种情况：</p>
<p>①不加变量：控制变量过多</p>
<p>在模型设计中，我们想要探究<span
class="math inline">\(x_{1}\)</span>对<span
class="math inline">\(y\)</span>的影响，我们的逻辑是<span
class="math inline">\(x_{1}\)</span>可能会影响<span
class="math inline">\(x_{2}\)</span>进而影响<span
class="math inline">\(y\)</span>。这里的<span
class="math inline">\(x_{2}\)</span>就叫做中介变量，产生了中介效应。那我们应不应该将中介变量加入模型中呢？不应该！</p>
<p>例子：我们想要探究增加啤酒税（<span
class="math inline">\(tax\)</span>）对减少交通事故死亡率（<span
class="math inline">\(y\)</span>）有没有影响？我们的逻辑是，增加啤酒税（<span
class="math inline">\(tax\)</span>）会减少啤酒销量（<span
class="math inline">\(cons\)</span>），进而减少醉驾数量，从而减少交通事故发生数和死亡率。如果我们将啤酒销量也加入模型中：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}tax +
\beta_{2}cons + \beta_{3}x + u\]</span></p>
<p>那么，此时<span
class="math inline">\(\beta_{1}\)</span>的含义就是，在控制变量<span
class="math inline">\(cons\)</span>和<span
class="math inline">\(x\)</span>的前提下，<span
class="math inline">\(tax\)</span>对<span
class="math inline">\(y\)</span>的影响，这与我们的逻辑矛盾了，所以此时<span
class="math inline">\(\beta_{1}\)</span>是没有意义的，除非我们是想研究<span
class="math inline">\(tax\)</span>对<span
class="math inline">\(y\)</span>的简介效应，即不是通过<span
class="math inline">\(tax\)</span>影响<span
class="math inline">\(cons\)</span>而造成<span
class="math inline">\(y\)</span>的变化。如果不是这样，那我们需要将我们提前设定逻辑中的中介变量从模型中去除，去研究<span
class="math inline">\(tax\)</span>对<span
class="math inline">\(y\)</span>的总效应。<em><br />
</em><span class="math display">\[y = \beta_{0} + \beta_{1}tax +
\beta_{2}x + u\]</span></p>
<p>总而言之，我们需要记住不同的模型将起到不同的作用，并且要注重对回归做其他条件不变的解释。</p>
<p>②增加回归元</p>
<p>如果变量<span class="math inline">\(\mathbf{x}_{\mathbf{2}
}\)</span>与<span class="math inline">\(\mathbf{x}_{\mathbf{1}
}\)</span>无关，但<span class="math inline">\(\mathbf{x}_{\mathbf{2}
}\)</span>会影响<span
class="math inline">\(\mathbf{y}\)</span>，那我们应不应该将<span
class="math inline">\(\mathbf{x}_{\mathbf{2}
}\)</span>加入模型中呢？</p>
<p>由于变量<span class="math inline">\(\mathbf{x}_{\mathbf{2}
}\)</span>与<span class="math inline">\(\mathbf{x}_{\mathbf{1}
}\)</span>无关，那么缺少变量<span
class="math inline">\(\mathbf{x}_{\mathbf{2} }\)</span>的话<span
class="math inline">\(\mathbf{x}_{\mathbf{1} }\)</span>的估计系数<span
class="math inline">\(\widehat{\beta_{1} }\)</span>仍旧是无偏的，对<span
class="math inline">\(var\left( \widehat{\beta_{1} } \right) = \frac{
{\widehat{\sigma} }^{2} }{ {SST}_{1}(1 - {R_{1}
}^{2})}\)</span>中的分母<span class="math inline">\({SST}_{1}(1 - {R_{1}
}^{2})\)</span>也是没有影响的。但由于<span
class="math inline">\(\mathbf{x}_{\mathbf{2} }\)</span>会影响<span
class="math inline">\(\mathbf{y}\)</span>，因此加入<span
class="math inline">\(\mathbf{x}_{\mathbf{2}
}\)</span>会使得估计模型的<span
class="math inline">\(SSR\)</span>减小，进而减小分子<span
class="math inline">\({\widehat{\sigma} }^{2} = \frac{SSR}{n - k -
1}\)</span>，从而减小<span class="math inline">\(var\left(
\widehat{\beta_{1} } \right) = \frac{ {\widehat{\sigma} }^{2} }{
{SST}_{1}(1 - {R_{1}
}^{2})}\)</span>，从这个角度来说，我们有必要加入变量<span
class="math inline">\(\mathbf{x}_{\mathbf{2} }\)</span>。</p>
<h2 id="预测与残差分析">预测与残差分析</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11C4y1U7nh/?p=22&amp;spm_id_from=pageDriver">【教材精讲-《计量经济学导论.现代观点》】第六章
6.4 预测区间估计与残差分析_哔哩哔哩_bilibili</a></p>
<h3 id="预测的置信区间两种理解">预测的置信区间（两种理解）</h3>
<p>理解一：对于<span
class="math inline">\(E(Y|X)\)</span>的预测置信区间</p>
<p>换言之，当<span class="math inline">\(X = x\)</span>时，<span
class="math inline">\(E(Y|x)\)</span>的置信区间。在一元回归中：</p>
<p><span class="math display">\[E\left( Y \middle| x \right) = \beta_{0}
+ \beta_{1}x_{1}\]</span></p>
<p>理解二：对于单个个体<span
class="math inline">\(y_{i}\)</span>的预测置信区间</p>
<p>在一元回归中。</p>
<p><span class="math display">\[\widehat{y_{i} } = \widehat{\beta_{0} }
+ \widehat{\beta_{1} }x_{1}\]</span></p>
<p>在第一种理解中，<span
class="math inline">\(E(Y|x)\)</span>的波动来自于<span
class="math inline">\(\beta_{0}\)</span>和<span
class="math inline">\(\beta_{1}\)</span>，而在第二种理解中<span
class="math inline">\(y_{i}\)</span>的波动不仅包含了参数估计量的波动，还包含了自身的情况。因此，一般来说第二种理解的波动会更强，置信区间更宽。举例：</p>
<p>我们已经估计出<span class="math inline">\(gpa\)</span>成绩对<span
class="math inline">\(sat\)</span>成绩的回归模型：</p>
<p><span class="math display">\[gpa = 2 + 0.1sat + u\]</span></p>
<p>当<span class="math inline">\(sat = 1000\)</span>时，<span
class="math inline">\(\widehat{gpa} = 102\)</span>。</p>
<p>根据第一种理解，预测<span class="math inline">\(E\left( y \middle| x
\right)\)</span>的置信区间，即在总体中，对于所有<span
class="math inline">\(sat = 1000\)</span>的同学，其平均<span
class="math inline">\(gpa\)</span>是多少？</p>
<p>根据第二种理解，比如邻居的孩子昨天考了<span class="math inline">\(sat
= 1000\)</span>，那么预测他的<span
class="math inline">\(gpa\)</span>在哪个置信区间？</p>
<h4 id="第一种理解mathbfeyx">第一种理解：<span
class="math inline">\(\mathbf{E(Y|X)}\)</span></h4>
<p>已有模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} + \ldots
+ \beta_{k}x_{k} + u\]</span></p>
<p>我们想要预测当<span class="math inline">\(x_{1} =
c_{1}\)</span>、...、<span class="math inline">\(x_{k} =
c_{k}\)</span>时，<span class="math inline">\(E(y|x_{1} = c_{1}\ldots
x_{k} = c_{k})\)</span>的置信区间。我们记：</p>
<p><span class="math display">\[E\left( y \middle| x_{1} = c_{1}\ldots
x_{k} = c_{k} \right) = \theta_{0}\]</span></p>
<p><span class="math display">\[\theta_{0} = \beta_{0} + \beta_{1}c_{1}
+ \ldots + \beta_{k}c_{k}\]</span></p>
<p>首先对<span class="math inline">\(\theta_{0}\)</span>进行点估计：</p>
<p><span class="math display">\[\widehat{\theta_{0} } =
\widehat{\beta_{0} } + \widehat{\beta_{1} }c_{1} + \ldots +
\widehat{\beta_{k} }c_{k}\]</span></p>
<p>接着对<span
class="math inline">\(\theta_{0}\)</span>进行区间估计，这就需要计算<span
class="math inline">\(se(\widehat{\theta_{0} })\)</span>和<span
class="math inline">\(var(\widehat{\theta_{0}
})\)</span>。如果我们直接计算：</p>
<p><span class="math display">\[var\left( \widehat{\theta_{0} } \right)
= var\left( \widehat{\beta_{0} } + \widehat{\beta_{1} }c_{1} + \ldots +
\widehat{\beta_{k} }c_{k} \right) = var\left( \widehat{\beta_{0} }
\right) + {c_{1} }^{2}var\left( \widehat{\beta_{1} } \right) + \ldots +
{c_{k} }^{2}var\left( \widehat{\beta_{k} } \right) +
许多\widehat{\beta_{i} }与\widehat{\beta_{j}
}的交互作用（协方差）\]</span></p>
<p>这样很难计算，因此我们得转变思路，通过改造模型，直接通过软件计算出<span
class="math inline">\(\widehat{\theta_{0}
}\)</span>的估计量、标准误和置信区间。对于：<em><br />
</em><span class="math display">\[\theta_{0} = \beta_{0} +
\beta_{1}c_{1} + \ldots + \beta_{k}c_{k}\]</span></p>
<p>我们将其移项：</p>
<p><span class="math display">\[\beta_{0} = \theta_{0} - \beta_{1}c_{1}
- \ldots - \beta_{k}c_{k}\]</span></p>
<p>将上式代入原模型，则有：</p>
<p><span class="math display">\[y = \theta_{0} - \beta_{1}c_{1} - \ldots
- \beta_{k}c_{k} + \beta_{1}x_{1} + \ldots + \beta_{k}x_{k} +
u\]</span></p>
<p>进一步移项改写：</p>
<p><span class="math display">\[y = \theta_{0} + \beta_{1}{(x}_{1} -
c_{1}) + \ldots + \beta_{k}{(x}_{k} - c_{k}) + u\]</span></p>
<p>此时，<span
class="math inline">\(\theta_{0}\)</span>就是这个方程的截距项，接下来就可以使用软件估计<span
class="math inline">\(y\)</span>对<span class="math inline">\({(x}_{1} -
c_{1})、\ldots 、{(x}_{k} - c_{k})\)</span>的回归，得到<span
class="math inline">\(\widehat{\theta_{0} }\)</span>、<span
class="math inline">\(se(\widehat{\theta_{0} })\)</span>和置信区间<span
class="math inline">\((\widehat{\theta_{0} } - Cse\left(
\widehat{\theta_{0} } \right),\widehat{\theta_{0} } + Cse\left(
\widehat{\theta_{0} } \right))\)</span></p>
<p>那接下来的问题是，<span class="math inline">\(c_{1}\ldots
c_{k}\)</span>取何值时，<span
class="math inline">\(var(\widehat{\theta_{0}
})\)</span>最小。以一元回归举例，在一元回归模型中：</p>
<p><span class="math display">\[var\left( \widehat{\beta_{0} } \right) =
\frac{\sigma^{2} }{ {SST}_{x} }\frac{\sum_{}^{}{x_{i} }^{2} }{n} =
\frac{\sigma^{2} }{n}\frac{\sum_{}^{}{x_{i} }^{2} }{\sum_{}^{}{(x_{i} -
\overline{x})}^{2} }\]</span></p>
<p><u>当</u><span class="math inline">\(\overline{x} =
0\)</span><u>时，截距项的方差最小</u>。</p>
<p>那么在式子：<span class="math inline">\(y = \theta_{0} +
\beta_{1}{(x}_{1} - c_{1}) + \ldots + \beta_{k}{(x}_{k} - c_{k}) +
u\)</span>中，<span class="math inline">\({(x}_{j} -
c_{j}\)</span>)的平均值为0时，<span
class="math inline">\(var(\widehat{\theta_{0} })\)</span>最小，即<span
class="math inline">\(c_{j} = \overline{x_{j}
}\)</span>时。如下图所示，在一元回归中，当<span class="math inline">\(x
= \overline{x}\)</span>时，<span
class="math inline">\(y\)</span>的方差最小。</p>
<p><img src="https://s2.loli.net/2025/01/28/eKSEQP7TxvGUsbo.png"
style="width:4.42407in;height:3.62188in" /></p>
<h4 id="第二种理解mathbfy_mathbfi-预测值的置信区间">第二种理解：<span
class="math inline">\(\mathbf{y}_{\mathbf{i}
}\)</span>预测值的置信区间</h4>
<p>有一个新观测<span class="math inline">\(({x_{1} }^{0},{x_{2}
}^{0}\ldots{x_{k} }^{0})\)</span>，那么在总体模型中就有：</p>
<p><span class="math display">\[y^{0} = \beta_{0} + \beta_{1}{x_{1}
}^{0} + \ldots + \beta_{k}{x_{k} }^{0} + u^{0}\]</span></p>
<p>而代入样本回归函数，我们有<span
class="math inline">\(y^{0}\)</span>的样本估计量<span
class="math inline">\({\widehat{y} }^{0}\)</span>：</p>
<p><span class="math display">\[{\widehat{y} }^{0} = \widehat{\beta_{0}
} + \widehat{\beta_{1} }{x_{1} }^{0} + \ldots + \widehat{\beta_{k}
}{x_{k} }^{0}\]</span></p>
<p>从中我们有估计的残差<span class="math inline">\({\widehat{e}
}^{0}:\)</span></p>
<p><span class="math display">\[{\widehat{e} }^{0} = y^{0} -
{\widehat{y} }^{0} = \beta_{0} + \beta_{1}{x_{1} }^{0} + \ldots +
\beta_{k}{x_{k} }^{0} + u^{0} - {\widehat{y} }^{0}\]</span></p>
<p>根据<span
class="math inline">\(CLM\)</span>经典线性模型假定（假设1-6），我们知道<span
class="math inline">\(u^{0}\)</span>和<span
class="math inline">\(\widehat{\beta_{j}
}\)</span>都是服从正态分布。由于<span
class="math inline">\(\widehat{\beta_{j} }\)</span>服从正态分布，而<span
class="math inline">\({\widehat{y} }^{0}\)</span>是关于<span
class="math inline">\(\widehat{\beta_{j}
}\)</span>的线性组合（在确定了一组<span
class="math inline">\(x\)</span>的值的条件下），所以<span
class="math inline">\({\widehat{y}
}^{0}\)</span>也服从正态分布。那么<span
class="math inline">\({\widehat{e}
}^{0}\)</span>也是服从正态分布。因此我们可以构建关于<span
class="math inline">\({\widehat{e} }^{0}\)</span>的<span
class="math inline">\(t\)</span>检验统计量：<span
class="math inline">\(\frac{ {\widehat{e} }^{0} }{se({\widehat{e}
}^{0})}\)</span></p>
<p>又因为：</p>
<p><span class="math display">\[var\left( {\widehat{e} }^{0} \right) =
var\left( u^{0} - {\widehat{y} }^{0} \right) = var\left( u^{0} \right) +
var\left( {\widehat{y} }^{0} \right) - cov(u^{0},{\widehat{y}
}^{0})\]</span></p>
<p>又由于其中<span class="math inline">\(u^{0}\)</span>和<span
class="math inline">\({\widehat{y}
}^{0}\)</span>是不相关的【书中有解释，没怎么看懂】，因此：</p>
<p><span class="math display">\[var\left( {\widehat{e} }^{0} \right) =
var\left( u^{0} \right) + var\left( {\widehat{y} }^{0} \right) =
\sigma^{2} + var\left( {\widehat{y} }^{0} \right)\]</span></p>
<p>我们知道<span class="math inline">\({\widehat{y}
}^{0}\)</span>的方差取决于<span class="math inline">\(\widehat{\beta_{j}
}\)</span>的波动性，而当<span class="math inline">\(n \rightarrow
\infty\)</span>时，<span class="math inline">\(var\left(
\widehat{\beta_{j} } \right) = \frac{\sigma^{2} }{n{\sigma_{x} }^{2}(1 -
\rho^{2})}\)</span>，是以<span
class="math inline">\(\frac{1}{n}\)</span>的速度收缩到0。而<span
class="math inline">\(\sigma^{2}\)</span>是总体方差，不随样本量的变化而变化。所以<span
class="math inline">\(var\left( {\widehat{e} }^{0}
\right)\)</span>中总体误差项方差<span
class="math inline">\(\sigma^{2}\)</span>占主导地位。</p>
<p>因此：</p>
<p><span class="math display">\[sd\left( {\widehat{e} }^{0} \right) =
\sqrt{var\left( u^{0} \right) + var\left( {\widehat{y} }^{0} \right)} =
\sqrt{\sigma^{2} + var\left( {\widehat{y} }^{0} \right)} =
{\lbrack{se\left( {\widehat{y} }^{0} \right)}^{2} +
\sigma^{2}\rbrack}^{\frac{1}{2} }\]</span></p>
<p><span class="math display">\[se\left( {\widehat{e} }^{0} \right) =
\sqrt{ {\widehat{\sigma} }^{2} + var\left( {\widehat{y} }^{0} \right)} =
{\lbrack{se\left( {\widehat{y} }^{0} \right)}^{2} + {\widehat{\sigma}
}^{2}\rbrack}^{\frac{1}{2} }\]</span></p>
<p>那么关于<span class="math inline">\({\widehat{e}
}^{0}\)</span>的<span class="math inline">\(t\)</span>检验统计量：<span
class="math inline">\(\frac{ {\widehat{e} }^{0} }{se\left( {\widehat{e}
}^{0} \right)} = \frac{ {\widehat{e} }^{0} }{\left\lbrack {se\left(
{\widehat{y} }^{0} \right)}^{2} + {\widehat{\sigma} }^{2}
\right\rbrack^{\frac{1}{2} } }\)</span>服从自由度为<span
class="math inline">\(n - k - 1\)</span>的<span
class="math inline">\(t\)</span>分布。假设我们需要构建置信度为95%的置信区间，那么就有：</p>
<p><span class="math display">\[P\left( - t_{0.025} \leq \frac{
{\widehat{e} }^{0} }{se\left( {\widehat{e} }^{0} \right)} \leq t_{0.025}
\right) = 95\%\]</span></p>
<p>因此<span class="math inline">\({\widehat{e}
}^{0}\)</span>在95%置信水平上的置信区间为<span class="math inline">\(\pm
se\left( {\widehat{e} }^{0} \right)t_{0.025}\)</span>。又由于<span
class="math inline">\({\widehat{e} }^{0} = y^{0} - {\widehat{y}
}^{0}\)</span>，因此我们就能能够求出<span
class="math inline">\(y^{0}\)</span>在95%置信水平上的置信区间为：</p>
<p><span class="math display">\[{\widehat{y} }^{0} \pm se\left(
{\widehat{e} }^{0} \right)t_{0.025}\]</span></p>
<p>根据查表<span class="math inline">\(t_{0.025} \approx
1.96\)</span>，一些情况下为了方便我们也取2。</p>
<p>我们再对这个置信区间进一步分析，为什么求<span
class="math inline">\(y^{0}\)</span>的置信区间要将<span
class="math inline">\({\widehat{e}
}^{0}\)</span>的标准误纳入进来呢？如果我们仅有<span
class="math inline">\({\widehat{y}
}^{0}\)</span>，其实是只考虑到了影响<span
class="math inline">\({\widehat{y} }^{0}\)</span>的<span
class="math inline">\(\widehat{\beta_{j}
}\)</span>的波动，也就是我们从样本中估计出来的波动。但是，在我们实际预测个人时，不仅要考虑我们样本中给出的信息，还要考虑总体中我们对于<span
class="math inline">\(y^{0}\)</span>观测不到的个体信息差异，因此在预测<span
class="math inline">\(y^{0}\)</span>时，我们将<span
class="math inline">\({\widehat{e} }^{0}\)</span>进来，实际上是将<span
class="math inline">\({\widehat{e} }^{0}\)</span>中的<span
class="math inline">\(u^{0}\)</span>纳入考虑（以书中的表述，我们必须考虑另一个十分重要的误差来源：观测不到的误差方差，它度量了我们对那些既影响<span
class="math inline">\(y\)</span>而又无法观测因素的忽略），同时影响<span
class="math inline">\({\widehat{y} }^{0}\)</span>的<span
class="math inline">\(\widehat{\beta_{j}
}\)</span>的波动一般是远小于<span class="math inline">\({\widehat{e}
}^{0}\)</span>中的<span
class="math inline">\(u^{0}\)</span>的波动的。</p>
<h3 id="预测的特殊情况">预测的特殊情况</h3>
<p>当因变量为<span class="math inline">\(log(y)\)</span>时，如何对<span
class="math inline">\(y\)</span>进行预测？</p>
<p>假设已有模型：</p>
<p><span class="math display">\[\log(y) = \beta_{0} + \beta_{1}x_{1} +
\ldots + \beta_{k}x_{k} + u\]</span></p>
<p>通过<span class="math inline">\(OLS\)</span>估计，我们有：</p>
<p><span class="math display">\[\widehat{\log(y)} = \widehat{\beta_{0} }
+ \widehat{\beta_{1} }x_{1} + \ldots + \widehat{\beta_{k}
}x_{k}\]</span></p>
<p>那么我们很有可能简单的认为<span class="math inline">\(\widehat{y} =
exp(\widehat{\beta_{0} } + \widehat{\beta_{1} }x_{1} + \ldots +
\widehat{\beta_{k} }x_{k})\)</span>，但这是系统地低估了<span
class="math inline">\(y\)</span>的预测值。我们将总体模型两边取指数函数，则有：</p>
<p><span class="math display">\[y = exp(\beta_{0} + \beta_{1}x_{1} +
\ldots + \beta_{k}x_{k})exp(u)\]</span></p>
<p>在假设1-5的前提下，总体回归函数就是：</p>
<p><span class="math display">\[E\left( y \middle| x \right) =
E(exp(u))exp(\beta_{0} + \beta_{1}x_{1} + \ldots +
\beta_{k}x_{k})\]</span></p>
<p>我们下面分为两种情况进行考虑：</p>
<p>①如果还满足假设6，<span class="math inline">\(u\sim
N(0,\sigma^{2})\)</span>，可以证明<span class="math inline">\(E\left(
exp(u) \right) = exp(\frac{\sigma^{2} }{2})\)</span>，就有：</p>
<p><span class="math display">\[E\left( y \middle| x \right) =
exp(\frac{\sigma^{2} }{2})exp(\beta_{0} + \beta_{1}x_{1} + \ldots +
\beta_{k}x_{k})\]</span></p>
<p>那么当知道一组<span class="math inline">\(x\)</span>值时，<span
class="math inline">\(y\)</span>的预测值：</p>
<p><span class="math display">\[\widehat{y} = exp(\frac{
{\widehat{\sigma} }^{2} }{2})exp(\widehat{\beta_{0} } +
\widehat{\beta_{1} }x_{1} + \ldots + \widehat{\beta_{k}
}x_{k})\]</span></p>
<p>②如果我们没有假设6，只有假设1-5，误差项<span
class="math inline">\(u\)</span>独立于自变量，但不需要正态分布。那么我们有：</p>
<p><span class="math display">\[\widehat{y} = \widehat{\alpha_{0}
}\exp\left( \widehat{\log(y)} \right) = \widehat{\alpha_{0} }\exp\left(
\widehat{\beta_{0} } + \widehat{\beta_{1} }x_{1} + \ldots +
\widehat{\beta_{k} }x_{k} \right)\]</span></p>
<p><span class="math inline">\(\exp\left( \widehat{\log(y)}
\right)\)</span>是能够估计出来的，现在需要计算的就是<span
class="math inline">\(\widehat{\alpha_{0} }\)</span>（其本质是<span
class="math inline">\(E(exp(u))\)</span>的估计）。有两种解决办法：</p>
<p>方法一：我们使用样本中的残差作为<span
class="math inline">\(E(exp(u))\)</span>中误差的估计。那么<span
class="math inline">\(\widehat{\alpha_{0} } =
\frac{1}{n}\sum_{}^{}{exp(\widehat{u_{i} })}\)</span>。</p>
<p>方法二：我们记<span class="math inline">\(m_{i} = \exp\left(
\widehat{\beta_{0} } + \widehat{\beta_{1} }x_{1} + \ldots +
\widehat{\beta_{k} }x_{k}
\right)\)</span>，也就是对于每一个观测，我们都能计算出一个<span
class="math inline">\(m_{i}\)</span>。因此，我们就有模型：</p>
<p><span class="math display">\[E\left( y \middle| x \right) =
\alpha_{0}m_{i}\]</span></p>
<p>现在计算<span class="math inline">\(E\left( y \middle| x
\right)\)</span>对<span
class="math inline">\(m_{i}\)</span>的无截距的回归，就能估计出系数<span
class="math inline">\(\widehat{\alpha_{0} }\)</span>。</p>
<h3 id="残差分析拓展思路">残差分析（拓展思路）</h3>
<p>在我们前面的叙述中，<span class="math inline">\(\widehat{u_{i} } =
y_{i} - \widehat{y_{i} }\)</span>。其中<span
class="math inline">\(\widehat{y_{i}
}\)</span>代表的是用已知模型或者已知变量能够解释的波动。那么<span
class="math inline">\(\widehat{u_{i}
}\)</span>就包括了我们那些观测不到的，但是会影响<span
class="math inline">\(y_{i}\)</span>的变量所产生的效应。从这个角度去分析实际问题，能够有很多有意思的结论。</p>
<p>举例一：法官认为，是贫困而不是隔离影响了学生的分数。</p>
<p>问题：相对于周边郊区，哈特福德校区在标准化考试中的表现不佳，是不是因为学校高度隔离而影响了学校质量？</p>
<p>将考试分数与各校区的社会经济因素进行回归。再给定哈特福德校区学生的贫困程度，发现预测的分数与实际分数基本一致，说明是贫困而不是隔离影响了学生的分数。</p>
<p>举例二：判断法学院的附加价值</p>
<p>将所有法学院学生的薪资中位数与一系列学生特征（新入学分数的中位数等）进行回归，可以得到每个法学院的预测值和残差。残差最大的法学院预计具有最高的附加价值。</p>
<h1 id="第7章-含有定性信息的多元回归分析二值虚拟变量">第7章
含有定性信息的多元回归分析：二值（虚拟）变量</h1>
<h2 id="模型中包含一个虚拟变量">模型中包含一个虚拟变量</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV18u4y157VT/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第七章
7.1 模型包含一个虚拟变量_哔哩哔哩_bilibili</a></p>
<p>我们把变量划分为定量和定性变量两类。定性变量的取值一般是离散的、有限的。在将定性变量放入模型中前，首先要进行编码。</p>
<p>直观地来讲，编码就是把字符替换成数字。最常见的，是将其编码为二值变量/0-1变量/虚拟变量。一般我们是将其编码为0和1（方便后续的系数解释），同时我们以替换为1的值作为变量名，譬如男性<span
class="math inline">\(male\)</span>取0，女性<span
class="math inline">\(female\)</span>取1，那么变量名就是<span
class="math inline">\(female\)</span>。</p>
<p>那我们如何把二值变量放入模型呢？</p>
<p>例子：研究性别对工资的影响。有如下模型：</p>
<p><span class="math display">\[wage = \beta_{0} + \delta_{0}female +
\beta_{1}edu + u\]</span></p>
<p>直接将二值变量<span
class="math inline">\(female\)</span>放入模型，进行系数估计即可。那么<span
class="math inline">\(\delta_{0}\)</span>的含义是什么呢？</p>
<p>含义一：当<span
class="math inline">\(female\)</span>分别取0和1时，我们有如下两个方程。<span
class="math inline">\(\delta_{0}\)</span>就代表了这两个回归方程的截距差。</p>
<p><span class="math display">\[female = \left\{ \begin{array}{r}
1\ \ 女:wage = \beta_{0} + \delta_{0} + \beta_{1}edu + u \\
0\ \ 男:wage = \beta_{0} + \beta_{1}edu + u
\end{array} \right.\ \]</span></p>
<p><img src="https://s2.loli.net/2025/01/28/cmPvXKCZ3hxj8y6.png"
style="width:4.39729in;height:2.88967in" /></p>
<p>含义二：从上图我们可以看出，<span
class="math inline">\(edu\)</span>任意取一个值，<span
class="math inline">\(\delta_{0}\)</span>代表男女工资的差异；</p>
<p>含义三：对于男性和女性我们能分别得到以下两个条件期望。因此<span
class="math inline">\(\delta_{0}\)</span>还代表两个条件期望的截距差。</p>
<p><span class="math display">\[E\left( wage \middle| female = 1,edu
\right) = \beta_{0} + \delta_{0} + \beta_{1}edu\]</span></p>
<p><span class="math display">\[E\left( wage \middle| female = 0,edu
\right) = \beta_{0} + \beta_{1}edu\]</span></p>
<p>有以下注意要点：</p>
<p>①我们不需要也不能把男性（<span
class="math inline">\(male\)</span>）和女性（<span
class="math inline">\(female\)</span>）两个变量同时放入模型，因为一个变量就足以包含所有男性和女性的信息，并且如果都加入的话会导致<span
class="math inline">\(male = 1 -
female\)</span>出现多重共线性（虚拟变量陷阱）。进一步推广，如果是一个<span
class="math inline">\(n\)</span>类取值的定性变量，那么我们只能将其转换成<span
class="math inline">\(n - 1\)</span>个虚拟变量/0-1变量。</p>
<p>②要尤其注意基准组的设置，我们将虚拟变量取值为0的组叫做基准组。因此其中<span
class="math inline">\(\delta_{0}\)</span>的含义表示为其他组和基准组的差异。</p>
<h2 id="多类别虚拟变量">多类别虚拟变量</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1mw411n754/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第七章
7.2 模型包含多个虚拟变量_哔哩哔哩_bilibili</a></p>
<p>变量有<span class="math inline">\(g\)</span>组取值，我们就要放入<span
class="math inline">\(g - 1\)</span>个虚拟变量！</p>
<p>其中需要注意：一个模型可以同时放多个虚拟变量；其实是用<span
class="math inline">\(g - 1\)</span>个虚拟变量分为了<span
class="math inline">\(g\)</span>个组别；我们需要结合实际问题和我们的研究注意基准组的设置，使得估计的系数正好是我们想要验证的内容。</p>
<p>那如果虚拟变量包含序数信息/定序数据怎么处理呢？</p>
<p>定序数据与定性数据同样有类别之分，但定序数据还有高低之分，如满意度、排名等。但是注意！定序数据不是定距的！</p>
<p>举例：研究城市信用等级<span
class="math inline">\(CR\)</span>（1、2、3、4、5等级）对地方政府债券利率<span
class="math inline">\(MBR\)</span>是否有显著影响。我们考虑如下两种模型：</p>
<p>模型一：</p>
<p><span class="math display">\[MBR = \beta_{0} + \beta_{1}CR +
u\]</span></p>
<p>模型二：<em><br />
</em><span class="math display">\[MBR = \beta_{0} + \delta_{1}{CR}_{1} +
\delta_{2}{CR}_{2} + \delta_{3}{CR}_{3} + \delta_{4}{CR}_{4} +
u\]</span></p>
<p>对于模型一，其背后的逻辑是<span
class="math inline">\(CR\)</span>每变化一个单位，都会使<span
class="math inline">\(MBR\)</span>变化相同的<span
class="math inline">\(\beta_{1}\)</span>个单位，换言之，模型假定<span
class="math inline">\(CR\)</span>每变化一个单位的影响是相同的。但这与实际是不符合的，因为定序数据虽然有高低之分，但不是等距的。</p>
<p>再看模型二，我们将变量<span
class="math inline">\(CR\)</span>拆分为四个虚拟变量，这样设定就允许<span
class="math inline">\(CR\)</span>每变动一个单位，对<span
class="math inline">\(MBR\)</span>的影响是不同的。这种设定是符合逻辑的。</p>
<p>因此，对比模型一和模型二，模型一实际上是在模型二的基础上增加了一个强约束。这个约束是：<span
class="math inline">\(\delta_{2} = 2\delta_{1}\)</span>，<span
class="math inline">\(\delta_{3} = 3\delta_{1}\)</span>，<span
class="math inline">\(\delta_{4} =
4\delta_{1}\)</span>。将这个约束代入模型二中：</p>
<p><span class="math display">\[MBR = \beta_{0} + \delta_{1}({CR}_{1} +
2{CR}_{2} + 3{CR}_{3} + 4{CR}_{4}) + u\]</span></p>
<p>我们令<span class="math inline">\(\left( {CR}_{1} + 2{CR}_{2} +
3{CR}_{3} + 4{CR}_{4} \right) = {CR}^{&#39;}\)</span>，则有模型三：</p>
<p><span class="math display">\[MBR = \beta_{0} + \delta_{1}{CR}^{&#39;}
+ u\]</span></p>
<p>比较模型三和模型一，当<span class="math inline">\(CR =
1\)</span>时<span class="math inline">\({CR}^{&#39;} = {CR}_{1} +
2{CR}_{2} + 3{CR}_{3} + 4{CR}_{4} = 1 + 2*0 + 3*0 + 4*0 =
1\)</span>；当<span class="math inline">\(CR = 2\)</span>时<span
class="math inline">\({CR}^{&#39;} = {CR}_{1} + 2{CR}_{2} + 3{CR}_{3} +
4{CR}_{4} = 0 + 2*1 + 3*0 + 4*0 = 2\)</span>；当<span
class="math inline">\(CR = 3\)</span>时<span
class="math inline">\({CR}^{&#39;} = {CR}_{1} + 2{CR}_{2} + 3{CR}_{3} +
4{CR}_{4} = 0 + 2*0 + 3*1 + 4*0 = 3\)</span>；当<span
class="math inline">\(CR = 4\)</span>时<span
class="math inline">\({CR}^{&#39;} = {CR}_{1} + 2{CR}_{2} + 3{CR}_{3} +
4{CR}_{4} = 0 + 2*0 + 3*0 + 4*1 = 0\)</span>；当<span
class="math inline">\(CR = 0\)</span>时<span
class="math inline">\({CR}^{&#39;} = {CR}_{1} + 2{CR}_{2} + 3{CR}_{3} +
4{CR}_{4} = 0 + 2*0 + 3*0 + 4*0 = 0\)</span>；发现<span
class="math inline">\({CR}^{&#39;} =
CR\)</span>。因此模型一和模型三是等价的。</p>
<p>所以，我们有结论在模型二上加入强约束：<span
class="math inline">\(\delta_{2} = 2\delta_{1}\)</span>，<span
class="math inline">\(\delta_{3} = 3\delta_{1}\)</span>，<span
class="math inline">\(\delta_{4} =
4\delta_{1}\)</span>，就等价于模型一。</p>
<p>【使用<span
class="math inline">\(F\)</span>统计量对模型一和模型二进行检验（没怎么看明白）】</p>
<p>还有一个小问题，如果我们的定序数据有相当多个取值（比如说有1000个），那我们是设置999个虚拟变量嘛？这显然是不现实的，也是性价比低的。同样的，我们也不能只设置一个变量而忽略其不是定距的。那么我们怎么办呢？</p>
<p>★我们可以选取一个折中的办法。将1000个取值划分为不同的组别（比如1-10，11-25，26-40，41-60，100-1000），假设划分成了5个组别，那么我们只需要设置4个虚拟变量，并分别估计它们的系数。这样的设定其背后的默认约束是，相同组别内我们认为变化一个单位对于因变量的影响是相同的，不同组别间我们认为是不同的。（这种操作方法在有些地方叫做<mark><u>连续变量离散化</u></mark>）。在实际问题中，一些变量直接放入模型的话其估计系数是不显著的，因为此时估计系数是一个平均的结果，可能存在相互抵消导致平均不显著。那此时如果我们将其离散化，就有可能找出估计系数显著的组别，反映出这一组对因变量影响的重要程度。</p>
<h2 id="虚拟变量的交互">虚拟变量的交互</h2>
<p>当有交互变量出现时，是可以反映一个调节关系，或者是一个变量对因变量的影响要收到另一个变量的影响。</p>
<h3 id="虚拟变量虚拟变量">虚拟变量*虚拟变量</h3>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Du4y1G7Pd/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第七章
7.3 虚拟变量与虚拟变量的交互_哔哩哔哩_bilibili</a></p>
<p>有例子：</p>
<p><span class="math display">\[\log(wage) = \beta_{0} + \beta_{1}female
+ \beta_{2}married + \beta_{3}(female*married) +
\beta_{4}edu\]</span></p>
<p><span class="math display">\[\widehat{\log(wage)} = 0.32 - 0.11female
+ 0.21married - 0.301(female*married) + \beta_{4}edu\]</span></p>
<p>其中<span class="math inline">\(female\)</span>和<span
class="math inline">\(married\)</span>是定序变量，<span
class="math inline">\(edu\)</span>是定量变量。</p>
<p>我们将所有分组写出：</p>
<table style="width:98%;">
<colgroup>
<col style="width: 12%" />
<col style="width: 11%" />
<col style="width: 12%" />
<col style="width: 62%" />
</colgroup>
<thead>
<tr>
<th></th>
<th style="text-align: left;"><span
class="math display">\[female\]</span></th>
<th style="text-align: left;"><span
class="math display">\[married\]</span></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>1（基准组）</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td><span class="math display">\[\widehat{\log(wage)} = 0.32 +
\beta_{4}edu\]</span></td>
</tr>
<tr>
<td>2</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
<td><span class="math display">\[\widehat{\log(wage)} = 0.32 + 0.21 +
\beta_{4}edu\]</span></td>
</tr>
<tr>
<td>3</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
<td><span class="math display">\[\widehat{\log(wage)} = 0.32 - 0.11 +
\beta_{4}edu\]</span></td>
</tr>
<tr>
<td>4</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td><span class="math display">\[\widehat{\log(wage)} = 0.32 - 0.11 +
0.21 - 0.301 + \beta_{4}edu\]</span></td>
</tr>
</tbody>
</table>
<p>其中基准组是<span class="math inline">\(female = 0\)</span>且<span
class="math inline">\(married =
0\)</span>，即未婚男性。两个定序变量将模型一共分为四组。每组之间只有截距项不同，斜率是相同的。我们可以用三个虚拟变量来表示这四组情况（未婚女性、已婚女性、未婚男性、已婚男性）。</p>
<p><span
class="math inline">\(\beta_{1}\)</span>衡量未婚女性相比未婚男性对因变量的影响（组1和组3），<span
class="math inline">\(\beta_{2}\)</span>衡量已婚男性相比未婚男性对因变量的影响（组1和组2），<span
class="math inline">\(\beta_{3} +
\beta_{1}\)</span>表示已婚女性相比于已婚男性对因变量的影响（组2和组4），<span
class="math inline">\(\beta_{3} +
\beta_{2}\)</span>表示已婚女性相比于未婚女性对因变量的影响（组3和组4）。</p>
<p><img src="https://s2.loli.net/2025/01/28/dl9RHarVnhSUxB5.png"
style="width:5.33894in;height:2.46053in" /></p>
<h3 id="虚拟变量定量变量">虚拟变量*定量变量</h3>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1YH4y117sP/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第七章
7.4 虚拟变量与定量变量的交互_哔哩哔哩_bilibili</a></p>
<p>有例子：</p>
<p><span class="math display">\[\log(wage) = \beta_{0} +
\delta_{0}female + \beta_{1}educ + \delta_{1}(female*educ) +
u\]</span></p>
<p><span class="math display">\[female = \left\{ \begin{array}{r}
1\ \ 女:\log(wage) = \left( \beta_{0} + \delta_{0} \right) + (\beta_{1}
+ \delta_{1})educ + u \\
0\ \ 男:\log(wage) = \beta_{0} + \beta_{1}educ + u
\end{array} \right.\ \]</span></p>
<p>因此，如果虚拟变量和定量变量做交互，截距项和斜率都发生了改变。</p>
<p><span
class="math inline">\(\delta_{0}\)</span>表示两组之间的截距差率，也就是当<span
class="math inline">\(educ =
0\)</span>时，女性和男性的工资差距。而当<span
class="math inline">\(educ\)</span>发生改变时，男性和女性之间的工资差距也会发生改变；</p>
<p><span
class="math inline">\(\beta_{1}\)</span>在基准组（男性组）中，<span
class="math inline">\(educ\)</span>对工资的影响效应。而在女性组中，<span
class="math inline">\(educ\)</span>对工资的影响效应是<span
class="math inline">\(\beta_{1} + \delta_{1}\)</span>；</p>
<p><span class="math inline">\(\delta_{1}\)</span>代表男女两组，<span
class="math inline">\(educ\)</span>对工资的影响效应差。</p>
<p>★其中有一点需要注意，当我们加入了交互项<span
class="math inline">\(female*educ\)</span>时，可能会使得原来显著的<span
class="math inline">\(\delta_{0}\)</span>变得不显著，其原因是<span
class="math inline">\(female\)</span>与交互项<span
class="math inline">\(female*educ\)</span>的相关性更高，使得<span
class="math inline">\(female\)</span>系数<span
class="math inline">\(\delta_{0}\)</span>的标准误<span
class="math inline">\(se\left( \delta_{0} \right) = \frac{
{\widehat{\sigma} }^{2} }{ {SST}_{female}(1 - {R^{2}
}_{female})}\)</span>很大。其解决办法是，上文说过<span
class="math inline">\(\delta_{0}\)</span>表示的是当<span
class="math inline">\(educ =
0\)</span>时，女性和男性的工资差距。但我们在实际问题中一般会想要研究的是<span
class="math inline">\(educ\)</span>为某一个特定的值，比如12，那我们就可以将模型中的<span
class="math inline">\(educ\)</span>变换为<span
class="math inline">\(educ - 12\)</span>，那么:</p>
<p><span class="math display">\[female = \left\{ \begin{array}{r}
1\ \ 女:\log(wage) = \left( \beta_{0} + \delta_{0} \right) + (\beta_{1}
+ \delta_{1})(educ - 12) + u \\
0\ \ 男:\log(wage) = \beta_{0} + \beta_{1}(educ - 12) + u
\end{array} \right.\ \]</span></p>
<p>此时，<span class="math inline">\(\delta_{0}\)</span>表示的是当<span
class="math inline">\(educ =
12\)</span>时，女性和男性的工资差距。这个指标对我们来说就更有意义。通同时，过这种方式也可能能减少<span
class="math inline">\(female\)</span>与交互项<span
class="math inline">\(female*(educ -
12)\)</span>的相关程度，从而使估计的系数统计显著。</p>
<p>特殊情况：检验分组回归差异（邹至庄检验）</p>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1uc411U7Xa/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第七章
7.5 邹至庄检验_哔哩哔哩_bilibili</a></p>
<p>在实际问题中，根据定类变量，我们常常将样本分为不同组别分别进行回归，以此来检验不同组别的回归差异。</p>
<p>仍旧使用上述例子，不同的是，我们想要分为男、女两组分别进行回归估计。<span
class="math inline">\(y\)</span>对其余自变量<span
class="math inline">\(x_{1}\ldots x_{k}\)</span>回归的模型如下：</p>
<p><span class="math display">\[y = \beta_{g,0} + \beta_{g,1}x_{1} +
\beta_{g,2}x_{2} + \ldots + \beta_{g,k}x_{k} + u\]</span></p>
<p>其中下标<span class="math inline">\(g =
1\)</span>为组别1（女性），<span class="math inline">\(g =
2\)</span>为组别2（男性）。</p>
<p>★我们对男性和女性进行分组回归，可以认为是做了以下这个统一的回归：</p>
<p><span class="math display">\[y = \beta_{0} + \delta_{0}female +
\beta_{1}x_{1} + \delta_{1}(female*x_{1}) + \beta_{2}x_{2} +
\delta_{2}(female*x_{2}) + \ldots + \beta_{k}x_{k} +
\delta_{k}(female*x_{k}) + u\]</span></p>
<p>进一步解释，由于我们用的自变量和因变量都是相同的，因此对男女进行分组回归所估计出来的两个模型只有没有自变量前的估计系数是不同的。因此我们可以将其整合到上述这个模型中，当<span
class="math inline">\(female = 0\)</span>是，就是男性的回归方程，当<span
class="math inline">\(female = 1\)</span>时，所有的截距项和系数<span
class="math inline">\(\beta_{j}\)</span>都会再加入一个<span
class="math inline">\(\delta_{j}\)</span>，此时估计出来的模型就是女性的回归方程。</p>
<p>那么如果我们想要检验两个模型有没有显著差异，就是要检验原假设：</p>
<p><span class="math display">\[H_{0}:\delta_{0} = \ldots{= \delta}_{k}
= 0\]</span></p>
<p>这是对多个线性约束的检验，使用<span
class="math inline">\(F\)</span>检验：</p>
<p><span class="math display">\[F = \frac{({SSR}_{r} - {SSR}_{ur})/q}{
{SSR}_{ur}/(n - k - 1)}\]</span></p>
<p>不受约束模型：<em><br />
</em><span class="math display">\[y = \beta_{0} + \delta_{0}female +
\beta_{1}x_{1} + \delta_{1}(female*x_{1}) + \beta_{2}x_{2} +
\delta_{2}(female*x_{2}) + \ldots + \beta_{k}x_{k} +
\delta_{k}(female*x_{k}) + u\]</span></p>
<p>受约束模型：</p>
<p><span class="math display">\[y = \beta_{0} + 0 + \beta_{1}x_{1} + 0 +
\beta_{2}x_{2} + 0 + \ldots + \beta_{k}x_{k} + 0 + u\]</span></p>
<p>但由于我们是进行了分组回归，得到了男性和女性两个回归方程，因此就有两个<span
class="math inline">\(SSR\)</span>，分别记为：<span
class="math inline">\({SSR}_{male}\)</span>、<span
class="math inline">\({SSR}_{female}\)</span>。我们能够知道<span
class="math inline">\({SSR}_{male} + {SSR}_{female} =
{SSR}_{ur}\)</span>。约束数量为：<span class="math inline">\(q = k +
1\)</span>。自由度为<span class="math inline">\(n - 2(k +
1)\)</span>。因此在这个问题下的<span
class="math inline">\(F\)</span>检验统计量为：</p>
<p><span class="math display">\[F = \frac{\lbrack{SSR}_{r} - \left(
{SSR}_{male} + {SSR}_{female} \right)\rbrack/(k + 1)}{\left(
{SSR}_{male} + {SSR}_{female} \right)/\lbrack n - 2(k + 1)\rbrack} =
\frac{ {SSR}_{r} - \left( {SSR}_{male} + {SSR}_{female} \right)}{\left(
{SSR}_{male} + {SSR}_{female} \right)}\frac{n - 2(k + 1)}{k +
1}\]</span></p>
<p>这就是<mark><u>邹至庄检验</u></mark>！</p>
<h2 id="二值因变量模型线性概率模型">二值因变量模型（线性概率模型）</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1ic41117aV/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">教材精讲-《计量经济学导论.现代观点》】第七章
7.6 线性概率模型_哔哩哔哩_bilibili</a></p>
<p>有模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + u\]</span></p>
<p>如果<span
class="math inline">\(y\)</span>只有0和1两种取值，那么它就是一个二值因变量。经过<span
class="math inline">\(OLS\)</span>估计后，在<span
class="math inline">\(\beta_{1}\)</span>进行解释时，我们就不能说当控制其他条件时，<span
class="math inline">\(x_{1}\)</span>变化1个单位，<span
class="math inline">\(y\)</span>变化<span
class="math inline">\(\beta_{1}\)</span>个单位。那么我们该如何解释呢？</p>
<p>从总体回归模型角度来思考，<mark><u>如果假设</u></mark><span
class="math inline">\(E\left( u \middle| x \right) =
0\)</span>，那么我们有总体回归模型：</p>
<p><span class="math display">\[E\left( y \middle| x \right) = \beta_{0}
+ \beta_{1}x_{1} + \beta_{2}x_{2}\]</span></p>
<p>由于<span
class="math inline">\(y\)</span>只有0和1两个取值，因此可以把其看成一个伯努利试验，符合伯努利分布，因此<span
class="math inline">\(E\left( y \middle| x \right) = P\left( y = 1
\middle| x \right)\)</span>，所以有：</p>
<p><span class="math display">\[P\left( y = 1 \middle| x \right) =
\beta_{0} + \beta_{1}x_{1} + \beta_{2}x_{2}\]</span></p>
<p>这种模型就叫做<mark><u>线性概率模型（</u></mark><span
class="math inline">\(LPM\)</span><mark><u>模型，也叫做二值响应模型）</u></mark>。</p>
<p>其满足：<span
class="math inline">\(y\)</span>只能取两个值；响应概率<span
class="math inline">\(P\left( y = 1 \middle| x
\right)\)</span>可以写成各个<span
class="math inline">\(x\)</span>的线性组合。其本质还是使用<span
class="math inline">\(OLS\)</span>估计。将估计出来的系数代入，可以得到估计概率：</p>
<p><span class="math display">\[\widehat{P\left( y = 1 \middle| x
\right)} = \widehat{\beta_{0} } + \widehat{\beta_{1} }x_{1} +
\widehat{\beta_{2} }x_{2}\]</span></p>
<p><span class="math inline">\(LPM\)</span>模型中<span
class="math inline">\(\beta_{1}\)</span>表示<span
class="math inline">\(x_{1}\)</span>变化一个单位，<span
class="math inline">\(y\)</span>成功的概率变化多少。</p>
<p>线性概率模型与<span
class="math inline">\(logistic\)</span>模型不同。线性概率模型是直接用0-1取值放入<span
class="math inline">\(OLS\)</span>回归中进行估计，而<span
class="math inline">\(logistic\)</span>模型是将0-1取值通过<span
class="math inline">\(logit\)</span>函数映射到<span
class="math inline">\(( - \infty, + \infty)\)</span>的范围。</p>
<p>举例：</p>
<p><span class="math display">\[\widehat{已婚妇女是否参加工作} = 0.586 +
0.0034丈夫收入 + 0.038妇女受教育程度 + 0.039妇女过去工作经验 -
0.0006{工作经验}^{2} - 0.016年龄 - 0.262幼儿数 +
0.013儿童数\]</span></p>
<p>其中，<span class="math inline">\(已婚妇女是否参加工作 =
1\)</span>表示参加工作。</p>
<p><span class="math inline">\(妇女受教育程度\)</span>系数<span
class="math inline">\(\beta
=\)</span><!-- -->0.038表示，控制其余因素，妇女受教育程度每变化一个单位，其婚后参加工作的可能性变化0.038。</p>
<p>使用<span
class="math inline">\(LPM\)</span>模型建模可能遇到的问题：</p>
<p>①由于是使用<span
class="math inline">\(OLS\)</span>回归，那么因变量的预测值（如<span
class="math inline">\(\widehat{已婚妇女是否参加工作}\)</span>）完全有可能预测到小于0或者大于1的情况。一个可能的改善方法就是设定阈值"一刀切"，譬如估计出来因变量大于0.5，我们都赋值为1，小于0.5，赋值为0。</p>
<p>②<span
class="math inline">\(LPM\)</span>模型背后的认为，概率与自变量是成线性相关的，但在实际问题中很多可能不是这样。比如研究幼儿数对<span
class="math inline">\(已婚妇女是否参加工作\)</span>的影响，实际生活中幼儿数从0到1，和从1到2，对已婚妇女是否参加工作的影响我们认为一般是不同的。那这个问题我们怎么解决呢？<mark><u>只能从样本出发，实际问题实际分析</u></mark>。如果我们的样本中，只有幼儿数为0和1的取值，从1到2就不是我们需要讨论的范围，从而可以规避这个问题。与之相似的是当模型中出现了二次项，此时某个变量对因变量的影响会收到另一个二次项系数的影响，可能会产生拐点，也就是斜率为0的地方。如果我们的样本跨过了这个拐点，那么我们需要分析这个拐点是否符合实际情况，但如果这个拐点不在我们的样本范围中，那么就不需要去考虑这个拐点了。</p>
<p>③确定存在无法避免的<mark><u>异方差问题</u></mark>。根据伯努利分布，<span
class="math inline">\(var\left( y \middle| x \right) = p\left( y|x
\right)\lbrack 1 - p\left( y|x \right)\rbrack\)</span>，而<span
class="math inline">\(p\left( y|x \right) = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2}\)</span>。这表明除非<span class="math inline">\(p\left(
y|x \right)\)</span>与所有<span
class="math inline">\(x\)</span>都无关（那这个模型就是错误无意义的），否则<span
class="math inline">\(var\left( y \middle| x
\right)\)</span>一定会随着<span
class="math inline">\(x\)</span>而发生改变。违背了同方差假设，随着这个系数估计的无偏性是没有影响的，但是会影响系数估计的方差和标准误。</p>
<h2 id="离散因变量模型">离散因变量模型</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Fi4y1i7sv/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">教材精讲-《计量经济学导论.现代观点》】第七章
7.7 多值因变量模型_哔哩哔哩_bilibili</a></p>
<p>若因变量的取值为离散的，我们该如何解释系数呢？</p>
<p>有例子（探讨妇女年龄、教育程度对生孩子个数的影响）：</p>
<p><span class="math display">\[children = \beta_{0} + \beta_{1}age +
\beta_{2}edu\]</span></p>
<p><span class="math display">\[\widehat{children} = - 1.997 + 0.175age
- 0.09edu\]</span></p>
<p>我们该如何解释系数<span class="math inline">\(\widehat{\beta_{2} } =
-
0.09\)</span>呢？妇女受教育年限减少1年，生孩子的个数减少0.09？这显然是不正确的。我们仍然从总体回归函数来分析：</p>
<p><span class="math display">\[E(children|age,edu) = \beta_{0} +
\beta_{1}age + \beta_{2}edu\]</span></p>
<p><span class="math display">\[\widehat{E(children|age,edu)} = - 1.997
+ 0.175age - 0.09edu\]</span></p>
<p>给定一组<span class="math inline">\(age\)</span>，<span
class="math inline">\(edu\)</span>，<span class="math inline">\(- 1.997
+ 0.175age - 0.09edu\)</span>就是<span
class="math inline">\(children\)</span>期望的估计。那么可以从期望的角度对<span
class="math inline">\(\widehat{\beta_{2} } = -
0.09\)</span>进行解释：<span class="math inline">\(\widehat{\beta_{2} }
= -
0.09\)</span>表明妇女受教育年限减少1年，平均生育率下降0.09（平均生育率=新出生孩子数/适龄妇女）。具体来说，如果有100个妇女受教育年限都增加1年，那么一共会减少出生9个孩子。</p>
<h2
id="政策分析与项目评价内生性问题">政策分析与项目评价（内生性问题）</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1v94y1P7cL/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">教材精讲-《计量经济学导论.现代观点》】第七章
7.8 政策分析与项目评价_哔哩哔哩_bilibili</a></p>
<p>在政策分析以及使用<span
class="math inline">\(OLS\)</span>回归解决其余实际问题中，内生性问题是绕不开也是必须要解决的问题。简单来说，内生性问题产生是因为模型中的<span
class="math inline">\(u\)</span>包含了会同时影响<span
class="math inline">\(x\)</span>和<span
class="math inline">\(y\)</span>的变量，导致零条件均值假设不成立，即<span
class="math inline">\(E\left( u \middle| x \right) \neq
E(u)\)</span>。而导致这种问题的原因大致可以分为三类：</p>
<p><mark><u>第一类：供给端出现不平衡。最常见的是政策实施，</u></mark>往往政策实施的地点和人群都是指定的，不是随机分配。以奖学金分配举例，那么对于以下模型（探究奖学金发放是否能够提升学生成绩）：</p>
<p><span class="math display">\[Grade = \beta_{0} +
\beta_{1}isGetScholarship + u\]</span></p>
<p>模型中<span
class="math inline">\(\beta_{1}\)</span>是否能够反映因果关系？是否是无偏的？可能要打上一个问号。因为这个模型是不满足零条件均值假设的，即<span
class="math inline">\(E(u|x) \neq
E(u)\)</span>。具体来说奖学金的发放是有目标性的，不是随机发放，因此<span
class="math inline">\(E(本来的学习成绩，学习兴趣等|isGetScholarship = 1)
\neq E(本来的学习成绩，学习兴趣等|isGetScholarship =
0)\)</span>。所以我们不能说<span
class="math inline">\(Grade\)</span>的差异只是由<span
class="math inline">\(isGetScholarship\)</span>带来的，可能本来获得奖学金的人成绩就好。</p>
<p><mark><u>第二类：需求端（自选择不平衡）。</u></mark>以出国留学为例，探究是否出国留学对工资的影响，构造如下模型：</p>
<p><span class="math display">\[wage = \beta_{0} + \beta_{1}isAbroad +
u\]</span></p>
<p>这个模型的设定也是存在内生性问题。比如，选择出国留学的人可能家里面经济条件更好，那么零条件均值假设就不再满足，即<span
class="math inline">\(E(家庭经济情况|isAbroad = 1) \neq
E(家庭经济情况|isAbroad = 0)\)</span>。家庭经济情况即会影响<span
class="math inline">\(isAbroad\)</span>同时还会影响<span
class="math inline">\(wage\)</span>，但我们并没有将其作为控制变量，因此导致内生性问题。想要改善内生性问题，就需要将这些同时影响自变量和因变量的因素作为控制变量加入到模型中。</p>
<p><mark><u>第三类：系统不平衡（如性别、种族）。</u></mark>以男女性别为例，想要探究男女性别对工资的影响，建立如下模型：<em><br />
</em><span class="math display">\[wage = \beta_{0} + \beta_{1}gender +
u\]</span></p>
<p>这也是存在严重的内生性问题的。从表面上来看，<span
class="math inline">\(gender\)</span>既不是像第一类问题一样被选择为男性或女性，也不是像第二类问题一样自己选择成为男性或女性，看似是随机分配的。但是，由于男性和女性与生俱来的生理心理差异，就导致了能从事的工作种类、工作意愿不同，同时在一些地区受教育年限也是男女不平衡，而受教育年限很可能会影响<span
class="math inline">\(wage\)</span>。所以这个模型也不满足零条件均值假设。</p>
<p>内生性问题是计量经济学的一个难点。后续会有更多高级的模型和方法来帮助我们改善内生性问题。但最为重要的，还是要结合样本数据，具体问题具体分析。</p>
<h1 id="第8章-异方差性">第8章 异方差性</h1>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1pc411S7ob/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第八章
8.1 异方差对OLS估计的影响_哔哩哔哩_bilibili</a></p>
<h2 id="异方差对mathbfols估计所造成的影响">异方差对<span
class="math inline">\(\mathbf{OLS}\)</span>估计所造成的影响</h2>
<p>假设五中我们对同方差性进行了假定：<span
class="math inline">\(var\left( u \middle| x_{1}\ldots x_{k} \right) =
\sigma^{2}\)</span>。在给定一组<span
class="math inline">\(x\)</span>的取值的情况下，误差项的方差是一个常数。从中就能推出<span
class="math inline">\(var\left( y \middle| x \right) =
\sigma^{2}\)</span>。</p>
<p>那出现异方差会对我们哪些推断和结论产生影响呢？</p>
<p>①是否对系数估计量的期望及其无偏性产生影响？</p>
<p>不会产生影响。计算期望和无偏性只需要假设1-4。</p>
<p>②是否对<span class="math inline">\(R^{2}\)</span>或<span
class="math inline">\({\overline{R} }^{2}\)</span>产生影响？</p>
<p>不会产生影响。我们定义：<span class="math inline">\(R^{2} = 1 -
\frac{SSR}{SST} = 1 - \frac{\sum_{}^{}{(y_{i} - \widehat{y_{i} })}^{2}
}{\sum_{}^{}{(y_{i} - \overline{y_{i} })}^{2} }\)</span>=<span
class="math inline">\(1 - \frac{ {\sigma_{\widehat{u} } }^{2} }{
{\sigma_{y} }^{2}
}\)</span>，其中虽然有残差项平方和，但是这是无条件的，与同方差假定不同。</p>
<p>③是否会影响系数估计的方差<span
class="math inline">\(var(\widehat{\beta_{j} })\)</span></p>
<p>会影响！并且会进一步影响<span
class="math inline">\(se(\widehat{\beta_{j} })\)</span>、<span
class="math inline">\(t\)</span>检验和<span
class="math inline">\(F\)</span>检验。由于<span
class="math inline">\(var\left( \widehat{\beta_{j} } \right) =
\frac{\sigma^{2} }{ {SST}_{j}(1 - {R_{j} }^{2})}\)</span>，而<span
class="math inline">\(se\left( \widehat{\beta_{j} } \right) =
\sqrt{var\left( \widehat{\beta_{j} } \right)}\)</span>，<span
class="math inline">\(t = \frac{\widehat{\beta_{j} } - \beta_{j}
}{se(\widehat{\beta_{j} })}\)</span>。当不满足同方差假定后，<span
class="math inline">\(t\)</span>统计量不服从<span
class="math inline">\(t\)</span>分布，<span
class="math inline">\(F\)</span>统计量也不服从<span
class="math inline">\(F\)</span>分布。</p>
<h2 id="mathbfols估计后的异方差------稳健推断"><span
class="math inline">\(\mathbf{OLS}\)</span>估计后的异方差------稳健推断</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1uN411L7Xw/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">教材精讲-《计量经济学导论.现代观点》第八章
8.2 OLS估计的异方差稳健推断1_哔哩哔哩_bilibili</a></p>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1ew411t7MF/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">教材精讲-《计量经济学导论.现代观点》第八章
8.3 OLS估计的异方差稳健推断2_哔哩哔哩_bilibili</a></p>
<p>首先以一元回归为例：</p>
<p><span class="math display">\[y_{i} = \beta_{0} + \beta_{1}x_{i} +
u\]</span></p>
<p>由于没有同方差假定，因此设<span class="math inline">\(var\left( u
\middle| x_{i} \right) = {\sigma_{i} }^{2}\)</span></p>
<p>通过<span class="math inline">\(OLS\)</span>估计，得到<span
class="math inline">\(\widehat{\beta_{1} } = \beta_{1} +
\frac{\sum_{}^{}{(x_{i} - \overline{x})u_{i} } }{\sum_{}^{}{(x_{i} -
\overline{x})}^{2} }\)</span>，那么<span class="math inline">\(var\left(
\widehat{\beta_{1} }|x \right) = \frac{\sum_{}^{}{\left( x_{i} -
\overline{x} \right)^{2}var(u_{i}|x)} }{ {\lbrack\sum_{}^{}\left( x_{i}
- \overline{x} \right)^{2}\rbrack}^{2} } = \frac{\sum_{}^{}{\left( x_{i}
- \overline{x} \right)^{2}{\sigma_{i} }^{2} } }{
{\lbrack\sum_{}^{}\left( x_{i} - \overline{x} \right)^{2}\rbrack}^{2}
}\)</span>。现在我们的目标是对<span
class="math inline">\(\frac{\sum_{}^{}{\left( x_{i} - \overline{x}
\right)^{2}{\sigma_{i} }^{2} } }{ {\lbrack\sum_{}^{}\left( x_{i} -
\overline{x} \right)^{2}\rbrack}^{2}
}\)</span>进行一个合理的估计。根据怀特（<span
class="math inline">\(White\)</span>，1980）的方法，我们有<span
class="math inline">\(var\left( \widehat{\beta_{1} }|x
\right)\)</span>的一个有效估计量是：</p>
<p><span class="math display">\[\widehat{var\left( \widehat{\beta_{1}
}|x \right)} = \frac{\sum_{}^{}{\left( x_{i} - \overline{x}
\right)^{2}{\widehat{u_{i} } }^{2} } }{ {\lbrack\sum_{}^{}\left( x_{i} -
\overline{x} \right)^{2}\rbrack}^{2} }\]</span></p>
<p>其思想是用<span class="math inline">\({\widehat{u_{i} }
}^{2}\)</span>估计<span class="math inline">\({\sigma_{i}
}^{2}\)</span>，<span class="math inline">\(\widehat{u_{i}
}\)</span>是指每组观测计算出的残差。可以通过数学推断证明<span
class="math inline">\(plim\left( n*\frac{\sum_{}^{}{\left( x_{i} -
\overline{x} \right)^{2}{\widehat{u_{i} } }^{2} } }{\left\lbrack
\sum_{}^{}\left( x_{i} - \overline{x} \right)^{2} \right\rbrack^{2} }
\right) = \frac{E\lbrack{(x_{i} - \mu_{x})}^{2}{u_{i} }^{2}\rbrack}{
{\sigma_{x} }^{2} }\)</span>，因此说这是<span
class="math inline">\(var\left( \widehat{\beta_{1} }|x
\right)\)</span>的一个有效估计量。</p>
<p>而在多元线性回归中，我们有<span
class="math inline">\(\widehat{\beta_{j} }\)</span>的估计表达式：</p>
<p><span class="math display">\[\widehat{\beta_{j} } = \beta_{j} +
\frac{\sum_{}^{}{\widehat{r_{ij} }u_{i} } }{\sum_{}^{}{\widehat{r_{ij} }
}^{2} }\]</span></p>
<p>其中<span class="math inline">\(\widehat{r_{ij} }\)</span>是<span
class="math inline">\(x_{j}\)</span>对其余自变量回归得到残差。那么<span
class="math inline">\(var\left( \widehat{\beta_{j} }|x \right) =
\frac{\sum_{}^{}{ {\widehat{r_{ij} } }^{2}var(u_{i}|x)} }{
{\lbrack\sum_{}^{}{ {\widehat{r_{ij} } }^{2}\rbrack} }^{2} } =
\frac{\sum_{}^{}{ {\widehat{r_{ij} } }^{2}{\sigma_{i} }^{2} } }{
{\lbrack\sum_{}^{}{ {\widehat{r_{ij} } }^{2}\rbrack} }^{2}
}\)</span>，使用上述<span
class="math inline">\(White\)</span>的方法，我们能得到<span
class="math inline">\(var\left( \widehat{\beta_{j} }|x
\right)\)</span>的一个有效估计量：</p>
<p><span class="math display">\[\widehat{var\left( \widehat{\beta_{J}
}|x \right)} = \frac{\sum_{}^{}{ {\widehat{r_{ij} } }^{2}{\widehat{u_{i}
} }^{2} } }{ {\lbrack\sum_{}^{}{ {\widehat{r_{ij} } }^{2}\rbrack} }^{2}
}\]</span></p>
<p>那么此时，其标准误就为（简写去掉条件<span
class="math inline">\(x\)</span>）：</p>
<p><span class="math display">\[se\left( \widehat{\beta_{J} } \right) =
\sqrt{\widehat{var\left( \widehat{\beta_{J} }|x \right)} } =
\frac{\sqrt{\sum_{}^{}{ {\widehat{r_{ij} } }^{2}{\widehat{u_{i} } }^{2}
} } }{\sum_{}^{}{\widehat{r_{ij} } }^{2} } = \frac{\sqrt{\sum_{}^{}{
{\widehat{r_{ij} } }^{2}{\widehat{u_{i} } }^{2} } } }{ {SSR}_{J}
}\]</span></p>
<p>这个我们就叫做<mark><u>异方差稳健标准误</u></mark>。</p>
<p>那么此时，就能够计算出异方差稳健的<span
class="math inline">\(t\)</span>统计量。但问题是，异方差稳健的<span
class="math inline">\(t\)</span>统计量是否服从<span
class="math inline">\(t\)</span>分布呢？在这里，我们需要强调，只有在样本量较大时，异方差稳健的<span
class="math inline">\(t\)</span>统计量才能渐近服从<span
class="math inline">\(t\)</span>分布。（这也很好理解，因为我们使用残差来估计误差方差的，当样本量越来越大时，残差约接近误差，估计越准确。）</p>
<p>在使用异方差稳健标准误时，还需要注意我们是不限制误差的形式的。换言之，当出现未知形式的异方差性时，我们就可以使用异方差稳健标准误。</p>
<p>那么我们想要检验多重排除性约束，那么就需要使用<span
class="math inline">\(F\)</span>统计量或者<span
class="math inline">\(LM\)</span>统计量（朗格朗日统计量）。部分软件是不能计算异方差稳健<span
class="math inline">\(F\)</span>统计量的，但大多数软件都是能够计算异方差稳健的<span
class="math inline">\(LM\)</span>统计量。常规同方差<span
class="math inline">\(LM\)</span>统计量的计算过程是，算出约束模型的残差<span
class="math inline">\(\widehat{u_{i} }\)</span>，再将<span
class="math inline">\(\widehat{u_{i}
}\)</span>对所有自变量求回归，得到残差平方和<span
class="math inline">\({R_{\widehat{u_{i} } } }^{2}\)</span>，<span
class="math inline">\(LM = n{R_{\widehat{u_{i} } }
}^{2}\)</span>符合卡方分布。</p>
<p>而异方差稳健<span
class="math inline">\(LM\)</span>统计量的计算过程要更为复杂一些，具体流程如下：</p>
<p>①计算受约束模型的残差<span
class="math inline">\(\widetilde{u}\)</span>；</p>
<p>②用受约束的自变量分别对其余未受约束的变量做回归，得到残差<span
class="math inline">\(\widetilde{r_{1} }\)</span>、<span
class="math inline">\(\widetilde{r_{2} }\)</span>...<span
class="math inline">\(\widetilde{r_{q} }\)</span>（假设一共有<span
class="math inline">\(q\)</span>个约束）</p>
<p>③做1对<span class="math inline">\(\widetilde{r_{1}
}\widetilde{u}、\widetilde{r_{2} }\widetilde{u}\ldots\widetilde{r_{q}
}\widetilde{u}\)</span>回归，得到残差<span
class="math inline">\({SSR}_{1}\)</span></p>
<p>④异方差稳健的<span class="math inline">\(LM = n -
{SSR}_{1}\)</span>服从自由度为<span
class="math inline">\(q\)</span>的卡方分布。</p>
<h2 id="对异方差的检验">对异方差的检验</h2>
<h3 id="bp-test">BP test</h3>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1vb4y157mr/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">教材精讲-《计量经济学导论.现代观点》】第八章
8.4 异方差的检验_哔哩哔哩_bilibili</a></p>
<p>上述我们讨论的背景都是假设模型存在异方差。那我们如何检验模型是否存在异方差呢？这一节我们介绍检验模型是否存在异方差的一种方法：布罗施-帕甘异方差检验（BP
test）。</p>
<p>假设我们有模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} + \ldots
+ \beta_{k}x_{k} + u\]</span></p>
<p>在假设1-4成立的情况下，<span class="math inline">\(\widehat{\beta_{j}
}\)</span>的估计是无偏且一致的，并且<span class="math inline">\(E\left(
u \middle| x_{1}\ldots x_{k} \right) =
0\)</span>。我们需要检验的内容是，是否存在异方差，即原假设为：</p>
<p><span class="math display">\[H_{0}:var\left( u \middle| x_{1}\ldots
x_{k} \right) = \sigma^{2}\]</span></p>
<p>但我们无法对直接对这个原假设进行检验，需要将它进行转换。</p>
<p><span class="math display">\[var\left( u \middle| x_{1}\ldots x_{k}
\right) = E\left( u^{2} \middle| x_{1}\ldots x_{k} \right) - {E\left( u
\middle| x_{1}\ldots x_{k} \right)}^{2} = E\left( u^{2} \middle|
x_{1}\ldots x_{k} \right)\]</span></p>
<p>因此，原假设等价于：</p>
<p><span class="math display">\[E\left( u^{2} \middle| x_{1}\ldots x_{k}
\right) = \sigma^{2}\]</span></p>
<p>这表明<span class="math inline">\(u^{2}\)</span>与<span
class="math inline">\(x_{1}\ldots x_{k}\)</span>是不相关的（即<span
class="math inline">\(cov\left( u^{2},x_{1}\ldots x_{k} \right) =
0\)</span>）。证明过程如下：</p>
<p><span class="math display">\[E\left( u^{2}\left( x_{1}\ldots x_{k}
\right) \right) = E\left( E\left( u^{2}\left( x_{1}\ldots x_{k}
\right)|x_{1}\ldots x_{k} \right) \right) = E\left( \left( x_{1}\ldots
x_{k} \right)E\left( u^{2}|x_{1}\ldots x_{k} \right) \right) = E\left(
\left( x_{1}\ldots x_{k} \right)\sigma^{2} \right) =
\sigma^{2}E(x_{1}\ldots x_{k})\]</span></p>
<p><span class="math display">\[E\left( u^{2} \right)E\left( x_{1}\ldots
x_{k} \right) = E\left( E(u^{2}|x_{1}\ldots x_{k}) \right)E\left(
x_{1}\ldots x_{k} \right) = \sigma^{2}E(x_{1}\ldots x_{k})\]</span></p>
<p><span class="math display">\[cov\left( u^{2},x_{1}\ldots x_{k}
\right) = E\left( u^{2}\left( x_{1}\ldots x_{k} \right) \right) -
E\left( u^{2} \right)E\left( x_{1}\ldots x_{k} \right) =
\sigma^{2}E\left( x_{1}\ldots x_{k} \right) - \sigma^{2}E\left(
x_{1}\ldots x_{k} \right) = 0\]</span></p>
<p>所以我们现在的原假设转换成：<span
class="math inline">\(u^{2}\)</span>与<span
class="math inline">\(x_{1}\ldots x_{k}\)</span>是不相关的。</p>
<p>为此，我们构建模型：</p>
<p><span class="math display">\[u^{2} = \delta_{0} + \delta_{1}x_{1} +
\ldots + \delta_{k}x_{k} + v\]</span></p>
<p>因此我们能将原假设<span class="math inline">\(u^{2}\)</span>与<span
class="math inline">\(x_{1}\ldots x_{k}\)</span>是不相关的转化成：</p>
<p><span class="math display">\[H_{0}:\delta_{1} = \ldots = \delta_{k} =
0\]</span></p>
<p>在新构建的模型中，我们仍然不知道<span
class="math inline">\(u^{2}\)</span>，所以我们使用<span
class="math inline">\({\widehat{u} }^{2}\)</span>进行估计：<em><br />
</em><span class="math display">\[{\widehat{u} }^{2} = \delta_{0} +
\delta_{1}x_{1} + \ldots + \delta_{k}x_{k} + v\]</span></p>
<p>计算出此模型的<span class="math inline">\({R_{ {\widehat{u} }^{2} }
}^{2}\)</span>。从而就可以计算<span
class="math inline">\(LM\)</span>统计量：</p>
<p><span class="math display">\[LM = n{R_{ {\widehat{u} }^{2} }
}^{2}\]</span></p>
<p>这种<span
class="math inline">\(LM\)</span>形式的检验通常被成为布罗施-帕甘异方差检验（BP
test）。当然，我们也可以进行<span
class="math inline">\(F\)</span>统计量检验。</p>
<h3 id="怀特检验">怀特检验</h3>
<p>相比如BP
test，怀特检验在前期的原假设转换都是一致的，都将原假设转换成：<span
class="math inline">\(u^{2}\)</span>与<span
class="math inline">\(x_{1}\ldots
x_{k}\)</span>是不相关的。但在接下来新模型的设定中有所不同。怀特检验要求更为严苛，不仅要求<span
class="math inline">\(u^{2}\)</span>与<span
class="math inline">\(x_{1}\ldots
x_{k}\)</span>的线性组合无关，还要求与<span
class="math inline">\(x_{1}\ldots
x_{k}\)</span>的所有交互项无关，但这也带来了自由度过高的问题，因为有太多的变量系数需要估计，举例来说，假设<span
class="math inline">\(k = 3\)</span>，则需要假定模型：</p>
<p><span class="math display">\[{\widehat{u} }^{2} = \delta_{0} +
\delta_{1}x_{1} + \delta_{2}x_{2} + \delta_{3}x_{3} +
\delta_{4}x_{1}x_{2} + \delta_{5}x_{1}x_{3} + \delta_{6}x_{2}x_{3} +
\delta_{7}{x_{1} }^{2} + \delta_{8}{x_{2} }^{2} + \delta_{9}{x_{3} }^{2}
+ v\]</span></p>
<p><span class="math display">\[H_{0}:\delta_{0} = \ldots = \delta_{9} =
0\]</span></p>
<p>共有9个系数需要估计，自由度过大。为了解决这个问题，我们用<span
class="math inline">\(\widehat{y}\)</span>替换<span
class="math inline">\(x_{j}\)</span>纳入模型，因为<span
class="math inline">\(\widehat{y} = \widehat{\delta_{0} } +
\widehat{\delta_{1} }x_{1} + \ldots + \widehat{\delta_{k}
}x_{k}\)</span>，所以我们有特殊模型：</p>
<p><span class="math display">\[{\widehat{u} }^{2} = \delta_{0} +
\delta_{1}\widehat{y} + \delta_{2}{\widehat{y} }^{2} + v\]</span></p>
<p><span class="math display">\[H_{0}:\delta_{0} = \delta_{1} =
\delta_{2} = 0\]</span></p>
<p>对比新旧两个模型，<span
class="math inline">\(\widehat{y}\)</span>就相当于所有<span
class="math inline">\(x_{j}\)</span>的一次项，<span
class="math inline">\({\widehat{y} }^{2}\)</span>相当于<span
class="math inline">\(x_{j}\)</span>的交互项。但新模型的自由度只有3个。</p>
<p>接下来就可以用<span class="math inline">\(LM\)</span>统计量或者<span
class="math inline">\(F\)</span>统计量进行检验。</p>
<p>在对异方差进行假设检验中，需要注意最终检验不通过的原因可能不是异方差，也有可能是模型误设或者其余的假设1-4不满足。因此在进行异方差检验之间，需要首先排除是否有模型误设，以及是否满足假设1-4。</p>
<h2 id="加权最小二乘估计wls">加权最小二乘估计（WLS）</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1NH4y1C75b/?p=35&amp;spm_id_from=pageDriver">教材精讲-《计量经济学导论.现代观点》】第八章
8.5 加权最小二乘估计_哔哩哔哩_bilibili</a></p>
<p>在8.3节提到，如果模型出现异方差问题，并且我们不清楚异方差的具体形式，那么我们可以使用OLS估计+异方差稳健统计量进行假设检验，这些异方差稳健统计量在大样本的情况下有较好的渐近分布能够辅助我们的推断。</p>
<p>那么，如果我们能够明确异方差的形式，那我们就可以使用这小节的加权最小二乘估计（WLS）。例如，此时我们知道异方差的形式如下：</p>
<p><span class="math display">\[Var\left( u \middle| x \right) =
\sigma^{2}h(x)\]</span></p>
<p>其中，<span
class="math inline">\(h(x)\)</span>是关于解释变量的函数，并且<span
class="math inline">\(h(x) &gt; 0\)</span>。那么在样本中就有：</p>
<p><span class="math display">\[{\sigma_{i} }^{2} = var\left( u_{i}
\middle| x_{i} \right) = \sigma^{2}h\left( x_{i} \right) =
\sigma^{2}h_{i}\]</span></p>
<p>那么我们原始存在异方差问题的模型为：</p>
<p><span class="math display">\[y_{i} = \beta_{0} + \beta_{1}x_{i1} +
\ldots + \beta_{k}x_{ik} + u_{i}\]</span></p>
<p>我们现在的目标是构建一个新的模型，使之满足误差项同方差条件，从而能够进行OLS估计。由于：</p>
<p><span class="math display">\[var\left( u_{i} \middle| x_{i} \right) =
\sigma^{2}h\left( x_{i} \right) = \sigma^{2}h_{i}\]</span></p>
<p>那么：<em><br />
</em><span class="math display">\[var(\frac{u_{i} }{\sqrt{h_{i} }
}|x_{i1}\ldots x_{ik}) = \sigma^{2}\]</span></p>
<p>因此我们对原模型两边同时除以<span class="math inline">\(\sqrt{h_{i}
}\)</span>，得到新模型：</p>
<p><span class="math display">\[\frac{y_{i} }{\sqrt{h_{i} } } =
\beta_{0}\frac{1}{\sqrt{h_{i} } } + \beta_{1}\frac{x_{i1} }{\sqrt{h_{i}
} } + \ldots + \beta_{k}\frac{x_{ik} }{\sqrt{h_{i} } } + \frac{u_{i}
}{\sqrt{h_{i} } }\]</span></p>
<p>进一步改写：</p>
<p><span class="math display">\[{y_{i} }^{*} = \beta_{0}{x_{i0} }^{*} +
\beta_{1}{x_{i1} }^{*} + \ldots + \beta_{k}{x_{ik} }^{*} + {u_{i}
}^{*}\]</span></p>
<p>我们就可以对新模型进行OLS估计，最小化新的残差平方和：</p>
<p><span class="math display">\[\sum_{}^{}{\widehat{ {u_{i} }^{*} }
}^{2} = \sum_{}^{}{(\frac{\widehat{u_{i} } }{\sqrt{h_{i} } })}^{2} =
\sum_{}^{}\frac{ {\widehat{u_{i} } }^{2} }{h_{i} }\]</span></p>
<p>这种方法就是加权最小二乘估计。加权体现在对每一个观测的原残差平方加上一个权重，在这个例子里面权重是<span
class="math inline">\(\frac{1}{h_{i} }\)</span>。</p>
<p>我们进一步理解一下权重。在这里例子中<span
class="math inline">\(var\left( u_{i} \middle| x_{i} \right) =
\sigma^{2}h\left( x_{i} \right) =
\sigma^{2}h_{i}\)</span>，因此那些方差越大的观测，其<span
class="math inline">\(h_{i}\)</span>越大，所以我们就给这些观测的残差平方更小的权重（<span
class="math inline">\(\sum_{}^{}\frac{ {\widehat{u_{i} } }^{2} }{h_{i}
}\)</span>，乘以<span class="math inline">\(\frac{1}{h_{i}
}\)</span>）。从这个角度来看，OLS估计其实是一个等权最小二乘估计。但需要注意，怎么加权其实有不同的方案，在这个例子中我们是乘以<span
class="math inline">\(\frac{1}{h_{i} }\)</span>。</p>
<h2 id="可行的广义最小二乘估计fgls">可行的广义最小二乘估计（FGLS）</h2>
<p>在8.4小节中，如果我们知道了异方差的形式<span
class="math inline">\(Var\left( u \middle| x \right) =
\sigma^{2}h(x)\)</span>，即知道了<span
class="math inline">\(h(x)\)</span>的具体表达式，那么我们使用加权最小二乘估计出来的估计量还是最优线性无偏的（因为其本质还是使用OLS估计）。但是在实际问题中，我们并不知道<span
class="math inline">\(h(x)\)</span>的具体表达式。因此我们在这一小节首先需要对<span
class="math inline">\(h(x)\)</span>进行估计，这样的估计方法我们就叫做可行的广义最小二乘估计（FGLS）。这种方法估计出来的系数不是无偏的，但是是一致的。具体方法如下：</p>
<p>设模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} + \ldots
+ \beta_{k}x_{k} + u\]</span></p>
<p>满足假设1-4，并且：</p>
<p>对于</p>
<p><span class="math display">\[Var\left( u \middle| x \right) =
\sigma^{2}h(x) = h_{i}\]</span></p>
<p>我们假设<span
class="math inline">\(h_{i}\)</span>是一个指数形式函数，因为<span
class="math inline">\(h_{i}\)</span>必须要保证大于零。即：</p>
<p><span class="math display">\[Var\left( u \middle| x \right) =
\sigma^{2}exp(\delta_{0} + \delta_{1}x_{1} + \ldots +
\delta_{k}x_{k})\]</span></p>
<p>又因为：</p>
<p><span class="math display">\[Var\left( u \middle| x \right) = E\left(
u^{2} \middle| x \right) - {E\left( u \middle| x
\right)}^{2}\]</span></p>
<p><span class="math display">\[E\left( u \middle| x \right) =
0\]</span></p>
<p>所以：</p>
<p><span class="math display">\[E\left( u^{2} \middle| x \right) =
\sigma^{2}exp(\delta_{0} + \delta_{1}x_{1} + \ldots +
\delta_{k}x_{k})\]</span></p>
<p>因此，我们设定模型：</p>
<p><span class="math display">\[u^{2} = \sigma^{2}exp(\delta_{0} +
\delta_{1}x_{1} + \ldots + \delta_{k}x_{k})v\]</span></p>
<p>其中假设<span class="math inline">\(E\left( v \middle| x \right) =
1\)</span>，那么新设定的模型是满足<span class="math inline">\(E\left(
u^{2} \middle| x \right) = \sigma^{2}exp(\delta_{0} + \delta_{1}x_{1} +
\ldots + \delta_{2}x_{2})\)</span>这一条件的。我们在新模型两边取<span
class="math inline">\(\log\)</span>，就有：</p>
<p><span class="math display">\[\log\left( u^{2} \right) = \log\left(
\sigma^{2} \right) + \delta_{0} + \delta_{1}x_{1} + \ldots +
\delta_{k}x_{k} + log(v)\]</span></p>
<p>如果我们假定<span class="math inline">\(v\)</span>确实与<span
class="math inline">\(x\)</span>无关。那么模型就改写为以下形式：</p>
<p><span class="math display">\[\log\left( u^{2} \right) = \alpha_{0} +
\delta_{1}x_{1} + \ldots + \delta_{k}x_{k} + e\]</span></p>
<p>其中，<span class="math inline">\(e\)</span>的均值等于0且与<span
class="math inline">\(x\)</span>无关。此外，我们也必须用OLS残差来取代观测不到的<span
class="math inline">\(u\)</span>。所以，我们做：<span
class="math inline">\(\log\left( u^{2} \right)\)</span>对<span
class="math inline">\(x_{1}\ldots
x_{k}\)</span>的回归。我们只想从这个回归中得到拟合值，称之为<span
class="math inline">\(\widehat{g_{i} }\)</span>。那么<span
class="math inline">\(h_{i}\)</span>的估计量就是：</p>
<p><span class="math display">\[\widehat{h_{i} } = exp(\widehat{g_{i}
})\]</span></p>
<p>那么，我们现在就有：</p>
<p><span class="math display">\[Var\left( u \middle| x \right) =
\sigma^{2}\widehat{h(x)} = \sigma^{2}exp(\widehat{g_{i} })\]</span></p>
<p>接下来就可以使用加权最小二乘估计。</p>
<p>使用可行的GLS估计有以下几点注意：</p>
<p>①如果我们能够知道<span
class="math inline">\(h_{i}\)</span>的具体形式，那我们就能够通过WLS估计出最优线性无偏（BLUE）的系数估计量。但多数情况下我们并不知道，因此只能使用FGLS对<span
class="math inline">\(h_{i}\)</span>进行估计得到<span
class="math inline">\(\widehat{h_{i}
}\)</span>。然后再使用WLS，这样估计出来的系数估计量不是无偏的，但是是一致的，并且相比于直接使用OLS是渐近有效的；</p>
<p>②FGLS最终给出的还是原始方程每个系数的估计量，而不是我们中间的那些假定模型的系数估计量；</p>
<p>③在使用FGLS进行<span
class="math inline">\(F\)</span>统计量检验时，<span
class="math inline">\({SSR}_{r}\)</span>、<span
class="math inline">\({SSR}_{ur}\)</span>要注意受约束和不受约束的模型需要加权一致；</p>
<p>④在实证研究中，一般会报告一个OLS和WLS的结果。一般来说这两个结果不会相差太大。如果两个量出现了显著差异，那就有理由怀疑时零条件均值假设出现了问题。</p>
<p>⑤如果估计出来的异方差还是有误设了，这也不算是特别严重的问题（模型误设和零条件均值不满足带来的问题更加严重）。因为我们在后面还是可以使用一个异方差稳健标准误进行改善。因此，我们推荐的做法时WLS+异方差稳健标准误。</p>
<h2
id="线性概率模型lpm的异方差问题">线性概率模型（LPM）的异方差问题</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1qa4y1r7F6/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第八章
8.7 线性概率模型的异方差问题_哔哩哔哩_bilibili</a></p>
<p>在线性概率模型，我们假设<span
class="math inline">\(y\)</span>服从伯努利分布：</p>
<p><span class="math display">\[P(Y = 1) = \beta_{0} + \beta_{1}x_{1} +
\ldots + \beta_{k}x_{k}\]</span></p>
<p>其中：</p>
<p><span class="math display">\[var\left( y \middle| x \right) =
p(x)\left\lbrack 1 - p(x) \right\rbrack = h(x)\]</span></p>
<p>也就是我们已知异方差的形式<span
class="math inline">\(h(x)\)</span>。那么，我们就能使用FGLS进行估计：</p>
<p><span class="math display">\[\widehat{h_{i} } = \widehat{y_{i} }(1 -
\widehat{y_{i} })\]</span></p>
<p><span class="math inline">\(\widehat{y_{i}
}\)</span>是我们通过样本得到的OLS拟合值。但问题是<span
class="math inline">\(\widehat{y_{i}
}\)</span>不一定落在0-1之间，如果<span
class="math inline">\(\widehat{y_{i} } &lt; 0\)</span>或<span
class="math inline">\(\widehat{y_{i} } &gt; 0\)</span>，都会导致<span
class="math inline">\(\widehat{h_{i} } &lt;
0\)</span>，这是不允许的。一个可能的解决办法是，将所有小于0的值修改为0.01，将所有大于1的值修改为0.99。但这种方法也存在争议，为什么不修改为0.001和0.999呢？因此，在处理线性概率模型的异方差问题时，我们还是建议，假装不知道异方差的形式，而直接用OLS+异方差稳健标准误。</p>
<h1 id="第9章-模型设定和数据问题的深入探讨">第9章
模型设定和数据问题的深入探讨</h1>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Rj411H7N3/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第九章
导论_哔哩哔哩_bilibili</a></p>
<p>本章是在实际运用中遇到问题的经验总结</p>
<h2 id="函数形式误设">函数形式误设</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1he411r76V/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第九章
9.1 函数形式误设_哔哩哔哩_bilibili</a></p>
<p>9.1.1定义：在建模中，误设<span
class="math inline">\(x\)</span>和<span
class="math inline">\(y\)</span>的关系。</p>
<p>举例：</p>
<p>假设真实模型为：</p>
<p><span class="math display">\[\log(wage) = \beta_{0} + \beta_{1}edu +
\beta_{2}exper + \beta_{3}{exper}^{2} + \beta_{4}female +
\beta_{5}female*edu + u\]</span></p>
<p>可能会产生以下三种误设：</p>
<p>①遗漏二次项：甲同学想要探究<span
class="math inline">\(exper\)</span>对工资<span
class="math inline">\(wage\)</span>的影响，但他在模型中遗漏了<span
class="math inline">\({exper}^{2}\)</span>，这就会导致无法准确估计<span
class="math inline">\(exper\)</span>对工资<span
class="math inline">\(wage\)</span>的影响效应，因为现在的模型假定效应始终是恒定不变的，但真实模型中效应是会随着<span
class="math inline">\(exper\)</span>的改变而发生改变的。其次，遗漏了<span
class="math inline">\({exper}^{2}\)</span>就到这其被纳入误差项<span
class="math inline">\(u\)</span>中，那么大概率<span
class="math inline">\(u\)</span>会与其余自变量相关，从而影响其余自变量系数的估计；</p>
<p>②遗漏交互项：乙同学想要探究<span
class="math inline">\(edu\)</span>对<span
class="math inline">\(wage\)</span>的影响，但他在模型中遗漏了交互项<span
class="math inline">\(female*edu\)</span>，这也同样导致无法准确估计我们关心的效应。在真实模型中，由于有交互项的存在，因此<span
class="math inline">\(edu\)</span>对<span
class="math inline">\(wage\)</span>的影响效应是与<span
class="math inline">\(female\)</span>有关的<span
class="math inline">\(\frac{\mathrm{\Delta}\log(wage)}{\mathrm{\Delta}edu}
= \beta_{1} + \beta_{5}female\)</span>。</p>
<p>③因变量形式设置错误。丙同学将因变量设置成水平值形式，但在真实模型中应该是一个对数形式（半弹性模型，效应随自变量的改变而改变）。</p>
<h3 id="检验">检验</h3>
<p>如果我们探究的问题是需不需要加二次项，如：</p>
<p><span class="math display">\[\log(wage) = \beta_{0} + \beta_{1}exper
+ {\beta_{2}exper}^{2} + \beta_{3}edu + \beta_{4}{edu}^{2} +
u\]</span></p>
<p>我们想要知道要不要加入<span
class="math inline">\({exper}^{2}\)</span>和<span
class="math inline">\({edu}^{2}\)</span>（我们非常明确要加的部分的形式）。在这里，我们使用<span
class="math inline">\(F\)</span>检验，原假设为：</p>
<p><span class="math display">\[H_{0}:\beta_{2} = \beta_{4} =
0\]</span></p>
<p>受约束的不受约束的模型分别是：</p>
<p><span class="math display">\[\log(wage) = \beta_{0} + \beta_{1}exper
+ \beta_{3}edu + u\]</span></p>
<p><span class="math display">\[\log(wage) = \beta_{0} + \beta_{1}exper
+ {\beta_{2}exper}^{2} + \beta_{3}edu + \beta_{4}{edu}^{2} +
u\]</span></p>
<p>但在大多数情况下，我们并不知道具体需要加哪些项。比如我们想检验如下模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} + \ldots
+ \beta_{k}x_{k} + u\]</span></p>
<p>我们想要知道是否有二次方项、三次方项、交互项......如果我们把所有自变量组合都放入模型中，就会导致自由度过大。那么，参照异方差的检验方式，我们就可以把<span
class="math inline">\({\widehat{y}
}^{m}\)</span>放入模型中，其中根据实证经验<span
class="math inline">\(m\)</span>一般取2和3就足够。这种检验方式就叫做<mark><u>Reset检验</u></mark>（拉姆齐，1969）。我们构建如下模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} + \ldots
+ \beta_{k}x_{k} + \delta_{1}{\widehat{y} }^{2} + \delta_{2}{\widehat{y}
}^{3} + u\]</span></p>
<p>原假设为：</p>
<p><span class="math display">\[H_{0}:\delta_{1} = \delta_{1} =
0\]</span></p>
<p>如果我们检验出拒绝了原假设，就意味着<span
class="math inline">\({\widehat{y} }^{2}\)</span>和<span
class="math inline">\({\widehat{y}
}^{3}\)</span>是有影响的（但我们不知道究竟是哪一个自变量组合产生的影响），模型是出现了误设。如果没有拒绝，只能说暂时没有发现误设（只能证伪，不能证实）。</p>
<p>上述我们进行检验的都是两组嵌套模型，如果我们想要检验以下两组非嵌套模型哪一种更符合真实模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + u\]</span></p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}log(x_{1}) +
\beta_{2}log(x_{2}) + u\]</span></p>
<p>我们有两种思路：</p>
<p>思路一：将两个模型合成一个模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + \beta_{3}log(x_{1}) + \beta_{4}log(x_{2}) +
u\]</span></p>
<p>如果我们想要检验模型一是否符合真实模型，原假设就是：</p>
<p><span class="math display">\[H_{0}:\beta_{3} = \beta_{4} =
0\]</span></p>
<p>我们检验结果是不拒绝原假设，则模型一就有可能是对的。</p>
<p>如果想要检验模型二是否符合真实模型，原假设就是：</p>
<p><span class="math display">\[H_{0}:\beta_{1} = \beta_{2} =
0\]</span></p>
<p>思路二（戴文森·麦金农）：<em><br />
</em><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + \theta_{1}\widehat{y} + u\]</span></p>
<p>其背后的思路是，我们真实的模型是模型一，那么就不应该包含<span
class="math inline">\(\log\)</span>形式的自变量。那么，如果我们使用模型二<span
class="math inline">\(\log\)</span>形式的自变量拟合出一个因变量估计值<span
class="math inline">\(\widehat{y}\)</span>，将其作为自变量放入模型一中，那么其系数<span
class="math inline">\(\theta_{1}\)</span>就应该为0。因此此时的原假设就是：</p>
<p><span class="math display">\[H_{0}:\theta_{1} = 0\]</span></p>
<p>如果我们检验出拒绝原假设，就说明<span
class="math inline">\(\widehat{y}\)</span>对<span
class="math inline">\(y\)</span>有影响，换言之，模型中应该包含<span
class="math inline">\(\log\)</span>形式的自变量。那么就拒绝模型一是正确的模型。</p>
<p>同理，我们也可以对模型二进行检验：</p>
<p>以<span class="math inline">\(\log\)</span>形式的自变量拟合出<span
class="math inline">\(\widehat{y}\)</span>；将<span
class="math inline">\(\widehat{y}\)</span>代入模型二，检验其系数是否为0；拒绝其系数为0，则拒绝模型二。</p>
<p>在这个方法中，有一些注意点：</p>
<p>有可能两个都拒绝，这就说明模型一和模型二都不妥，都遗漏了成分。如果两个都接受，则说明两个模型都有可能对，都没有明显的错误，可以用调整<span
class="math inline">\({\overline{R}
}^{2}\)</span>做假设。如果我们拒绝原假设推出拒绝了模型二，但这也不能说明模型一更好。</p>
<h2 id="对无法观测的变量使用代理变量">对无法观测的变量使用代理变量</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1wQ4y1g7Nf/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第九章
9.2 对无法观测的变量使用代理变量_哔哩哔哩_bilibili</a></p>
<h3 id="如何使用代理变量">如何使用代理变量</h3>
<p>假设真实模型如下：</p>
<p><span class="math display">\[\log(wage) = \beta_{0} + \beta_{1}edu +
\beta_{2}exper + \beta_{3}ability + u\]</span></p>
<p>我们现在的目标是：保证<span
class="math inline">\(\beta_{1}\)</span>和<span
class="math inline">\(\beta_{2}\)</span>是无偏的，这就需要满足零条件均值假设，也就是误差项<span
class="math inline">\(u\)</span>中不包含与自变量（<span
class="math inline">\(edu\)</span>、<span
class="math inline">\(exper\)</span>）相关的项。现在，我们有另外一个自变量<span
class="math inline">\(ability\)</span>，根据实际分析，<span
class="math inline">\(ability\)</span>是肯定会影响自变量的，也有可能影响因变量，因此我们要将其纳入模型。但问题是，我们很难去测度<span
class="math inline">\(ability\)</span>。</p>
<p>为了解决这种问题，我们代理变量（proxy
variable），其特点是可观测，并且与被代理的变量高度相关。</p>
<p>假设真实模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + \beta_{3}{x_{3} }^{*} + u\]</span></p>
<p>辅助模型：</p>
<p><span class="math display">\[{x_{3} }^{*} = \delta_{0} +
\delta_{1}x_{3} + v\]</span></p>
<p>其中<span class="math inline">\({x_{3}
}^{*}\)</span>是无法观测的真实变量，<span
class="math inline">\(x_{3}\)</span>是可以观测的代理变量。</p>
<p>实际进行回归的模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} +
\beta_{2}x_{2} + \beta_{3}(\delta_{0} + \delta_{1}x_{3} + v) +
u\]</span></p>
<p>即：</p>
<p><span class="math display">\[y = (\beta_{0} + {\beta_{3}\delta}_{0})
+ \beta_{1}x_{1} + \beta_{2}x_{2} + \beta_{3}\delta_{1}x_{3} +
(\beta_{3}v + u)\]</span></p>
<p>那么，在这个新方程中，我们的目标是让<span
class="math inline">\(\beta_{1}\)</span>和<span
class="math inline">\(\beta_{2}\)</span>估计的系数是无偏的。这就需要我们加设一些假设：</p>
<h2 id="使用代理变量需要增加的假设">使用代理变量需要增加的假设</h2>
<p>假设一：<span class="math inline">\(u\)</span>与<span
class="math inline">\(x_{1}\)</span>、<span
class="math inline">\(x_{2}\)</span>、<span class="math inline">\({x_{3}
}^{*}\)</span>、<span
class="math inline">\(x_{3}\)</span>均无关。从真实模型中可知<span
class="math inline">\(u\)</span>需要满足与<span
class="math inline">\(x_{1}\)</span>、<span
class="math inline">\(x_{2}\)</span>、<span class="math inline">\({x_{3}
}^{*}\)</span>无关。从实际回归的模型中可知，<span
class="math inline">\((\beta_{3}v + u)\)</span>与<span
class="math inline">\(x_{3}\)</span>无关，那么<span
class="math inline">\(u\)</span>与<span
class="math inline">\(x_{3}\)</span>是无关的。</p>
<p>假设二：<span class="math inline">\(v\)</span>与<span
class="math inline">\(x_{1}、x_{2}、x_{3}\)</span>均无关。有两种理解角度，①根据实际回归方程，要满足<span
class="math inline">\((\beta_{3}v + u)\)</span>与<span
class="math inline">\(x_{1}\)</span>、<span
class="math inline">\(x_{2}\)</span>、<span
class="math inline">\(x_{3}\)</span>无关，那么就要满足<span
class="math inline">\(v\)</span>与<span
class="math inline">\(x_{1}、x_{2}、x_{3}\)</span>均无关。②这一假设也可改写为：<span
class="math inline">\(E\left( {x_{3} }^{*} \middle| x_{1},x_{2},x_{3}
\right) = E\left( {x_{3} }^{*} \middle| x_{3} \right) = \delta_{0} +
\delta_{1}x_{3}\)</span>。只要控制了<span
class="math inline">\(x_{3}\)</span>，那么无论<span
class="math inline">\(x_{1},x_{2}\)</span>怎么变化，<span
class="math inline">\({x_{3}
}^{*}\)</span>的期望都是不变的（结合辅助模型：<span
class="math inline">\({x_{3} }^{*} = \delta_{0} + \delta_{1}x_{3} +
v\)</span>，只要控制了自变量<span
class="math inline">\(x_{3}\)</span>，那么<span
class="math inline">\({x_{3} }^{*}\)</span>就与<span
class="math inline">\(x_{1},x_{2}\)</span>是无关的，也就是<span
class="math inline">\(v\)</span>不与<span
class="math inline">\(x_{1},x_{2}\)</span>相关）。<span
class="math inline">\(x_{3}\)</span><mark><u>要把</u></mark><span
class="math inline">\({x_{3} }^{*}\)</span><mark><u>与</u></mark><span
class="math inline">\(x_{1},x_{2}\)</span><mark><u>的相关性提取干净</u></mark>。如果没有提取干净，那么剩下的相关性就会漏到<span
class="math inline">\(v\)</span>中，导致<span
class="math inline">\(v\)</span>和<span
class="math inline">\(x_{1}、x_{2}\)</span>相关。</p>
<h3 id="违背了假设所产生的偏误">违背了假设所产生的偏误</h3>
<p>如果假设不满足（<span class="math inline">\(x_{3}\)</span>没有把<span
class="math inline">\({x_{3} }^{*}\)</span>与<span
class="math inline">\(x_{1},x_{2}\)</span>的相关性提取干净），则：</p>
<p><span class="math display">\[{x_{3} }^{*} = \delta_{0} +
\delta_{1}x_{1} + \delta_{2}x_{2} + \delta_{3}x_{3} + v\]</span></p>
<p><span class="math display">\[y = (\beta_{0} + {\beta_{3}\delta}_{0})
+ (\beta_{1} + {\beta_{3}\delta}_{1})x_{1} + (\beta_{2} +
{\beta_{3}\delta}_{2})x_{2} + \beta_{3}\delta_{3}x_{3} + (\beta_{3}v +
u)\]</span></p>
<p>此时，对<span class="math inline">\(x_{1}\)</span>和<span
class="math inline">\(x_{2}\)</span>系数的估计就有偏误了。</p>
<p>可以与模型遗漏变量的影响进行对比，如下图：</p>
<p><span class="math display">\[{x_{3} }^{*}\]</span></p>
<p><span class="math display">\[y\]</span></p>
<p><span class="math display">\[x_{3}\]</span></p>
<p><span class="math display">\[\widehat{\beta_{3} }\]</span></p>
<p><span class="math display">\[\widetilde{\delta_{1} }\]</span></p>
<p><span class="math display">\[\widehat{\beta_{1} }\]</span></p>
<p><span class="math display">\[x_{1}\]</span></p>
<p>我们已知，由于<span class="math inline">\({x_{3}
}^{*}\)</span>与因变量<span
class="math inline">\(y\)</span>和自变量<span
class="math inline">\(x_{1}\)</span>都有相关性，所以一定要放入模型，否则就会导致<span
class="math inline">\(x_{1}\)</span>的系数估计有偏差（走图中绿色线路，<span
class="math inline">\(\widetilde{\beta_{1} } = \widehat{\beta_{1} } +
\widehat{\beta_{3} }\widetilde{\delta_{1} }\)</span>）但是，由于<span
class="math inline">\({x_{3}
}^{*}\)</span>无法观测，因此我们得使用代理变量<span
class="math inline">\(x_{3}\)</span>（图中红色线路）。如果<span
class="math inline">\(x_{3}\)</span>没有把<span
class="math inline">\({x_{3} }^{*}\)</span>与<span
class="math inline">\(x_{1}\)</span>的相关性提取干净，那么还是存在部分相关性（包含在<span
class="math inline">\(v\)</span>之中，仍旧通过绿色线路）导致<span
class="math inline">\(x_{1}\)</span>的系数估计产生偏误。</p>
<p>在实际问题的操作中，还有以下三点提示：</p>
<p>①代理变量可以使用0-1变量，只要含义符合；</p>
<p>②也有使用滞后因变量作为代理变量（<span class="math inline">\(y\sim
y_{- 1}\)</span>），控制一些不可观测的遗漏变量；</p>
<p>③在一些情况下，我们使用代理变量就要考虑新增的假设问题，但如果我们不把其看作代理变量，而是直接看成一个自变量，转换一下我们的研究问题，就不需要考虑代理变量的假设了。比如对于以上这个例子，如果我们从代理变量的角度，使用<span
class="math inline">\(IQ\)</span>作为<span
class="math inline">\(ability\)</span>的代理变量，那么就需要考虑上述的假设是否成立，但如果直接将<span
class="math inline">\(IQ\)</span>作为因变量，探究其对自变量的影响，就不需要考虑上述的假设问题。</p>
<h2 id="随机斜率模型">随机斜率模型</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1BC4y1q7dR/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第九章
9.3 随机斜率模型_哔哩哔哩_bilibili</a></p>
<h3 id="什么时候需要用随机斜率模型">什么时候需要用随机斜率模型</h3>
<p>我们把如下模型，叫做固定效应模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} + \ldots
+ \beta_{k}x_{k} + u\]</span></p>
<p>也可以通过加入交互项，表达这一自变量在不同<strong><u>可观测</u></strong>特征取值下的影响效应。如：<br />
<span class="math display">\[y = \beta_{0} + \beta_{1}edu +
\beta_{3}edu*female + u\]</span></p>
<p>而我们这一节所讨论的随机斜率模型形式如下：</p>
<p><span class="math display">\[y_{i} = a_{i} + b_{i}x_{i}\]</span></p>
<p>对于每一个<span
class="math inline">\(i\)</span>（观测），都有一个单独的<span
class="math inline">\(a_{i}\)</span>和<span
class="math inline">\(b_{i}\)</span>。但在实际问题中，我们不可能达到这个目标。因此我们更加关心的是平均截距<span
class="math inline">\(E\left( a_{i} \right) = \alpha\)</span>和斜率<span
class="math inline">\(E\left( b_{i} \right) =
\beta\)</span>。我们把斜率的平均值称作<mark><u>平均偏效应（APE/AME）</u></mark>。那么对于每一个观测，我们有：</p>
<p><span class="math display">\[a_{i} = \alpha + c_{i}\]</span></p>
<p><span class="math display">\[b_{i} = \beta + d_{i}\]</span></p>
<p>因此，原模型可以改写为：</p>
<p><span class="math display">\[y_{i} = \alpha + c_{i} + (\beta +
d_{i})x_{i}\]</span></p>
<p>整理之后：</p>
<p><span class="math display">\[y_{i} = \alpha + \beta x_{i} + c_{i} +
d_{i}x_{i}\]</span></p>
<p>其中，<span class="math inline">\(c_{i} +
d_{i}x_{i}\)</span>就是<span class="math inline">\(u_{i}\)</span></p>
<h3 id="如何无偏估计出平均偏效应">如何无偏估计出平均偏效应？</h3>
<p>那么，如果我们想要对平均偏效应估计准了，就需要一些对<span
class="math inline">\(u_{i}\)</span>的假设。</p>
<p>对于原方程：</p>
<p><span class="math display">\[y_{i} = \alpha + \beta x_{i} + c_{i} +
d_{i}x_{i}\]</span></p>
<p>我们需要其满足假设四零条件均值假设，即需要满足：</p>
<p><span class="math display">\[E\left( c_{i} + d_{i}x_{i} \middle|
x_{i} \right) = 0\]</span></p>
<p>那么其充分条件就是：<em><br />
</em><span class="math display">\[E\left( c_{i} \middle| x_{i} \right) =
0\]</span></p>
<p><span class="math display">\[E\left( d_{i} \middle| x_{i} \right) =
0\]</span></p>
<p>又由于：<em><br />
</em><span class="math display">\[a_{i} = \alpha + c_{i}\]</span></p>
<p><span class="math display">\[b_{i} = \beta + d_{i}\]</span></p>
<p>则充要条件可以转换为：</p>
<p><span class="math display">\[E\left( a_{i} \middle| x_{i} \right) =
E(a_{i})\]</span></p>
<p><span class="math display">\[E\left( b_{i} \middle| x_{i} \right) =
E(b_{i})\]</span></p>
<p>因此，如果我们需要随机斜率模型估计出来的截距和系数是无偏的，那么就需要满足<mark>截距</mark><span
class="math inline">\(a_{i}\)</span><mark>和系数</mark><span
class="math inline">\(b_{i}\)</span><mark>的期望独立于</mark><span
class="math inline">\(x_{i}\)</span>。</p>
<p>此外，如果我们使用随机斜率模型，就不可避免地会出现异方差问题，因为：</p>
<p><span class="math display">\[var\left( u_{i} \middle| x_{i} \right) =
var\left( c_{i} + d_{i}x_{i} \middle| x_{i} \right) = var\left( c_{i}
\middle| x_{i} \right) + var\left( d_{i}x_{i} \middle| x_{i} \right) =
{\sigma_{c} }^{2} + {x_{i} }^{2}{\sigma_{d} }^{2}\]</span></p>
<p>这个等式需要满足<span class="math inline">\(c_{i}\)</span>与<span
class="math inline">\(d_{i}x_{i}\)</span>独立（第二个等号），且<span
class="math inline">\(c_{i}\)</span>与<span
class="math inline">\(d_{i}\)</span>没有异方差，对于每一个<span
class="math inline">\(x_{i}\)</span>，<span
class="math inline">\(var\left( c_{i} \middle| x_{i} \right) =
{\sigma_{c} }^{2}\)</span>，<span class="math inline">\(var\left( d_{i}
\middle| x_{i} \right) = {\sigma_{d}
}^{2}\)</span>。因此在进行统计地时候可以使用OLS+异方差稳健估计量，或者由于我们知道了异方差的形式（在满足以上两个条件的前提下），也可以使用WLS加权估计。</p>
<h2 id="有测量误差时ols的性质">有测量误差时OLS的性质</h2>
<p><a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1te411z7bn/?spm_id_from=333.788&amp;vd_source=980bb3616cb681e51fd04eecfce37ffa">【教材精讲-《计量经济学导论.现代观点》】第九章
9.4 变量有测量误差时的OLS的性质_哔哩哔哩_bilibili</a></p>
<h3 id="因变量有测量误差">因变量有测量误差</h3>
<p>假设真实模型为：</p>
<p><span class="math display">\[y^{*} = \beta_{0} + \beta_{1}x_{1} +
\ldots + \beta_{k}x_{k} + u\]</span></p>
<p>其中，<span
class="math inline">\(y^{*}\)</span>为真实的自变量。但现在我们放入方程的是测量出的自变量<span
class="math inline">\(y\)</span>。假设测量值<span
class="math inline">\(y\)</span>与真实值<span
class="math inline">\(y^{*}\)</span>有误差<span
class="math inline">\(e_{0}\)</span>，即<span
class="math inline">\(e_{0} = y -
y^{*}\)</span>。那么进行拟合的模型为：</p>
<p><span class="math display">\[y - e_{0} = \beta_{0} + \beta_{1}x_{1} +
\ldots + \beta_{k}x_{k} + u\]</span></p>
<p>进一步移项变换，就能得到实际输入数据进行<span
class="math inline">\(OLS\)</span>回归的模型：</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1} + \ldots
+ \beta_{k}x_{k} + u + e_{0}\]</span></p>
<p>在这个模型中，我们忽略了<span class="math inline">\(y\)</span>与<span
class="math inline">\(y^{*}\)</span>之间的测量误差，而是直接将<span
class="math inline">\(u +
e_{0}\)</span>作为误差项。此时，我们需要探究的问题是这个模型估计出来的<span
class="math inline">\(\widehat{\beta_{k}
}\)</span>是否是无偏且一致的？其方差是否会有变化？</p>
<h4 id="估计系数是否仍然无偏一致">估计系数是否仍然无偏一致？</h4>
<p>那么，我们需要设定一些假设。对于真实模型，我们已知其满足（假设1~4，<span
class="math inline">\(y\)</span>对参数线性相关、随机抽样、自变量不为常数且不与其余自变量线性相关、零条件均值假设），有<span
class="math inline">\(E\left( u \middle| x \right) =
0\)</span>。为了使实际拟合模型也满足假设1~4，那么就要有<span
class="math inline">\(E\left( u + e_{0} \middle| x \right) =
0\)</span>，又因为<span class="math inline">\(E\left( u \middle| x
\right) = 0\)</span>，所以需要满足假设<span
class="math inline">\(E\left( e_{0} \middle| x \right) =
0\)</span>。那么我们就能够推导出<span
class="math inline">\(\widehat{\beta_{k}
}\)</span>是否是无偏且一致的。（对于简单回归，一致性的推导只需要满足<span
class="math inline">\(cov\left( x_{i},u_{i} \right) =
0\)</span>，但是为了推至总体回归方程以及证明系数估计量的无偏性，我们仍然需要一个更加的假设，及零条件均值假设<span
class="math inline">\(E\left( u \middle| x \right) = E(u) =
0\)</span>。）</p>
<h4 id="估计系数的方差如何变化">估计系数的方差如何变化？</h4>
<p>如我们再次假定<span class="math inline">\(u\)</span>与<span
class="math inline">\(e_{0}\)</span>是不相关的。由于方差公式为<span
class="math inline">\(var\left( \widehat{\beta_{j} } \right) =
\frac{\sigma^{2} }{ {SST}_{j}(1 - {R_{j} }^{2})},j =
1,\ldots,k\)</span>，其中<span class="math inline">\(var\left( u + e_{0}
\middle| x_{1},x_{2},x_{3},\ldots,x_{k} \right) =
\sigma^{2}\)</span>。相比于真实模型的误差方差<span
class="math inline">\(var\left( u \middle|
x_{1},x_{2},x_{3},\ldots,x_{k} \right) = {\sigma_{u}
}^{2}\)</span>，真实拟合模型的误差方差为<span
class="math inline">\(var\left( u + e_{0} \middle|
x_{1},x_{2},x_{3},\ldots,x_{k} \right) = {\sigma_{u} }^{2} +
{\sigma_{e_{0} } }^{2}＞{\sigma_{u}
}^{2}\)</span>。所以真实拟合模型的系数估计方差会变大。</p>
<h4 id="例子">例子</h4>
<p>例子1：探究个人储蓄<span
class="math inline">\(sav\)</span>与教育<span
class="math inline">\(edu\)</span>和收入<span
class="math inline">\(inc\)</span>的关系：</p>
<p><span class="math display">\[sav\sim edu + inc\]</span></p>
<p>由于是根据个人报告来测量个人储蓄<span
class="math inline">\(sav\)</span>，就有可能存在教育<span
class="math inline">\(edu\)</span>和收入<span
class="math inline">\(inc\)</span>较低的人群会估计高报个人储蓄，此时就不能实现假设<span
class="math inline">\(E\left( e_{0} \middle| x \right) =
0\)</span>，即测量误差与解释变量是无关的。</p>
<p>例子2：政府通过发放津贴来鼓励企业降低产品废弃率。探究企业产品废弃率与企业是否获得政府津贴的关系：</p>
<p><span class="math display">\[废弃率\sim 是否获得津贴\]</span></p>
<p>已经获得津贴的企业（<span class="math inline">\(是否获得津贴 =
1\)</span>）会倾向于报低自己企业的废弃率，依次来继续获得政府津贴。这也不满足因变量测量误差由于解释变量无关。</p>
<h3 id="自变量有测量误差">自变量有测量误差</h3>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Harlon Yan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/01/01/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6/">http://example.com/2024/01/01/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">Harlon Yan</a>！</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="/./img/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2logo%20%EF%BC%88%E5%B0%8F).png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI0OCIgaGVpZ2h0PSI0OCIgdmlld0JveD0iMCAwIDI0IDI0Ij48Y2lyY2xlIGN4PSI0IiBjeT0iMTIiIHI9IjMiIGZpbGw9ImN1cnJlbnRDb2xvciI+PGFuaW1hdGUgaWQ9InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAiIGF0dHJpYnV0ZU5hbWU9InIiIGJlZ2luPSIwO3N2Z1NwaW5uZXJzM0RvdHNTY2FsZTEuZW5kLTAuMjVzIiBkdXI9IjAuNzVzIiB2YWx1ZXM9IjM7LjI7MyIvPjwvY2lyY2xlPjxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjMiIGZpbGw9ImN1cnJlbnRDb2xvciI+PGFuaW1hdGUgYXR0cmlidXRlTmFtZT0iciIgYmVnaW49InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAuZW5kLTAuNnMiIGR1cj0iMC43NXMiIHZhbHVlcz0iMzsuMjszIi8+PC9jaXJjbGU+PGNpcmNsZSBjeD0iMjAiIGN5PSIxMiIgcj0iMyIgZmlsbD0iY3VycmVudENvbG9yIj48YW5pbWF0ZSBpZD0ic3ZnU3Bpbm5lcnMzRG90c1NjYWxlMSIgYXR0cmlidXRlTmFtZT0iciIgYmVnaW49InN2Z1NwaW5uZXJzM0RvdHNTY2FsZTAuZW5kLTAuNDVzIiBkdXI9IjAuNzVzIiB2YWx1ZXM9IjM7LjI7MyIvPjwvY2lyY2xlPjwvc3ZnPg==" data-original="/./img/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2logo%20%EF%BC%88%E5%B0%8F).png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Harlon Yan</div><div class="author-info-description">这是我的博客</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">5</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com//HarlonYan" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:xxxxxx@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #24292e;"></i></a><a class="social-icon" href="/QQ" target="_blank" title="QQ"><i class="fa-brands fa-qq" style="color: #24292e;"></i></a><a class="social-icon" href="/Wechat" target="_blank" title="Wechat"><i class="fa-brands fa-weixin" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC1%E7%AB%A0-%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6%E7%9A%84%E6%80%A7%E8%B4%A8%E4%B8%8E%E7%BB%8F%E6%B5%8E%E6%95%B0%E6%8D%AE"><span class="toc-number">1.</span> <span class="toc-text">第1章
计量经济学的性质与经济数据</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%9C%A8%E5%81%9A%E4%BB%80%E4%B9%88"><span class="toc-number">1.1.</span> <span class="toc-text">计量经济学在做什么？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E5%81%9A%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98"><span class="toc-number">1.1.1.</span> <span class="toc-text">在做什么问题？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E7%94%A8%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E6%96%B9%E6%B3%95%E4%BD%93%E7%B3%BB%E5%81%9A"><span class="toc-number">1.1.2.</span> <span class="toc-text">在用什么样的方法体系做？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%8F%E6%B5%8E%E6%95%B0%E6%8D%AE%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">1.1.3.</span> <span class="toc-text">经济数据的数据结构</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%88%AA%E9%9D%A2%E6%95%B0%E6%8D%AE%E9%9B%86cross-sectional-data-set"><span class="toc-number">1.1.3.1.</span> <span class="toc-text">截面数据集（cross-sectional
data set）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AEtime-series-data"><span class="toc-number">1.1.3.2.</span> <span class="toc-text">时间序列数据（time series
data）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%B7%E5%90%88%E6%88%AA%E9%9D%A2%E6%95%B0%E6%8D%AEpooled-cross-sectional-data"><span class="toc-number">1.1.3.3.</span> <span class="toc-text">混合截面数据（pooled
cross-sectional data）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%A2%E6%9D%BF%E6%95%B0%E6%8D%AEpanel-data%E5%8F%88%E7%A7%B0%E7%BA%B5%E5%88%97%E6%95%B0%E6%8D%AE"><span class="toc-number">1.1.3.4.</span> <span class="toc-text">面板数据（panel
data，又称纵列数据）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6%E6%9C%80%E5%85%B3%E5%BF%83%E4%BB%80%E4%B9%88"><span class="toc-number">1.2.</span> <span class="toc-text">计量经济学最关心什么</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC2%E7%AB%A0-%E7%AE%80%E5%8D%95%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.</span> <span class="toc-text">第2章 简单回归模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E6%A6%82%E5%BF%B5"><span class="toc-number">2.1.</span> <span class="toc-text">线性回归模型概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%A2%E5%BC%8F%E5%92%8C%E5%86%85%E6%B6%B5"><span class="toc-number">2.1.1.</span> <span class="toc-text">形式和内涵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%81%87%E8%AE%BE"><span class="toc-number">2.1.2.</span> <span class="toc-text">假设</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E4%BD%93%E5%9B%9E%E5%BD%92%E5%87%BD%E6%95%B0"><span class="toc-number">2.1.3.</span> <span class="toc-text">总体回归函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1"><span class="toc-number">2.2.</span> <span class="toc-text">参数估计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E4%BC%B0%E8%AE%A1ols"><span class="toc-number">2.2.1.</span> <span class="toc-text">最小二乘估计（OLS）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9F%A9%E4%BC%B0%E8%AE%A1"><span class="toc-number">2.2.2.</span> <span class="toc-text">矩估计</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%9F%E6%9C%9B%E6%96%B9%E5%B7%AE%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9A%84%E4%B8%80%E4%BA%9B%E5%85%AC%E5%BC%8F%E5%8F%98%E6%8D%A2%E6%80%A7%E8%B4%A8"><span class="toc-number">2.3.</span> <span class="toc-text">期望、方差、协方差的一些公式变换性质</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1%E7%9A%84%E6%95%B0%E5%AD%A6%E6%80%A7%E8%B4%A8"><span class="toc-number">2.4.</span> <span class="toc-text">参数估计的数学性质</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E4%BC%B0%E8%AE%A1%E7%9A%84%E6%95%B0%E5%AD%A6%E6%80%A7%E8%B4%A8%E6%9F%90%E4%B8%80%E5%85%B7%E4%BD%93%E6%A0%B7%E6%9C%AC%E7%9A%84%E6%95%B0%E5%AD%A6%E6%80%A7%E8%B4%A8%E5%8D%B3widehatmathbfbeta_mathbf0-%E5%92%8Cwidehatmathbfbeta_mathbf1-%E6%98%AF%E5%9B%BA%E5%AE%9A%E7%9A%84"><span class="toc-number">2.4.1.</span> <span class="toc-text">最小二乘估计的数学性质（某一具体样本的数学性质，即\(\widehat{\mathbf{\beta}_{\mathbf{0} }
}\)和\(\widehat{\mathbf{\beta}_{\mathbf{1} }
}\)是固定的）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E5%88%86%E8%A7%A3sstssessr"><span class="toc-number">2.4.2.</span> <span class="toc-text">方差分解：SST&#x2F;SSE&#x2F;SSR</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8F%E7%BA%B2%E5%8F%98%E6%8D%A2"><span class="toc-number">2.4.3.</span> <span class="toc-text">量纲变换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E5%92%8C%E5%BC%B9%E6%80%A7"><span class="toc-number">2.4.4.</span> <span class="toc-text">非线性变换和弹性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B8%B8%E5%BC%B9%E6%80%A7%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.4.4.1.</span> <span class="toc-text">常弹性模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%8A%E5%BC%B9%E6%80%A7%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.4.4.2.</span> <span class="toc-text">半弹性模型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1%E7%9A%84%E7%BB%9F%E8%AE%A1%E6%80%A7%E8%B4%A8"><span class="toc-number">2.5.</span> <span class="toc-text">参数估计的统计性质</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ols%E4%BC%B0%E8%AE%A1%E7%9A%84%E6%97%A0%E5%81%8F%E6%80%A7"><span class="toc-number">2.5.1.</span> <span class="toc-text">OLS估计的无偏性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ols%E4%BC%B0%E8%AE%A1%E7%9A%84%E6%96%B9%E5%B7%AE"><span class="toc-number">2.5.2.</span> <span class="toc-text">OLS估计的方差</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AC%E5%BC%8F"><span class="toc-number">3.</span> <span class="toc-text">公式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AC%E7%AB%A0%E5%A4%8D%E4%B9%A0"><span class="toc-number">3.1.</span> <span class="toc-text">本章复习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.1.1.</span> <span class="toc-text">简单线性回归模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E4%BC%B0%E8%AE%A1"><span class="toc-number">3.1.2.</span> <span class="toc-text">最小二乘估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E7%BA%BF"><span class="toc-number">3.1.3.</span> <span class="toc-text">回归线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AE%8B%E5%B7%AE%E7%9A%84%E6%95%B0%E5%AD%A6%E6%80%A7%E8%B4%A8"><span class="toc-number">3.1.4.</span> <span class="toc-text">残差的数学性质</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%9F%E5%90%88%E4%BC%98%E5%BA%A6"><span class="toc-number">3.1.5.</span> <span class="toc-text">拟合优度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8F%E7%BA%B2%E5%8F%98%E6%8D%A2-1"><span class="toc-number">3.1.6.</span> <span class="toc-text">量纲变换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E5%8F%98%E6%8D%A2%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%92%8C%E5%BC%B9%E6%80%A7"><span class="toc-number">3.1.7.</span> <span class="toc-text">函数变换（非线性和弹性）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E6%9C%9F%E6%9C%9B"><span class="toc-number">3.1.8.</span> <span class="toc-text">参数期望</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E6%96%B9%E5%B7%AE"><span class="toc-number">3.1.9.</span> <span class="toc-text">参数方差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E4%BC%B0%E8%AE%A1"><span class="toc-number">3.1.10.</span> <span class="toc-text">方差估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B9%A0%E9%A2%98%E7%BB%83%E4%B9%A0"><span class="toc-number">3.1.11.</span> <span class="toc-text">习题练习</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC3%E7%AB%A0-%E5%A4%9A%E5%85%83%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%B8%8E%E4%BC%B0%E8%AE%A1"><span class="toc-number">4.</span> <span class="toc-text">第3章
多元回归分析：模型与估计</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E5%BD%A2%E5%BC%8F%E5%92%8C%E5%81%87%E8%AE%BE"><span class="toc-number">4.1.</span> <span class="toc-text">多元回归模型（形式和假设）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B3%BB%E6%95%B0%E4%BC%B0%E8%AE%A1%E4%B8%8E%E6%8E%A8%E5%AF%BC%E5%87%BA%E7%9A%84%E6%95%B0%E5%AD%A6%E6%80%A7%E8%B4%A8"><span class="toc-number">4.2.</span> <span class="toc-text">系数估计与推导出的数学性质</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%81%97%E6%BC%8F%E5%A2%9E%E5%8A%A0%E5%8F%98%E9%87%8F%E5%AF%B9%E5%9B%9E%E5%BD%92%E7%B3%BB%E6%95%B0%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">4.3.</span> <span class="toc-text">遗漏&#x2F;增加变量对回归系数的影响</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B3%BB%E6%95%B0%E6%9C%9F%E6%9C%9B"><span class="toc-number">4.4.</span> <span class="toc-text">系数期望</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9B%E4%B8%AA%E5%89%8D%E6%8F%90%E5%81%87%E8%AE%BE"><span class="toc-number">4.4.1.</span> <span class="toc-text">四个前提假设</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E9%87%8F%E6%9C%9F%E6%9C%9B%E6%8E%A8%E5%AF%BC"><span class="toc-number">4.4.2.</span> <span class="toc-text">估计量期望推导</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A0%E5%85%B3%E9%81%97%E6%BC%8F%E5%8F%98%E9%87%8F%E5%AF%B9%E6%9C%9F%E6%9C%9B%E7%9A%84%E5%BD%B1%E5%93%8D%E5%81%8F%E8%AF%AF"><span class="toc-number">4.4.3.</span> <span class="toc-text">无关&#x2F;遗漏变量对期望的影响（偏误）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E4%B8%AD%E5%8C%85%E5%90%AB%E4%BA%86%E6%97%A0%E5%85%B3%E5%8F%98%E9%87%8F"><span class="toc-number">4.4.3.1.</span> <span class="toc-text">在回归模型中包含了无关变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%81%97%E6%BC%8F%E5%8F%98%E9%87%8F%E7%9A%84%E5%81%8F%E8%AF%AF%E7%AE%80%E5%8D%95%E6%83%85%E5%BD%A2"><span class="toc-number">4.4.3.2.</span> <span class="toc-text">遗漏变量的偏误：简单情形</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%81%97%E6%BC%8F%E5%8F%98%E9%87%8F%E7%9A%84%E5%81%8F%E8%AF%AF%E6%9B%B4%E4%B8%80%E8%88%AC%E7%9A%84%E6%83%85%E5%BD%A2"><span class="toc-number">4.4.3.3.</span> <span class="toc-text">遗漏变量的偏误：更一般的情形</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B3%BB%E6%95%B0%E6%96%B9%E5%B7%AE%E4%B8%8E%E6%A0%87%E5%87%86%E8%AF%AF"><span class="toc-number">4.5.</span> <span class="toc-text">系数方差与标准误</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B3%BB%E6%95%B0%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E6%96%B9%E5%B7%AE%E6%8E%A8%E5%AF%BC"><span class="toc-number">4.5.1.</span> <span class="toc-text">系数估计量的方差推导</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%86%A8%E8%83%80%E5%9B%A0%E5%AD%90mathbfvmathbfif"><span class="toc-number">4.5.2.</span> <span class="toc-text">膨胀因子\(\mathbf{V}\mathbf{IF}\)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%81%97%E6%BC%8F%E5%A2%9E%E5%8A%A0%E5%8F%98%E9%87%8F%E5%AF%B9%E5%81%8F%E8%AF%AF%E5%92%8C%E6%96%B9%E5%B7%AE%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">4.5.3.</span> <span class="toc-text">遗漏&#x2F;增加变量对偏误和方差的影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B3%BB%E6%95%B0%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E6%96%B9%E5%B7%AE%E4%BC%B0%E8%AE%A1"><span class="toc-number">4.5.4.</span> <span class="toc-text">系数估计量的方差估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E6%96%AF%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%AE%9A%E7%90%86"><span class="toc-number">4.5.5.</span> <span class="toc-text">高斯马尔可夫定理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AB%A0%E6%9C%AB%E5%A4%8D%E4%B9%A0%E4%B8%8B%E6%AC%A1%E5%86%8D%E7%9C%8B"><span class="toc-number">4.6.</span> <span class="toc-text">章末复习【下次再看】</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC4%E7%AB%A0-%E5%A4%9A%E5%85%83%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E6%8E%A8%E6%96%AD"><span class="toc-number">5.</span> <span class="toc-text">第4章 多元回归分析：推断</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#ols%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83"><span class="toc-number">5.1.</span> <span class="toc-text">OLS估计量的抽样分布</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ols%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C"><span class="toc-number">5.2.</span> <span class="toc-text">OLS估计量的假设检验</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ols%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4"><span class="toc-number">5.3.</span> <span class="toc-text">OLS估计量的置信区间</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%8F%82%E6%95%B0%E6%A3%80%E9%AA%8C"><span class="toc-number">5.4.</span> <span class="toc-text">多参数检验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A3%80%E9%AA%8C%E5%8F%82%E6%95%B0%E7%9A%84%E7%BA%BF%E6%80%A7%E7%BB%84%E5%90%88"><span class="toc-number">5.4.1.</span> <span class="toc-text">检验参数的线性组合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E5%A4%9A%E4%B8%AA%E7%BA%BF%E6%80%A7%E7%BA%A6%E6%9D%9F%E7%9A%84%E6%A3%80%E9%AA%8C"><span class="toc-number">5.4.2.</span> <span class="toc-text">对多个线性约束的检验</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E6%8E%92%E9%99%A4%E6%80%A7%E7%BA%A6%E6%9D%9F%E7%9A%84%E6%A3%80%E9%AA%8C"><span class="toc-number">5.4.2.1.</span> <span class="toc-text">对排除性约束的检验</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E6%95%B4%E4%BD%93%E6%98%BE%E8%91%97%E6%80%A7%E7%9A%84mathbff%E7%BB%9F%E8%AE%A1%E9%87%8F"><span class="toc-number">5.4.2.2.</span> <span class="toc-text">回归整体显著性的\(\mathbf{F}\)统计量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A3%80%E9%AA%8C%E4%B8%80%E8%88%AC%E6%80%A7%E7%9A%84%E7%BA%BF%E6%80%A7%E7%BA%A6%E6%9D%9F"><span class="toc-number">5.4.2.3.</span> <span class="toc-text">检验一般性的线性约束</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E7%BB%93%E6%9E%9C%E7%9A%84%E4%B8%80%E8%88%AC%E6%8A%A5%E5%91%8A%E5%BD%A2%E5%BC%8F"><span class="toc-number">5.4.2.4.</span> <span class="toc-text">回归结果的一般报告形式</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC5%E7%AB%A0-%E5%A4%9A%E5%85%83%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90ols%E7%9A%84%E6%B8%90%E8%BF%91%E6%80%A7%E8%B4%A8"><span class="toc-number">6.</span> <span class="toc-text">第5章
多元回归分析：OLS的渐近性质</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#ols%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E5%81%87%E8%AE%BE1-4"><span class="toc-number">6.1.</span> <span class="toc-text">OLS估计量的一致性（假设1-4）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">6.1.1.</span> <span class="toc-text">一致性的定义：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="toc-number">6.1.2.</span> <span class="toc-text">一致性的性质</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%AE%9A%E7%90%86mathbfplimleft-widehatmathbfbeta_mathbfj-rightmathbfmathbfbeta_mathbfj"><span class="toc-number">6.1.3.</span> <span class="toc-text">一致性的定理\(\mathbf{plim}\left(
\widehat{\mathbf{\beta}_{\mathbf{j} } }
\right)\mathbf{&#x3D;}\mathbf{\beta}_{\mathbf{j} }\)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%81%97%E6%BC%8F%E5%8F%98%E9%87%8F%E6%97%B6%E5%AF%B9%E4%B8%8D%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">6.1.4.</span> <span class="toc-text">遗漏变量时对不一致性的影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%95%E4%B8%AA%E7%B3%BB%E6%95%B0%E4%B8%8D%E4%B8%80%E8%87%B4%E5%AF%B9%E5%85%B6%E4%BD%99%E7%B3%BB%E6%95%B0%E7%9A%84%E4%B8%8D%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">6.1.5.</span> <span class="toc-text">单个系数不一致对其余系数的不一致性的影响</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ols%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E6%B8%90%E8%BF%91%E6%AD%A3%E6%80%81%E5%81%87%E8%AE%BE1-5"><span class="toc-number">6.2.</span> <span class="toc-text">OLS估计量的渐近正态（假设1-5）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%81%E6%98%8E%E5%AE%9A%E7%90%86%E2%91%A0sqrtmathbfn-left-widehatmathbfbeta_mathbf1-mathbf-mathbfbeta_mathbf1-right%E8%B6%8B%E8%BF%91%E4%BA%8E%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83"><span class="toc-number">6.2.1.</span> <span class="toc-text">证明定理①：\(\sqrt{\mathbf{n} }\left(
\widehat{\mathbf{\beta}_{\mathbf{1} }
}\mathbf{-}\mathbf{\beta}_{\mathbf{1} }
\right)\)趋近于正态分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%81%E6%98%8E%E5%AE%9A%E7%90%86%E2%91%A1mathbfplimleft-widehatmathbfsigma-mathbf2-rightmathbfmathbfsigmamathbf2-%E5%90%8E%E7%BB%AD%E8%A1%A5%E5%85%85"><span class="toc-number">6.2.2.</span> <span class="toc-text">证明定理②\(\mathbf{plim}\left( {\widehat{\mathbf{\sigma} }
}^{\mathbf{2} } \right)\mathbf{&#x3D;}\mathbf{\sigma}^{\mathbf{2}
}\)【后续补充】</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%81%E6%98%8E%E5%AE%9A%E7%90%86%E2%91%A2widehatmathbfbeta_mathbfj-%E7%BB%8F%E8%BF%87%E6%A0%87%E5%87%86%E5%8C%96%E5%90%8E%E6%B8%90%E8%BF%91%E6%A0%87%E5%87%86%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83"><span class="toc-number">6.2.3.</span> <span class="toc-text">证明定理③：\(\widehat{\mathbf{\beta}_{\mathbf{j} }
}\)经过标准化后渐近标准正态分布</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%97%E6%A0%BC%E6%9C%97%E6%97%A5%E7%BB%9F%E8%AE%A1%E9%87%8F"><span class="toc-number">6.3.</span> <span class="toc-text">朗格朗日统计量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ols%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E6%B8%90%E8%BF%91%E6%9C%89%E6%95%88%E6%80%A7"><span class="toc-number">6.4.</span> <span class="toc-text">5.3 OLS估计量的渐近有效性</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC6%E7%AB%A0-%E5%A4%9A%E5%85%83%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E6%B7%B1%E5%85%A5%E4%B8%93%E9%A2%98"><span class="toc-number">7.</span> <span class="toc-text">第6章 多元回归分析：深入专题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%B5%8B%E5%BA%A6%E5%8F%98%E6%8D%A2%E6%B5%8B%E5%BA%A6%E5%8D%95%E4%BD%8D%E6%A0%87%E5%87%86%E5%8C%96mathbfbeta%E7%B3%BB%E6%95%B0"><span class="toc-number">7.1.</span> <span class="toc-text">6.1数据测度变换（测度单位、标准化\(\mathbf{\beta}\)系数）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#mathbfx%E5%92%8Cmathbfy%E5%8F%91%E7%94%9F%E6%B5%8B%E5%BA%A6%E5%8D%95%E4%BD%8D%E4%B8%8A%E7%9A%84%E5%8F%98%E5%8C%96"><span class="toc-number">7.1.1.</span> <span class="toc-text">\(\mathbf{x}\)和\(\mathbf{y}\)发生测度单位上的变化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%87%E5%87%86%E5%8C%96%E7%B3%BB%E6%95%B0mathbfbeta%E7%B3%BB%E6%95%B0"><span class="toc-number">7.1.2.</span> <span class="toc-text">标准化系数（\(\mathbf{\beta}\)系数）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E5%BD%A2%E5%BC%8F%E5%8F%98%E6%8D%A2%E5%AF%B9%E6%95%B0%E4%BA%8C%E6%AC%A1%E9%A1%B9%E4%BA%A4%E4%BA%92%E9%A1%B9"><span class="toc-number">7.2.</span> <span class="toc-text">函数形式变换（对数、二次项、交互项）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%95%B0%E5%8F%98%E6%8D%A2"><span class="toc-number">7.2.1.</span> <span class="toc-text">对数变换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%98%E5%8C%96%E4%B8%BA%E4%BA%8C%E6%AC%A1%E9%A1%B9"><span class="toc-number">7.2.2.</span> <span class="toc-text">变化为二次项</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%98%E6%8D%A2%E4%B8%BA%E4%BA%A4%E4%BA%92%E9%A1%B9"><span class="toc-number">7.2.3.</span> <span class="toc-text">变换为交互项</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8B%9F%E5%90%88%E4%BC%98%E5%BA%A6%E4%B8%8E%E5%9B%9E%E5%BD%92%E5%85%83%E9%80%89%E6%8B%A9"><span class="toc-number">7.3.</span> <span class="toc-text">拟合优度与回归元选择</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%9F%E5%90%88%E4%BC%98%E5%BA%A6%E8%B0%83%E6%95%B4mathbfrmathbf2"><span class="toc-number">7.3.1.</span> <span class="toc-text">拟合优度（调整\(\mathbf{R}^{\mathbf{2} }\)）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E5%85%83%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">7.3.2.</span> <span class="toc-text">回归元的选择</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E4%B8%8E%E6%AE%8B%E5%B7%AE%E5%88%86%E6%9E%90"><span class="toc-number">7.4.</span> <span class="toc-text">预测与残差分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E7%9A%84%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4%E4%B8%A4%E7%A7%8D%E7%90%86%E8%A7%A3"><span class="toc-number">7.4.1.</span> <span class="toc-text">预测的置信区间（两种理解）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E7%A7%8D%E7%90%86%E8%A7%A3mathbfeyx"><span class="toc-number">7.4.1.1.</span> <span class="toc-text">第一种理解：\(\mathbf{E(Y|X)}\)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%A7%8D%E7%90%86%E8%A7%A3mathbfy_mathbfi-%E9%A2%84%E6%B5%8B%E5%80%BC%E7%9A%84%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4"><span class="toc-number">7.4.1.2.</span> <span class="toc-text">第二种理解：\(\mathbf{y}_{\mathbf{i}
}\)预测值的置信区间</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E7%9A%84%E7%89%B9%E6%AE%8A%E6%83%85%E5%86%B5"><span class="toc-number">7.4.2.</span> <span class="toc-text">预测的特殊情况</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AE%8B%E5%B7%AE%E5%88%86%E6%9E%90%E6%8B%93%E5%B1%95%E6%80%9D%E8%B7%AF"><span class="toc-number">7.4.3.</span> <span class="toc-text">残差分析（拓展思路）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC7%E7%AB%A0-%E5%90%AB%E6%9C%89%E5%AE%9A%E6%80%A7%E4%BF%A1%E6%81%AF%E7%9A%84%E5%A4%9A%E5%85%83%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E4%BA%8C%E5%80%BC%E8%99%9A%E6%8B%9F%E5%8F%98%E9%87%8F"><span class="toc-number">8.</span> <span class="toc-text">第7章
含有定性信息的多元回归分析：二值（虚拟）变量</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%B8%AD%E5%8C%85%E5%90%AB%E4%B8%80%E4%B8%AA%E8%99%9A%E6%8B%9F%E5%8F%98%E9%87%8F"><span class="toc-number">8.1.</span> <span class="toc-text">模型中包含一个虚拟变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E7%B1%BB%E5%88%AB%E8%99%9A%E6%8B%9F%E5%8F%98%E9%87%8F"><span class="toc-number">8.2.</span> <span class="toc-text">多类别虚拟变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E5%8F%98%E9%87%8F%E7%9A%84%E4%BA%A4%E4%BA%92"><span class="toc-number">8.3.</span> <span class="toc-text">虚拟变量的交互</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E5%8F%98%E9%87%8F%E8%99%9A%E6%8B%9F%E5%8F%98%E9%87%8F"><span class="toc-number">8.3.1.</span> <span class="toc-text">虚拟变量*虚拟变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E5%8F%98%E9%87%8F%E5%AE%9A%E9%87%8F%E5%8F%98%E9%87%8F"><span class="toc-number">8.3.2.</span> <span class="toc-text">虚拟变量*定量变量</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E5%80%BC%E5%9B%A0%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E7%BA%BF%E6%80%A7%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B"><span class="toc-number">8.4.</span> <span class="toc-text">二值因变量模型（线性概率模型）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A6%BB%E6%95%A3%E5%9B%A0%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B"><span class="toc-number">8.5.</span> <span class="toc-text">离散因变量模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%94%BF%E7%AD%96%E5%88%86%E6%9E%90%E4%B8%8E%E9%A1%B9%E7%9B%AE%E8%AF%84%E4%BB%B7%E5%86%85%E7%94%9F%E6%80%A7%E9%97%AE%E9%A2%98"><span class="toc-number">8.6.</span> <span class="toc-text">政策分析与项目评价（内生性问题）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC8%E7%AB%A0-%E5%BC%82%E6%96%B9%E5%B7%AE%E6%80%A7"><span class="toc-number">9.</span> <span class="toc-text">第8章 异方差性</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%82%E6%96%B9%E5%B7%AE%E5%AF%B9mathbfols%E4%BC%B0%E8%AE%A1%E6%89%80%E9%80%A0%E6%88%90%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">9.1.</span> <span class="toc-text">异方差对\(\mathbf{OLS}\)估计所造成的影响</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mathbfols%E4%BC%B0%E8%AE%A1%E5%90%8E%E7%9A%84%E5%BC%82%E6%96%B9%E5%B7%AE------%E7%A8%B3%E5%81%A5%E6%8E%A8%E6%96%AD"><span class="toc-number">9.2.</span> <span class="toc-text">\(\mathbf{OLS}\)估计后的异方差------稳健推断</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E5%BC%82%E6%96%B9%E5%B7%AE%E7%9A%84%E6%A3%80%E9%AA%8C"><span class="toc-number">9.3.</span> <span class="toc-text">对异方差的检验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#bp-test"><span class="toc-number">9.3.1.</span> <span class="toc-text">BP test</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%80%E7%89%B9%E6%A3%80%E9%AA%8C"><span class="toc-number">9.3.2.</span> <span class="toc-text">怀特检验</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E6%9D%83%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E4%BC%B0%E8%AE%A1wls"><span class="toc-number">9.4.</span> <span class="toc-text">加权最小二乘估计（WLS）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E8%A1%8C%E7%9A%84%E5%B9%BF%E4%B9%89%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E4%BC%B0%E8%AE%A1fgls"><span class="toc-number">9.5.</span> <span class="toc-text">可行的广义最小二乘估计（FGLS）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8Blpm%E7%9A%84%E5%BC%82%E6%96%B9%E5%B7%AE%E9%97%AE%E9%A2%98"><span class="toc-number">9.6.</span> <span class="toc-text">线性概率模型（LPM）的异方差问题</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC9%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AE%BE%E5%AE%9A%E5%92%8C%E6%95%B0%E6%8D%AE%E9%97%AE%E9%A2%98%E7%9A%84%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8"><span class="toc-number">10.</span> <span class="toc-text">第9章
模型设定和数据问题的深入探讨</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E5%BD%A2%E5%BC%8F%E8%AF%AF%E8%AE%BE"><span class="toc-number">10.1.</span> <span class="toc-text">函数形式误设</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A3%80%E9%AA%8C"><span class="toc-number">10.1.1.</span> <span class="toc-text">检验</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E6%97%A0%E6%B3%95%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%98%E9%87%8F%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86%E5%8F%98%E9%87%8F"><span class="toc-number">10.2.</span> <span class="toc-text">对无法观测的变量使用代理变量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86%E5%8F%98%E9%87%8F"><span class="toc-number">10.2.1.</span> <span class="toc-text">如何使用代理变量</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86%E5%8F%98%E9%87%8F%E9%9C%80%E8%A6%81%E5%A2%9E%E5%8A%A0%E7%9A%84%E5%81%87%E8%AE%BE"><span class="toc-number">10.3.</span> <span class="toc-text">使用代理变量需要增加的假设</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9D%E8%83%8C%E4%BA%86%E5%81%87%E8%AE%BE%E6%89%80%E4%BA%A7%E7%94%9F%E7%9A%84%E5%81%8F%E8%AF%AF"><span class="toc-number">10.3.1.</span> <span class="toc-text">违背了假设所产生的偏误</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%96%9C%E7%8E%87%E6%A8%A1%E5%9E%8B"><span class="toc-number">10.4.</span> <span class="toc-text">随机斜率模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E9%9C%80%E8%A6%81%E7%94%A8%E9%9A%8F%E6%9C%BA%E6%96%9C%E7%8E%87%E6%A8%A1%E5%9E%8B"><span class="toc-number">10.4.1.</span> <span class="toc-text">什么时候需要用随机斜率模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1%E5%87%BA%E5%B9%B3%E5%9D%87%E5%81%8F%E6%95%88%E5%BA%94"><span class="toc-number">10.4.2.</span> <span class="toc-text">如何无偏估计出平均偏效应？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%89%E6%B5%8B%E9%87%8F%E8%AF%AF%E5%B7%AE%E6%97%B6ols%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="toc-number">10.5.</span> <span class="toc-text">有测量误差时OLS的性质</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%A0%E5%8F%98%E9%87%8F%E6%9C%89%E6%B5%8B%E9%87%8F%E8%AF%AF%E5%B7%AE"><span class="toc-number">10.5.1.</span> <span class="toc-text">因变量有测量误差</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E7%B3%BB%E6%95%B0%E6%98%AF%E5%90%A6%E4%BB%8D%E7%84%B6%E6%97%A0%E5%81%8F%E4%B8%80%E8%87%B4"><span class="toc-number">10.5.1.1.</span> <span class="toc-text">估计系数是否仍然无偏一致？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E7%B3%BB%E6%95%B0%E7%9A%84%E6%96%B9%E5%B7%AE%E5%A6%82%E4%BD%95%E5%8F%98%E5%8C%96"><span class="toc-number">10.5.1.2.</span> <span class="toc-text">估计系数的方差如何变化？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BE%8B%E5%AD%90"><span class="toc-number">10.5.1.3.</span> <span class="toc-text">例子</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%8F%98%E9%87%8F%E6%9C%89%E6%B5%8B%E9%87%8F%E8%AF%AF%E5%B7%AE"><span class="toc-number">10.5.2.</span> <span class="toc-text">自变量有测量误差</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/01/01/PPT%E4%BD%9C%E5%93%81/" title="PPT作品">PPT作品</a><time datetime="2023-12-31T16:00:00.000Z" title="发表于 2024-01-01 00:00:00">2024-01-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/01/01/%E5%8F%8C%E9%87%8D%E5%B7%AE%E5%88%86%E6%B3%95%EF%BC%88DID%EF%BC%89/" title="双重差分法（DID）">双重差分法（DID）</a><time datetime="2023-12-31T16:00:00.000Z" title="发表于 2024-01-01 00:00:00">2024-01-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/01/01/python%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0/" title="python语法笔记">python语法笔记</a><time datetime="2023-12-31T16:00:00.000Z" title="发表于 2024-01-01 00:00:00">2024-01-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/01/01/%E6%B5%85%E8%B0%88%E5%AE%9E%E8%AF%81%E7%A0%94%E7%A9%B6/" title="浅谈实证研究">浅谈实证研究</a><time datetime="2023-12-31T16:00:00.000Z" title="发表于 2024-01-01 00:00:00">2024-01-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/01/01/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6/" title="计量经济学">计量经济学</a><time datetime="2023-12-31T16:00:00.000Z" title="发表于 2024-01-01 00:00:00">2024-01-01</time></div></div></div></div></div></div></main><footer id="footer" style="background: linear-gradient(to left, #40e0d0, #ff8c00, #ff0080);"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Harlon Yan</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 3,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body></html>